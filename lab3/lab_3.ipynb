{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "\n",
    "Celem laboratorium jest zapoznanie się z podstawami sieci neuronowych oraz uczeniem głębokim (*deep learning*). Zapoznasz się na nim z następującymi tematami:\n",
    "- treningiem prostych sieci neuronowych, w szczególności z:\n",
    "  - regresją liniową w sieciach neuronowych\n",
    "  - optymalizacją funkcji kosztu\n",
    "  - algorytmem spadku wzdłuż gradientu\n",
    "  - siecią typu Multilayer Perceptron (MLP)\n",
    "- frameworkiem PyTorch, w szczególności z:\n",
    "  - ładowaniem danych\n",
    "  - preprocessingiem danych\n",
    "  - pisaniem pętli treningowej i walidacyjnej\n",
    "  - walidacją modeli\n",
    "- architekturą i hiperaprametrami sieci MLP, w szczególności z:\n",
    "  - warstwami gęstymi (w pełni połączonymi)\n",
    "  - funkcjami aktywacji\n",
    "  - regularyzacją: L2, dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystywane biblioteki\n",
    "\n",
    "Zaczniemy od pisania ręcznie prostych sieci w bibliotece Numpy, służącej do obliczeń numerycznych na CPU. Później przejdziemy do wykorzystywania frameworka PyTorch, służącego do obliczeń numerycznych na CPU, GPU oraz automatycznego różniczkowania, wykorzystywanego głównie do treningu sieci neuronowych.\n",
    "\n",
    "Wykorzystamy PyTorcha ze względu na popularność, łatwość instalacji i użycia, oraz dużą kontrolę nad niskopoziomowymi aspektami budowy i treningu sieci neuronowych. Framework ten został stworzony do zastosowań badawczych i naukowych, ale ze względu na wygodę użycia stał się bardzo popularny także w przemyśle. W szczególności całkowicie zdominował przetwarzanie języka naturalnego (NLP) oraz uczenie na grafach.\n",
    "\n",
    "Pierwszy duży framework do deep learningu, oraz obecnie najpopularniejszy, to TensorFlow, wraz z wysokopoziomową nakładką Keras. Są jednak szanse, że Google (autorzy) będzie go powoli porzucać na rzecz ich nowego frameworka JAX ([dyskusja](https://www.reddit.com/r/MachineLearning/comments/vfl57t/d_google_quietly_moving_its_products_from/), [artykuł Business Insidera](https://www.businessinsider.com/facebook-pytorch-beat-google-tensorflow-jax-meta-ai-2022-6?IR=T)), który jest bardzo świeżym, ale ciekawym narzędziem.\n",
    "\n",
    "Trzecia, ale znacznie mniej popularna od powyższych opcja to Apache MXNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja własnego komputera\n",
    "\n",
    "Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane).\n",
    "\n",
    "Jeżeli nie masz GPU lub nie chcesz z niego korzystać, to wystarczy znaleźć odpowiednią komendę CPU [na stronie PyTorcha](https://pytorch.org/get-started/locally/). Dla Anacondy odpowiednia komenda została podana poniżej, dla pip'a znajdź ją na stronie.\n",
    "\n",
    "Jeżeli chcesz korzystać ze wsparcia GPU (na tym laboratorium nie będzie potrzebne, na kolejnych może przyspieszyć nieco obliczenia), to musi być to odpowiednio nowa karta NVidii, mająca CUDA compatibility ([lista](https://developer.nvidia.com/cuda-gpus)). Poza PyTorchem będzie potrzebne narzędzie NVidia CUDA w wersji 11.6 lub 11.7. Instalacja na Windowsie jest bardzo prosta (wystarczy ściągnąć plik EXE i zainstalować jak każdy inny program). Instalacja na Linuxie jest trudna i można względnie łatwo zepsuć sobie system, ale jeżeli chcesz spróbować, to [ten tutorial](https://www.youtube.com/results?search_query=nvidia+cuda+install+ubuntu+20.04) jest bardzo dobry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for conda users\n",
    "!conda install -y matplotlib pandas pytorch torchvision torchaudio -c pytorch -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Othm3C2lLAsj"
   },
   "source": [
    "## Wprowadzenie\n",
    "\n",
    "Zanim zaczniemy naszą przygodę z sieciami neuronowymi, przyjrzyjmy się prostemu przykładowi regresji liniowej na syntetycznych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rnJsfxbnLAsj"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "EaYpEXzBLAsl",
    "outputId": "2f8d2922-72f0-4d38-8548-d1262adf522e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe7bce30160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = x + np.random.normal(scale=0.1, size=x.shape)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEM_-yKELAsl"
   },
   "source": [
    "W przeciwieństwie do laboratorium 1, tym razem będziemy chcieli rozwiązać ten problem własnoręcznie, bez użycia wysokopoziomowego interfejsu Scikit-learn'a. W tym celu musimy sobie przypomnieć sformułowanie naszego **problemu optymalizacyjnego (optimization problem)**.\n",
    "\n",
    "W przypadku prostej regresji liniowej (1 zmienna) mamy model postaci $\\hat{y} = \\alpha x + \\beta$, z dwoma parametrami, których będziemy się uczyć. Miarą niedopasowania modelu o danych parametrach jest **funkcja kosztu (cost function)**, nazywana też funkcją celu. Najczęściej używa się **błędu średniokwadratowego (mean squared error, MSE)**:\n",
    "$$\\large\n",
    "MSE = \\frac{1}{N} \\sum_{i}^{N} (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "Od jakich $\\alpha$ i $\\beta$ zacząć? W najprostszym wypadku wystarczy po prostu je wylosować jako niewielkie liczby zmiennoprzecinkowe.\n",
    "\n",
    "#### Zadanie 1 (0.5 punkt)\n",
    "\n",
    "Uzupełnij kod funkcji `mse`, obliczającej błąd średniokwadratowy. Wykorzystaj Numpy'a w celu wektoryzacji obliczeń dla wydajności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaA7Q46TLAsm",
    "outputId": "5c57fe58-1934-4d21-9a7b-d14e9a23140b"
   },
   "outputs": [],
   "source": [
    "def mse(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    return np.mean((y-y_hat)**2)\n",
    "    # implement me!\n",
    "#     raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "qSGfamGbLAsm",
    "outputId": "733ce15f-ae75-466b-e7ee-eb3c9d9d534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe7b4d3d400>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand()\n",
    "b = np.random.rand()\n",
    "print(f\"MSE: {mse(y, a * x + b):.3f}\")\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y--E9Mp9LAsn"
   },
   "source": [
    "Losowe parametry radzą sobie nie najlepiej. Jak lepiej dopasować naszą prostą do danych? Zawsze możemy starać się wyprowadzić rozwiązanie analitycznie, i w tym wypadku nawet nam się uda. Jest to jednak szczególny i dość rzadki przypadek, a w szczególności nie będzie to możliwe w większych sieciach neuronowych.\n",
    "\n",
    "Potrzebna nam będzie **metoda optymalizacji (optimization method)**, dającą wartości parametrów minimalizujące dowolną różniczkowalną funkcję kosztu. Zdecydowanie najpopularniejszy jest tutaj **spadek wzdłuż gradientu (gradient descent)**.\n",
    "\n",
    "Metoda ta wywodzi się z prostych obserwacji, które tutaj przedstawimy. Bardziej szczegółowe rozwinięcie dla zainteresowanych: [sekcja 4.3 \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/numerical.html), [ten praktyczny kurs](https://cs231n.github.io/optimization-1/), [analiza oryginalnej publikacji Cauchy'ego](https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf) (oryginał w języku francuskim).\n",
    "\n",
    "Pochodna jest dokładnie równa granicy funkcji. Dla małego $\\epsilon$ można ją przybliżyć jako:\n",
    "$$\\large\n",
    "\\frac{f(x)}{dx} \\approx \\frac{f(x) - f(x+\\epsilon)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "Przyglądając się temu równaniu widzimy, że: \n",
    "* dla funkcji rosnącej ($f(x+\\epsilon) > f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak ujemny \n",
    "* dla funkcji malejącej ($f(x+\\epsilon) < f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak dodatni \n",
    "\n",
    "Widzimy więc, że potrafimy wskazać kierunek zmniejszenia wartości funkcji, patrząc na znak pochodnej. Zaobserwowano także, że amplituda wartości w $\\frac{f(x)}{dx}$ jest tym większa, im dalej jesteśmy od minimum (maximum). Pochodna wyznacza więc, w jakim kierunku funkcja najszybciej rośnie, więc kierunek o przeciwnym zwrocie to kierunek, w którym funkcja najszybciej spada.\n",
    "\n",
    "Stosując powyższe do optymalizacji, mamy:\n",
    "$$\\large\n",
    "x_{t+1} = x_{t} -  \\alpha * \\frac{f(x)}{dx}\n",
    "$$\n",
    "\n",
    "$\\alpha$ to niewielka wartość (rzędu zwykle $10^{-5}$ - $10^{-2}$), wprowadzona, aby trzymać się założenia o małej zmianie parametrów ($\\epsilon$). Nazywa się ją **stałą uczącą (learning rate)** i jest zwykle najważniejszym hiperparametrem podczas nauki sieci.\n",
    "\n",
    "Metoda ta zakłada, że używamy całego zbioru danych do aktualizacji parametrów w każdym kroku, co nazywa się po prostu GD (od *gradient descent*) albo *full batch GD*. Wtedy każdy krok optymalizacji nazywa się **epoką (epoch)**.\n",
    "\n",
    "Im większa stała ucząca, tym większe nasze kroki podczas minimalizacji. Możemy więc uczyć szybciej, ale istnieje ryzyko, że będziemy \"przeskakiwać\" minima. Mniejsza stała ucząca to wolniejszy trening, ale dokładniejszy. Można także zmieniać ją podczas treningu, co nazywa się **learning rate scheduling (LR scheduling)**. Obrazowo:\n",
    "\n",
    "![learning_rate](http://www.bdhammel.com/assets/learning-rate/lr-types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "496qEjkVLAso"
   },
   "source": [
    "![interactive LR](http://cdn-images-1.medium.com/max/640/1*eeIvlwkMNG1wSmj3FR6M2g.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYkyAHKzLAsp"
   },
   "source": [
    "Policzmy więc pochodną dla naszej funkcji kosztu MSE. Pochodną liczymy po predykcjach naszego modelu, czyli de facto po jego parametrach, bo to od nich zależą predykcje.\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} \\hat{y}} = -2 \\cdot \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i) = -2 \\cdot \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (ax + b))\n",
    "$$\n",
    "\n",
    "Musimy jeszcze się dowiedzieć, jak zaktualizować każdy z naszych parametrów. Możemy wykorzystać tutaj regułę łańcuchową (*chain rule*) i policzyć ponownie pochodną, tylko że po naszych parametrach. Dzięki temu dostajemy informację, jak każdy z parametrów wpływa na funkcję kosztu i jak zmodyfikować każdy z nich w kolejnym kroku.\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y}}{\\text{d} a} = x\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y}}{\\text{d} b} = 1\n",
    "$$\n",
    "\n",
    "Pełna aktualizacja to zatem:\n",
    "$$\\large\n",
    "a' = a + \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) * (-x) \\right)\n",
    "$$\n",
    "$$\\large\n",
    "b' = b + \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) * (-1) \\right)\n",
    "$$\n",
    "\n",
    "Liczymy więc pochodną funkcji kosztu, a potem za pomocą reguły łańcuchowej \"cofamy się\", dochodząc do tego, jak każdy z parametrów wpływa na błąd i w jaki sposób powinniśmy go zmienić. Nazywa się to **propagacją wsteczną (backpropagation)** i jest podstawowym mechanizmem umożliwiającym naukę sieci neuronowych za pomocą spadku wzdłuż gradientu. Więcej możesz o tym przeczytać [tutaj](https://cs231n.github.io/optimization-2/).\n",
    "\n",
    "Obliczenie pochodnych cząstkowych ze względu na każdy \n",
    "\n",
    "\n",
    "#### Zadanie 2 (1.5 punkty)\n",
    "\n",
    "Zaimplementuj funkcję realizującą jedną epokę treningową. Oblicz predykcję przy aktualnych parametrach oraz zaktualizuj je zgodnie z powyższymi wzorami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qbdWOSULAsp",
    "outputId": "055607ae-87aa-470a-e6da-25682c82d470"
   },
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    x: np.ndarray, y: np.ndarray, a: float, b: float, learning_rate: float = 0.1\n",
    "):\n",
    "    y_hat = a * x + b\n",
    "    errors = y - y_hat\n",
    "    # implement me!\n",
    "#     raise NotImplementedError\n",
    "    new_a = a + learning_rate*(-2)*np.mean((y-y_hat)*(-x))\n",
    "    new_b = b + learning_rate*(-2)*np.mean((y-y_hat)*(-1))\n",
    "\n",
    "    return new_a, new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  0.1330225119404028\n",
      "step 100 loss:  0.012673197778527677\n",
      "step 200 loss:  0.010257153540857817\n",
      "step 300 loss:  0.0100948037549359\n",
      "step 400 loss:  0.010083894412889118\n",
      "step 500 loss:  0.010083161342973332\n",
      "step 600 loss:  0.010083112083219709\n",
      "step 700 loss:  0.010083108773135261\n",
      "step 800 loss:  0.010083108550709076\n",
      "step 900 loss:  0.01008310853576281\n",
      "final loss: 0.010083108534760455\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "    a, b = optimize(x, y, a, b)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "xOgRcPC1LAsq",
    "outputId": "85b0b3e4-aa0d-467a-d8ff-5f01be17b243",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe7b4cb2340>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOr2fWYpLAsq"
   },
   "source": [
    "Udało ci się wytrenować swoją pierwszą sieć neuronową. Czemu? Otóż neuron to po prostu wektor parametrów, a zwykle robimy iloczyn skalarny tych parametrów z wejściem. Dodatkowo na wyjście nakłada się **funkcję aktywacji (activation function)**, która przekształca wyjście. Tutaj takiej nie było, a właściwie była to po prostu funkcja identyczności.\n",
    "\n",
    "Oczywiście w praktyce korzystamy z odpowiedniego frameworka, który w szczególności:\n",
    "- ułatwia budowanie sieci, np. ma gotowe klasy dla warstw neuronów\n",
    "- ma zaimplementowane funkcje kosztu oraz ich pochodne\n",
    "- sam różniczkuje ze względu na odpowiednie parametry i aktualizuje je odpowiednio podczas treningu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJBYJabuLAsr"
   },
   "source": [
    "## Wprowadzenie do PyTorcha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB-99XqhLAsr"
   },
   "source": [
    "PyTorch to w gruncie rzeczy narzędzie do algebry liniowej z [automatycznym rożniczkowaniem](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html), z możliwością przyspieszenia obliczeń z pomocą GPU. Na tych fundamentach zbudowany jest pełny framework do uczenia głębokiego. Można spotkać się ze stwierdzenie, że PyTorch to NumPy + GPU + opcjonalne różniczkowanie, co jest całkiem celne. Plus można łatwo debugować printem :)\n",
    "\n",
    "PyTorch używa dynamicznego grafu obliczeń, który sami definiujemy w kodzie. Takie podejście jest bardzo wygodne, elastyczne i pozwala na łatwe eksperymentowanie. Odbywa się to potencjalnie kosztem wydajności, ponieważ pozostawia kwestię optymalizacji programiście. Więcej na ten temat dla zainteresowanych na końcu laboratorium.\n",
    "\n",
    "Samo API PyTorcha bardzo przypomina Numpy'a, a podstawowym obiektem jest `Tensor`, klasa reprezentująca tensory dowolnego wymiaru. Dodatkowo niektóre tensory będą miały automatycznie obliczony gradient. Co ważne, tensor jest na pewnym urządzeniu, CPU lub GPU, a przenosić między nimi trzeba explicite.\n",
    "\n",
    "Najważniejsze moduły:\n",
    "- `torch` - podstawowe klasy oraz funkcje, np. `Tensor`, `from_numpy()`\n",
    "- `torch.nn` - klasy związane z sieciami neuronowymi, np. `Linear`, `Sigmoid`\n",
    "- `torch.optim` - wszystko związane z optymalizacją, głównie spadkiem wzdłuż gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FwuIt8S-LAss",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfCiUFXULAss",
    "outputId": "83f6231d-ecc4-461a-b758-fdc4bc2a88a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4271, 1.4452, 1.1610, 1.3431, 1.5855, 1.2538, 1.8293, 1.0477, 1.7595,\n",
      "        1.1884])\n",
      "tensor([0.4271, 0.4452, 0.1610, 0.3431, 0.5855, 0.2538, 0.8293, 0.0477, 0.7595,\n",
      "        0.1884])\n",
      "tensor(4.0406)\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(10)\n",
    "noise = torch.ones(10) * torch.rand(10)\n",
    "\n",
    "# elementwise sum\n",
    "print(ones + noise)\n",
    "\n",
    "# elementwise multiplication\n",
    "print(ones * noise)\n",
    "\n",
    "# dot product\n",
    "print(ones @ noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ynNd_kD0LAst"
   },
   "outputs": [],
   "source": [
    "# beware - shares memory with original Numpy array!\n",
    "# very fast, but modifications are visible to original variable\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9kkxczELAsu"
   },
   "source": [
    "Jeżeli dla stworzonych przez nas tensorów chcemy śledzić operacje i obliczać gradient, to musimy oznaczyć `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HtZL-KfLAsu",
    "outputId": "47c6d930-5678-452a-95bc-227935138b40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2835], requires_grad=True), tensor([0.3490], requires_grad=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl1guWZ_LAsv"
   },
   "source": [
    "PyTorch zawiera większość powszechnie używanych funkcji kosztu, np. MSE. Mogą być one używane na 2 sposoby, z czego pierwszy jest popularniejszy:\n",
    "- jako klasy wywoływalne z modułu `torch.nn`\n",
    "- jako funkcje z modułu `torch.nn.functional`\n",
    "\n",
    "Po wykonaniu poniższego kodu widzimy, że zwraca on nam tensor z dodatkowymi atrybutami. Co ważne, jest to skalar (0-wymiarowy tensor), bo potrzebujemy zwyczajnej liczby do obliczania propagacji wstecznych (pochodnych czątkowych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0504, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(y, a * x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS35r49nLAsw"
   },
   "source": [
    "Atrybutu `grad_fn` nie używamy wprost, bo korzysta z niego w środku PyTorch, ale widać, że tensor jest \"świadomy\", że liczy się na nim pochodną. Możemy natomiast skorzystać z atrybutu `grad`, który zawiera faktyczny gradient. Zanim go jednak dostaniemy, to trzeba powiedzieć PyTorchowi, żeby policzył gradient. Służy do tego metoda `.backward()`, wywoływana na obiekcie zwracanym przez funkcję kosztu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Qb7l6Xg1LAsx"
   },
   "outputs": [],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LfQbLVoLAsx",
    "outputId": "d5b87fb7-d284-423c-f467-b677384b2f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1321])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kdf1iweELAsy"
   },
   "source": [
    "Ważne jest, że PyTorch nie liczy za każdym razem nowego gradientu, tylko dodaje go do istniejącego, czyli go akumuluje. Jest to przydatne w niektórych sieciach neuronowych, ale zazwyczaj trzeba go zerować. Jeżeli tego nie zrobimy, to dostaniemy coraz większe gradienty.\n",
    "\n",
    "Do zerowania służy metoda `.zero_()`. W PyTorchu wszystkie metody modyfikujące tensor w miejscu mają `_` na końcu nazwy. Jest to dość niskopoziomowa operacja dla pojedynczych tensorów - zobaczymy za chwilę, jak to robić łatwiej dla całej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiCQZKJsLAsy",
    "outputId": "2f779622-480d-43fc-b9d0-a0e36ff4b28b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2641])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNC3Ag8uLAsz"
   },
   "source": [
    "Zobaczmy, jak wyglądałaby regresja liniowa, ale napisana w PyTorchu. Jest to oczywiście bardzo niskopoziomowa implementacja - za chwilę zobaczymy, jak to wygląda w praktyce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKnxyeboLAsz",
    "outputId": "2f939474-901a-4773-9704-686a40ae6e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  tensor(0.0504, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 100 loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 200 loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 300 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 400 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 500 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 600 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 700 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 800 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 900 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    a.data -= learning_rate * a.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "\n",
    "    # zero gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DXNVhshmmI-"
   },
   "source": [
    "Trening modeli w PyTorchu jest dosyć schematyczny i najczęściej rozdziela się go na kilka bloków, dających razem **pętlę uczącą (training loop)**, powtarzaną w każdej epoce:\n",
    "1. Forward pass - obliczenie predykcji sieci\n",
    "2. Loss calculation\n",
    "3. Backpropagation - obliczenie pochodnych oraz zerowanie gradientów\n",
    "4. Optimalization - aktualizacja wag\n",
    "5. Other - ewaluacja na zbiorze walidacyjnym, logging etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2etpw7TNLAs0",
    "outputId": "8ac35c12-6c70-41ec-bf57-414456fc3c96",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss: 0.3638\n",
      "step 100 loss: 0.0146\n",
      "step 200 loss: 0.0104\n",
      "step 300 loss: 0.0101\n",
      "step 400 loss: 0.0101\n",
      "step 500 loss: 0.0101\n",
      "step 600 loss: 0.0101\n",
      "step 700 loss: 0.0101\n",
      "step 800 loss: 0.0101\n",
      "step 900 loss: 0.0101\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "learning_rate = 0.1\n",
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([a, b], lr=learning_rate)\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "# training loop in each epoch\n",
    "for i in range(1000):\n",
    "    # forward pass\n",
    "    y_hat = a * x + b\n",
    "\n",
    "    # loss calculation\n",
    "    loss = mse(y, y_hat)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # optimization\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()  # zeroes all gradients - very convenient!\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        if loss < best_loss:\n",
    "            best_model = (a.clone(), b.clone())\n",
    "            best_loss = loss\n",
    "        print(f\"step {i} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejdziemy teraz do budowy sieci neuronowej do klasyfikacji. Typowo implementuje się ją po prostu jako sieć dla regresji, ale zwracającą tyle wyników, ile mamy klas, a potem aplikuje się na tym funkcję sigmoidalną (2 klasy) lub softmax (>2 klasy). W przypadku klasyfikacji binarnej zwraca się czasem tylko 1 wartość, przepuszczaną przez sigmoidę - wtedy wyjście z sieci to prawdopodobieństwo klasy pozytywnej.\n",
    "\n",
    "Funkcją kosztu zwykle jest **entropia krzyżowa (cross-entropy)**, stosowana też w klasycznej regresji logistycznej. Co ważne, sieci neuronowe, nawet tak proste, uczą się szybciej i stabilniej, gdy dane na wejściu (a przynajmniej zmienne numeryczne) są **ustandaryzowane (standardized)**. Operacja ta polega na odjęciu średniej i podzieleniu przez odchylenie standardowe (tzw. *Z-score transformation*).\n",
    "\n",
    "**Uwaga - PyTorch wymaga tensora klas będącego liczbami zmiennoprzecinkowymi!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na tym laboratorium wykorzystamy zbiór [Adult Census](https://archive.ics.uci.edu/ml/datasets/adult). Dotyczy on przewidywania na podstawie danych demograficznych, czy dany człowiek zarabia powyżej 50 tysięcy dolarów miesięcznie, czy też mniej. Jest to cenna informacja np. przy planowaniu kampanii marketingowych. Jak możesz się domyślić, zbiór pochodzi z czasów, kiedy inflacja była dużo niższa :)\n",
    "\n",
    "Poniżej znajduje się kod do ściągnięcia i preprocessingu zbioru. Nie musisz go dokładnie analizować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DNsaZAnLAs0",
    "outputId": "70822008-530d-4173-deb9-8149a9fe5b41",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 23:51:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3974305 (3,8M) [application/x-httpd-php]\n",
      "Saving to: ‘adult.data’\n",
      "\n",
      "adult.data          100%[===================>]   3,79M  1,03MB/s    in 3,7s    \n",
      "\n",
      "2022-12-06 23:51:09 (1,03 MB/s) - ‘adult.data’ saved [3974305/3974305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"wage\"\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "age: continuous.\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous.\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "sex: Female, Male.\n",
    "capital-gain: continuous.\n",
    "capital-loss: continuous.\n",
    "hours-per-week: continuous.\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"adult.data\", header=None, names=columns)\n",
    "df.wage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribution: https://www.kaggle.com/code/royshih23/topic7-classification-in-python\n",
    "df['education'].replace('Preschool', 'dropout',inplace=True)\n",
    "df['education'].replace('10th', 'dropout',inplace=True)\n",
    "df['education'].replace('11th', 'dropout',inplace=True)\n",
    "df['education'].replace('12th', 'dropout',inplace=True)\n",
    "df['education'].replace('1st-4th', 'dropout',inplace=True)\n",
    "df['education'].replace('5th-6th', 'dropout',inplace=True)\n",
    "df['education'].replace('7th-8th', 'dropout',inplace=True)\n",
    "df['education'].replace('9th', 'dropout',inplace=True)\n",
    "df['education'].replace('HS-Grad', 'HighGrad',inplace=True)\n",
    "df['education'].replace('HS-grad', 'HighGrad',inplace=True)\n",
    "df['education'].replace('Some-college', 'CommunityCollege',inplace=True)\n",
    "df['education'].replace('Assoc-acdm', 'CommunityCollege',inplace=True)\n",
    "df['education'].replace('Assoc-voc', 'CommunityCollege',inplace=True)\n",
    "df['education'].replace('Bachelors', 'Bachelors',inplace=True)\n",
    "df['education'].replace('Masters', 'Masters',inplace=True)\n",
    "df['education'].replace('Prof-school', 'Masters',inplace=True)\n",
    "df['education'].replace('Doctorate', 'Doctorate',inplace=True)\n",
    "\n",
    "df['marital-status'].replace('Never-married', 'NotMarried',inplace=True)\n",
    "df['marital-status'].replace(['Married-AF-spouse'], 'Married',inplace=True)\n",
    "df['marital-status'].replace(['Married-civ-spouse'], 'Married',inplace=True)\n",
    "df['marital-status'].replace(['Married-spouse-absent'], 'NotMarried',inplace=True)\n",
    "df['marital-status'].replace(['Separated'], 'Separated',inplace=True)\n",
    "df['marital-status'].replace(['Divorced'], 'Separated',inplace=True)\n",
    "df['marital-status'].replace(['Widowed'], 'Widowed',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiOxs_6mLAs1",
    "outputId": "c95418cf-2632-41d0-de0a-9caf109de113",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20838, 108), (20838,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "\n",
    "X = df.copy()\n",
    "y = (X.pop(\"wage\") == ' >50K').astype(int).values\n",
    "\n",
    "train_valid_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=train_valid_size, \n",
    "    random_state=0, \n",
    "    shuffle=True, \n",
    "    stratify=y\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=train_valid_size, \n",
    "    random_state=0, \n",
    "    shuffle=True, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "continuous_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "continuous_X_train = X_train[continuous_cols]\n",
    "categorical_X_train = X_train.loc[:, ~X_train.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_valid = X_valid[continuous_cols]\n",
    "categorical_X_valid = X_valid.loc[:, ~X_valid.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_test = X_test[continuous_cols]\n",
    "categorical_X_test = X_test.loc[:, ~X_test.columns.isin(continuous_cols)]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "continuous_scaler = StandardScaler() #MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "categorical_encoder.fit(categorical_X_train)\n",
    "continuous_scaler.fit(continuous_X_train)\n",
    "\n",
    "continuous_X_train = continuous_scaler.transform(continuous_X_train)\n",
    "continuous_X_valid = continuous_scaler.transform(continuous_X_valid)\n",
    "continuous_X_test = continuous_scaler.transform(continuous_X_test)\n",
    "\n",
    "categorical_X_train = categorical_encoder.transform(categorical_X_train)\n",
    "categorical_X_valid = categorical_encoder.transform(categorical_X_valid)\n",
    "categorical_X_test = categorical_encoder.transform(categorical_X_test)\n",
    "\n",
    "X_train = np.concatenate([continuous_X_train, categorical_X_train], axis=1)\n",
    "X_valid = np.concatenate([continuous_X_valid, categorical_X_valid], axis=1)\n",
    "X_test = np.concatenate([continuous_X_test, categorical_X_test], axis=1)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga co do typów - PyTorchu wszystko w sieci neuronowej musi być typu `float32`. W szczególności trzeba uważać na konwersje z Numpy'a, który używa domyślnie typu `float64`. Może ci się przydać metoda `.float()`.\n",
    "\n",
    "Uwaga co do kształtów wyjścia - wejścia do `nn.BCELoss` muszą być tego samego kształtu. Może ci się przydać metoda `.squeeze()` lub `.unsqueeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qfRA3xEoLAs1"
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float().unsqueeze(-1)\n",
    "\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "y_valid = torch.from_numpy(y_valid).float().unsqueeze(-1)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie jak w laboratorium 2, mamy tu do czynienia z klasyfikacją niezbalansowaną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pos_perc = 100 * y_train.sum().item() / len(y_train)\n",
    "y_neg_perc = 100 - y_pos_perc\n",
    "\n",
    "plt.title(\"Class percentages\")\n",
    "plt.bar([\"<50k\", \">=50k\"], [y_neg_perc, y_pos_perc])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W związku z powyższym będziemy używać odpowiednich metryk, czyli AUROC, precyzji i czułości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLexWff-LAs0"
   },
   "source": [
    "#### Zadanie 3 (1 punkt)\n",
    "\n",
    "Zaimplementuj regresję logistyczną dla tego zbioru danych, używając PyTorcha. Dane wejściowe zostały dla ciebie przygotowane w komórkach poniżej.\n",
    "\n",
    "Sama sieć składa się z 2 elementów:\n",
    "- warstwa liniowa `nn.Linear`, przekształcająca wektor wejściowy na 1 wyjście - logit\n",
    "- aktywacja sigmoidalna `nn.Sigmoid`, przekształcająca logit na prawdopodobieństwo klasy pozytywnej\n",
    "\n",
    "Użyj binarnej entropii krzyżowej `nn.BCELoss` jako funkcji kosztu. Użyj optymalizatora SGD ze stałą uczącą `1e-3`. Trenuj przez 3000 epok. Pamiętaj, aby przekazać do optymalizatora `torch.optim.SGD` parametry sieci (metoda `.parameters()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbABKz5-LAs2",
    "outputId": "086dc0f3-0184-4072-9fd3-275b60dee2e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.7428\n",
      "epoch: 1, loss: 0.7423\n",
      "epoch: 2, loss: 0.7419\n",
      "epoch: 3, loss: 0.7415\n",
      "epoch: 4, loss: 0.7411\n",
      "epoch: 5, loss: 0.7407\n",
      "epoch: 6, loss: 0.7403\n",
      "epoch: 7, loss: 0.7399\n",
      "epoch: 8, loss: 0.7394\n",
      "epoch: 9, loss: 0.7390\n",
      "epoch: 10, loss: 0.7386\n",
      "epoch: 11, loss: 0.7382\n",
      "epoch: 12, loss: 0.7378\n",
      "epoch: 13, loss: 0.7374\n",
      "epoch: 14, loss: 0.7370\n",
      "epoch: 15, loss: 0.7366\n",
      "epoch: 16, loss: 0.7362\n",
      "epoch: 17, loss: 0.7358\n",
      "epoch: 18, loss: 0.7353\n",
      "epoch: 19, loss: 0.7349\n",
      "epoch: 20, loss: 0.7345\n",
      "epoch: 21, loss: 0.7341\n",
      "epoch: 22, loss: 0.7337\n",
      "epoch: 23, loss: 0.7333\n",
      "epoch: 24, loss: 0.7329\n",
      "epoch: 25, loss: 0.7325\n",
      "epoch: 26, loss: 0.7321\n",
      "epoch: 27, loss: 0.7317\n",
      "epoch: 28, loss: 0.7313\n",
      "epoch: 29, loss: 0.7309\n",
      "epoch: 30, loss: 0.7305\n",
      "epoch: 31, loss: 0.7301\n",
      "epoch: 32, loss: 0.7297\n",
      "epoch: 33, loss: 0.7294\n",
      "epoch: 34, loss: 0.7290\n",
      "epoch: 35, loss: 0.7286\n",
      "epoch: 36, loss: 0.7282\n",
      "epoch: 37, loss: 0.7278\n",
      "epoch: 38, loss: 0.7274\n",
      "epoch: 39, loss: 0.7270\n",
      "epoch: 40, loss: 0.7266\n",
      "epoch: 41, loss: 0.7262\n",
      "epoch: 42, loss: 0.7258\n",
      "epoch: 43, loss: 0.7254\n",
      "epoch: 44, loss: 0.7251\n",
      "epoch: 45, loss: 0.7247\n",
      "epoch: 46, loss: 0.7243\n",
      "epoch: 47, loss: 0.7239\n",
      "epoch: 48, loss: 0.7235\n",
      "epoch: 49, loss: 0.7231\n",
      "epoch: 50, loss: 0.7228\n",
      "epoch: 51, loss: 0.7224\n",
      "epoch: 52, loss: 0.7220\n",
      "epoch: 53, loss: 0.7216\n",
      "epoch: 54, loss: 0.7212\n",
      "epoch: 55, loss: 0.7208\n",
      "epoch: 56, loss: 0.7205\n",
      "epoch: 57, loss: 0.7201\n",
      "epoch: 58, loss: 0.7197\n",
      "epoch: 59, loss: 0.7193\n",
      "epoch: 60, loss: 0.7190\n",
      "epoch: 61, loss: 0.7186\n",
      "epoch: 62, loss: 0.7182\n",
      "epoch: 63, loss: 0.7178\n",
      "epoch: 64, loss: 0.7175\n",
      "epoch: 65, loss: 0.7171\n",
      "epoch: 66, loss: 0.7167\n",
      "epoch: 67, loss: 0.7164\n",
      "epoch: 68, loss: 0.7160\n",
      "epoch: 69, loss: 0.7156\n",
      "epoch: 70, loss: 0.7152\n",
      "epoch: 71, loss: 0.7149\n",
      "epoch: 72, loss: 0.7145\n",
      "epoch: 73, loss: 0.7141\n",
      "epoch: 74, loss: 0.7138\n",
      "epoch: 75, loss: 0.7134\n",
      "epoch: 76, loss: 0.7130\n",
      "epoch: 77, loss: 0.7127\n",
      "epoch: 78, loss: 0.7123\n",
      "epoch: 79, loss: 0.7120\n",
      "epoch: 80, loss: 0.7116\n",
      "epoch: 81, loss: 0.7112\n",
      "epoch: 82, loss: 0.7109\n",
      "epoch: 83, loss: 0.7105\n",
      "epoch: 84, loss: 0.7101\n",
      "epoch: 85, loss: 0.7098\n",
      "epoch: 86, loss: 0.7094\n",
      "epoch: 87, loss: 0.7091\n",
      "epoch: 88, loss: 0.7087\n",
      "epoch: 89, loss: 0.7084\n",
      "epoch: 90, loss: 0.7080\n",
      "epoch: 91, loss: 0.7076\n",
      "epoch: 92, loss: 0.7073\n",
      "epoch: 93, loss: 0.7069\n",
      "epoch: 94, loss: 0.7066\n",
      "epoch: 95, loss: 0.7062\n",
      "epoch: 96, loss: 0.7059\n",
      "epoch: 97, loss: 0.7055\n",
      "epoch: 98, loss: 0.7052\n",
      "epoch: 99, loss: 0.7048\n",
      "epoch: 100, loss: 0.7045\n",
      "epoch: 101, loss: 0.7041\n",
      "epoch: 102, loss: 0.7038\n",
      "epoch: 103, loss: 0.7034\n",
      "epoch: 104, loss: 0.7031\n",
      "epoch: 105, loss: 0.7027\n",
      "epoch: 106, loss: 0.7024\n",
      "epoch: 107, loss: 0.7020\n",
      "epoch: 108, loss: 0.7017\n",
      "epoch: 109, loss: 0.7014\n",
      "epoch: 110, loss: 0.7010\n",
      "epoch: 111, loss: 0.7007\n",
      "epoch: 112, loss: 0.7003\n",
      "epoch: 113, loss: 0.7000\n",
      "epoch: 114, loss: 0.6997\n",
      "epoch: 115, loss: 0.6993\n",
      "epoch: 116, loss: 0.6990\n",
      "epoch: 117, loss: 0.6986\n",
      "epoch: 118, loss: 0.6983\n",
      "epoch: 119, loss: 0.6980\n",
      "epoch: 120, loss: 0.6976\n",
      "epoch: 121, loss: 0.6973\n",
      "epoch: 122, loss: 0.6969\n",
      "epoch: 123, loss: 0.6966\n",
      "epoch: 124, loss: 0.6963\n",
      "epoch: 125, loss: 0.6959\n",
      "epoch: 126, loss: 0.6956\n",
      "epoch: 127, loss: 0.6953\n",
      "epoch: 128, loss: 0.6949\n",
      "epoch: 129, loss: 0.6946\n",
      "epoch: 130, loss: 0.6943\n",
      "epoch: 131, loss: 0.6939\n",
      "epoch: 132, loss: 0.6936\n",
      "epoch: 133, loss: 0.6933\n",
      "epoch: 134, loss: 0.6930\n",
      "epoch: 135, loss: 0.6926\n",
      "epoch: 136, loss: 0.6923\n",
      "epoch: 137, loss: 0.6920\n",
      "epoch: 138, loss: 0.6916\n",
      "epoch: 139, loss: 0.6913\n",
      "epoch: 140, loss: 0.6910\n",
      "epoch: 141, loss: 0.6907\n",
      "epoch: 142, loss: 0.6903\n",
      "epoch: 143, loss: 0.6900\n",
      "epoch: 144, loss: 0.6897\n",
      "epoch: 145, loss: 0.6894\n",
      "epoch: 146, loss: 0.6891\n",
      "epoch: 147, loss: 0.6887\n",
      "epoch: 148, loss: 0.6884\n",
      "epoch: 149, loss: 0.6881\n",
      "epoch: 150, loss: 0.6878\n",
      "epoch: 151, loss: 0.6875\n",
      "epoch: 152, loss: 0.6871\n",
      "epoch: 153, loss: 0.6868\n",
      "epoch: 154, loss: 0.6865\n",
      "epoch: 155, loss: 0.6862\n",
      "epoch: 156, loss: 0.6859\n",
      "epoch: 157, loss: 0.6856\n",
      "epoch: 158, loss: 0.6852\n",
      "epoch: 159, loss: 0.6849\n",
      "epoch: 160, loss: 0.6846\n",
      "epoch: 161, loss: 0.6843\n",
      "epoch: 162, loss: 0.6840\n",
      "epoch: 163, loss: 0.6837\n",
      "epoch: 164, loss: 0.6834\n",
      "epoch: 165, loss: 0.6830\n",
      "epoch: 166, loss: 0.6827\n",
      "epoch: 167, loss: 0.6824\n",
      "epoch: 168, loss: 0.6821\n",
      "epoch: 169, loss: 0.6818\n",
      "epoch: 170, loss: 0.6815\n",
      "epoch: 171, loss: 0.6812\n",
      "epoch: 172, loss: 0.6809\n",
      "epoch: 173, loss: 0.6806\n",
      "epoch: 174, loss: 0.6803\n",
      "epoch: 175, loss: 0.6800\n",
      "epoch: 176, loss: 0.6797\n",
      "epoch: 177, loss: 0.6794\n",
      "epoch: 178, loss: 0.6790\n",
      "epoch: 179, loss: 0.6787\n",
      "epoch: 180, loss: 0.6784\n",
      "epoch: 181, loss: 0.6781\n",
      "epoch: 182, loss: 0.6778\n",
      "epoch: 183, loss: 0.6775\n",
      "epoch: 184, loss: 0.6772\n",
      "epoch: 185, loss: 0.6769\n",
      "epoch: 186, loss: 0.6766\n",
      "epoch: 187, loss: 0.6763\n",
      "epoch: 188, loss: 0.6760\n",
      "epoch: 189, loss: 0.6757\n",
      "epoch: 190, loss: 0.6754\n",
      "epoch: 191, loss: 0.6751\n",
      "epoch: 192, loss: 0.6748\n",
      "epoch: 193, loss: 0.6745\n",
      "epoch: 194, loss: 0.6742\n",
      "epoch: 195, loss: 0.6740\n",
      "epoch: 196, loss: 0.6737\n",
      "epoch: 197, loss: 0.6734\n",
      "epoch: 198, loss: 0.6731\n",
      "epoch: 199, loss: 0.6728\n",
      "epoch: 200, loss: 0.6725\n",
      "epoch: 201, loss: 0.6722\n",
      "epoch: 202, loss: 0.6719\n",
      "epoch: 203, loss: 0.6716\n",
      "epoch: 204, loss: 0.6713\n",
      "epoch: 205, loss: 0.6710\n",
      "epoch: 206, loss: 0.6707\n",
      "epoch: 207, loss: 0.6704\n",
      "epoch: 208, loss: 0.6702\n",
      "epoch: 209, loss: 0.6699\n",
      "epoch: 210, loss: 0.6696\n",
      "epoch: 211, loss: 0.6693\n",
      "epoch: 212, loss: 0.6690\n",
      "epoch: 213, loss: 0.6687\n",
      "epoch: 214, loss: 0.6684\n",
      "epoch: 215, loss: 0.6681\n",
      "epoch: 216, loss: 0.6679\n",
      "epoch: 217, loss: 0.6676\n",
      "epoch: 218, loss: 0.6673\n",
      "epoch: 219, loss: 0.6670\n",
      "epoch: 220, loss: 0.6667\n",
      "epoch: 221, loss: 0.6664\n",
      "epoch: 222, loss: 0.6662\n",
      "epoch: 223, loss: 0.6659\n",
      "epoch: 224, loss: 0.6656\n",
      "epoch: 225, loss: 0.6653\n",
      "epoch: 226, loss: 0.6650\n",
      "epoch: 227, loss: 0.6648\n",
      "epoch: 228, loss: 0.6645\n",
      "epoch: 229, loss: 0.6642\n",
      "epoch: 230, loss: 0.6639\n",
      "epoch: 231, loss: 0.6636\n",
      "epoch: 232, loss: 0.6634\n",
      "epoch: 233, loss: 0.6631\n",
      "epoch: 234, loss: 0.6628\n",
      "epoch: 235, loss: 0.6625\n",
      "epoch: 236, loss: 0.6623\n",
      "epoch: 237, loss: 0.6620\n",
      "epoch: 238, loss: 0.6617\n",
      "epoch: 239, loss: 0.6614\n",
      "epoch: 240, loss: 0.6612\n",
      "epoch: 241, loss: 0.6609\n",
      "epoch: 242, loss: 0.6606\n",
      "epoch: 243, loss: 0.6603\n",
      "epoch: 244, loss: 0.6601\n",
      "epoch: 245, loss: 0.6598\n",
      "epoch: 246, loss: 0.6595\n",
      "epoch: 247, loss: 0.6593\n",
      "epoch: 248, loss: 0.6590\n",
      "epoch: 249, loss: 0.6587\n",
      "epoch: 250, loss: 0.6585\n",
      "epoch: 251, loss: 0.6582\n",
      "epoch: 252, loss: 0.6579\n",
      "epoch: 253, loss: 0.6577\n",
      "epoch: 254, loss: 0.6574\n",
      "epoch: 255, loss: 0.6571\n",
      "epoch: 256, loss: 0.6569\n",
      "epoch: 257, loss: 0.6566\n",
      "epoch: 258, loss: 0.6563\n",
      "epoch: 259, loss: 0.6561\n",
      "epoch: 260, loss: 0.6558\n",
      "epoch: 261, loss: 0.6555\n",
      "epoch: 262, loss: 0.6553\n",
      "epoch: 263, loss: 0.6550\n",
      "epoch: 264, loss: 0.6547\n",
      "epoch: 265, loss: 0.6545\n",
      "epoch: 266, loss: 0.6542\n",
      "epoch: 267, loss: 0.6540\n",
      "epoch: 268, loss: 0.6537\n",
      "epoch: 269, loss: 0.6534\n",
      "epoch: 270, loss: 0.6532\n",
      "epoch: 271, loss: 0.6529\n",
      "epoch: 272, loss: 0.6527\n",
      "epoch: 273, loss: 0.6524\n",
      "epoch: 274, loss: 0.6521\n",
      "epoch: 275, loss: 0.6519\n",
      "epoch: 276, loss: 0.6516\n",
      "epoch: 277, loss: 0.6514\n",
      "epoch: 278, loss: 0.6511\n",
      "epoch: 279, loss: 0.6509\n",
      "epoch: 280, loss: 0.6506\n",
      "epoch: 281, loss: 0.6503\n",
      "epoch: 282, loss: 0.6501\n",
      "epoch: 283, loss: 0.6498\n",
      "epoch: 284, loss: 0.6496\n",
      "epoch: 285, loss: 0.6493\n",
      "epoch: 286, loss: 0.6491\n",
      "epoch: 287, loss: 0.6488\n",
      "epoch: 288, loss: 0.6486\n",
      "epoch: 289, loss: 0.6483\n",
      "epoch: 290, loss: 0.6481\n",
      "epoch: 291, loss: 0.6478\n",
      "epoch: 292, loss: 0.6476\n",
      "epoch: 293, loss: 0.6473\n",
      "epoch: 294, loss: 0.6471\n",
      "epoch: 295, loss: 0.6468\n",
      "epoch: 296, loss: 0.6466\n",
      "epoch: 297, loss: 0.6463\n",
      "epoch: 298, loss: 0.6461\n",
      "epoch: 299, loss: 0.6458\n",
      "epoch: 300, loss: 0.6456\n",
      "epoch: 301, loss: 0.6453\n",
      "epoch: 302, loss: 0.6451\n",
      "epoch: 303, loss: 0.6448\n",
      "epoch: 304, loss: 0.6446\n",
      "epoch: 305, loss: 0.6443\n",
      "epoch: 306, loss: 0.6441\n",
      "epoch: 307, loss: 0.6439\n",
      "epoch: 308, loss: 0.6436\n",
      "epoch: 309, loss: 0.6434\n",
      "epoch: 310, loss: 0.6431\n",
      "epoch: 311, loss: 0.6429\n",
      "epoch: 312, loss: 0.6426\n",
      "epoch: 313, loss: 0.6424\n",
      "epoch: 314, loss: 0.6422\n",
      "epoch: 315, loss: 0.6419\n",
      "epoch: 316, loss: 0.6417\n",
      "epoch: 317, loss: 0.6414\n",
      "epoch: 318, loss: 0.6412\n",
      "epoch: 319, loss: 0.6410\n",
      "epoch: 320, loss: 0.6407\n",
      "epoch: 321, loss: 0.6405\n",
      "epoch: 322, loss: 0.6402\n",
      "epoch: 323, loss: 0.6400\n",
      "epoch: 324, loss: 0.6398\n",
      "epoch: 325, loss: 0.6395\n",
      "epoch: 326, loss: 0.6393\n",
      "epoch: 327, loss: 0.6391\n",
      "epoch: 328, loss: 0.6388\n",
      "epoch: 329, loss: 0.6386\n",
      "epoch: 330, loss: 0.6383\n",
      "epoch: 331, loss: 0.6381\n",
      "epoch: 332, loss: 0.6379\n",
      "epoch: 333, loss: 0.6376\n",
      "epoch: 334, loss: 0.6374\n",
      "epoch: 335, loss: 0.6372\n",
      "epoch: 336, loss: 0.6369\n",
      "epoch: 337, loss: 0.6367\n",
      "epoch: 338, loss: 0.6365\n",
      "epoch: 339, loss: 0.6362\n",
      "epoch: 340, loss: 0.6360\n",
      "epoch: 341, loss: 0.6358\n",
      "epoch: 342, loss: 0.6356\n",
      "epoch: 343, loss: 0.6353\n",
      "epoch: 344, loss: 0.6351\n",
      "epoch: 345, loss: 0.6349\n",
      "epoch: 346, loss: 0.6346\n",
      "epoch: 347, loss: 0.6344\n",
      "epoch: 348, loss: 0.6342\n",
      "epoch: 349, loss: 0.6339\n",
      "epoch: 350, loss: 0.6337\n",
      "epoch: 351, loss: 0.6335\n",
      "epoch: 352, loss: 0.6333\n",
      "epoch: 353, loss: 0.6330\n",
      "epoch: 354, loss: 0.6328\n",
      "epoch: 355, loss: 0.6326\n",
      "epoch: 356, loss: 0.6324\n",
      "epoch: 357, loss: 0.6321\n",
      "epoch: 358, loss: 0.6319\n",
      "epoch: 359, loss: 0.6317\n",
      "epoch: 360, loss: 0.6315\n",
      "epoch: 361, loss: 0.6312\n",
      "epoch: 362, loss: 0.6310\n",
      "epoch: 363, loss: 0.6308\n",
      "epoch: 364, loss: 0.6306\n",
      "epoch: 365, loss: 0.6303\n",
      "epoch: 366, loss: 0.6301\n",
      "epoch: 367, loss: 0.6299\n",
      "epoch: 368, loss: 0.6297\n",
      "epoch: 369, loss: 0.6295\n",
      "epoch: 370, loss: 0.6292\n",
      "epoch: 371, loss: 0.6290\n",
      "epoch: 372, loss: 0.6288\n",
      "epoch: 373, loss: 0.6286\n",
      "epoch: 374, loss: 0.6284\n",
      "epoch: 375, loss: 0.6281\n",
      "epoch: 376, loss: 0.6279\n",
      "epoch: 377, loss: 0.6277\n",
      "epoch: 378, loss: 0.6275\n",
      "epoch: 379, loss: 0.6273\n",
      "epoch: 380, loss: 0.6271\n",
      "epoch: 381, loss: 0.6268\n",
      "epoch: 382, loss: 0.6266\n",
      "epoch: 383, loss: 0.6264\n",
      "epoch: 384, loss: 0.6262\n",
      "epoch: 385, loss: 0.6260\n",
      "epoch: 386, loss: 0.6258\n",
      "epoch: 387, loss: 0.6255\n",
      "epoch: 388, loss: 0.6253\n",
      "epoch: 389, loss: 0.6251\n",
      "epoch: 390, loss: 0.6249\n",
      "epoch: 391, loss: 0.6247\n",
      "epoch: 392, loss: 0.6245\n",
      "epoch: 393, loss: 0.6243\n",
      "epoch: 394, loss: 0.6241\n",
      "epoch: 395, loss: 0.6238\n",
      "epoch: 396, loss: 0.6236\n",
      "epoch: 397, loss: 0.6234\n",
      "epoch: 398, loss: 0.6232\n",
      "epoch: 399, loss: 0.6230\n",
      "epoch: 400, loss: 0.6228\n",
      "epoch: 401, loss: 0.6226\n",
      "epoch: 402, loss: 0.6224\n",
      "epoch: 403, loss: 0.6222\n",
      "epoch: 404, loss: 0.6219\n",
      "epoch: 405, loss: 0.6217\n",
      "epoch: 406, loss: 0.6215\n",
      "epoch: 407, loss: 0.6213\n",
      "epoch: 408, loss: 0.6211\n",
      "epoch: 409, loss: 0.6209\n",
      "epoch: 410, loss: 0.6207\n",
      "epoch: 411, loss: 0.6205\n",
      "epoch: 412, loss: 0.6203\n",
      "epoch: 413, loss: 0.6201\n",
      "epoch: 414, loss: 0.6199\n",
      "epoch: 415, loss: 0.6197\n",
      "epoch: 416, loss: 0.6195\n",
      "epoch: 417, loss: 0.6193\n",
      "epoch: 418, loss: 0.6191\n",
      "epoch: 419, loss: 0.6189\n",
      "epoch: 420, loss: 0.6187\n",
      "epoch: 421, loss: 0.6184\n",
      "epoch: 422, loss: 0.6182\n",
      "epoch: 423, loss: 0.6180\n",
      "epoch: 424, loss: 0.6178\n",
      "epoch: 425, loss: 0.6176\n",
      "epoch: 426, loss: 0.6174\n",
      "epoch: 427, loss: 0.6172\n",
      "epoch: 428, loss: 0.6170\n",
      "epoch: 429, loss: 0.6168\n",
      "epoch: 430, loss: 0.6166\n",
      "epoch: 431, loss: 0.6164\n",
      "epoch: 432, loss: 0.6162\n",
      "epoch: 433, loss: 0.6160\n",
      "epoch: 434, loss: 0.6158\n",
      "epoch: 435, loss: 0.6156\n",
      "epoch: 436, loss: 0.6154\n",
      "epoch: 437, loss: 0.6152\n",
      "epoch: 438, loss: 0.6150\n",
      "epoch: 439, loss: 0.6148\n",
      "epoch: 440, loss: 0.6146\n",
      "epoch: 441, loss: 0.6144\n",
      "epoch: 442, loss: 0.6142\n",
      "epoch: 443, loss: 0.6141\n",
      "epoch: 444, loss: 0.6139\n",
      "epoch: 445, loss: 0.6137\n",
      "epoch: 446, loss: 0.6135\n",
      "epoch: 447, loss: 0.6133\n",
      "epoch: 448, loss: 0.6131\n",
      "epoch: 449, loss: 0.6129\n",
      "epoch: 450, loss: 0.6127\n",
      "epoch: 451, loss: 0.6125\n",
      "epoch: 452, loss: 0.6123\n",
      "epoch: 453, loss: 0.6121\n",
      "epoch: 454, loss: 0.6119\n",
      "epoch: 455, loss: 0.6117\n",
      "epoch: 456, loss: 0.6115\n",
      "epoch: 457, loss: 0.6113\n",
      "epoch: 458, loss: 0.6111\n",
      "epoch: 459, loss: 0.6109\n",
      "epoch: 460, loss: 0.6108\n",
      "epoch: 461, loss: 0.6106\n",
      "epoch: 462, loss: 0.6104\n",
      "epoch: 463, loss: 0.6102\n",
      "epoch: 464, loss: 0.6100\n",
      "epoch: 465, loss: 0.6098\n",
      "epoch: 466, loss: 0.6096\n",
      "epoch: 467, loss: 0.6094\n",
      "epoch: 468, loss: 0.6092\n",
      "epoch: 469, loss: 0.6090\n",
      "epoch: 470, loss: 0.6089\n",
      "epoch: 471, loss: 0.6087\n",
      "epoch: 472, loss: 0.6085\n",
      "epoch: 473, loss: 0.6083\n",
      "epoch: 474, loss: 0.6081\n",
      "epoch: 475, loss: 0.6079\n",
      "epoch: 476, loss: 0.6077\n",
      "epoch: 477, loss: 0.6075\n",
      "epoch: 478, loss: 0.6074\n",
      "epoch: 479, loss: 0.6072\n",
      "epoch: 480, loss: 0.6070\n",
      "epoch: 481, loss: 0.6068\n",
      "epoch: 482, loss: 0.6066\n",
      "epoch: 483, loss: 0.6064\n",
      "epoch: 484, loss: 0.6062\n",
      "epoch: 485, loss: 0.6061\n",
      "epoch: 486, loss: 0.6059\n",
      "epoch: 487, loss: 0.6057\n",
      "epoch: 488, loss: 0.6055\n",
      "epoch: 489, loss: 0.6053\n",
      "epoch: 490, loss: 0.6051\n",
      "epoch: 491, loss: 0.6050\n",
      "epoch: 492, loss: 0.6048\n",
      "epoch: 493, loss: 0.6046\n",
      "epoch: 494, loss: 0.6044\n",
      "epoch: 495, loss: 0.6042\n",
      "epoch: 496, loss: 0.6041\n",
      "epoch: 497, loss: 0.6039\n",
      "epoch: 498, loss: 0.6037\n",
      "epoch: 499, loss: 0.6035\n",
      "epoch: 500, loss: 0.6033\n",
      "epoch: 501, loss: 0.6031\n",
      "epoch: 502, loss: 0.6030\n",
      "epoch: 503, loss: 0.6028\n",
      "epoch: 504, loss: 0.6026\n",
      "epoch: 505, loss: 0.6024\n",
      "epoch: 506, loss: 0.6023\n",
      "epoch: 507, loss: 0.6021\n",
      "epoch: 508, loss: 0.6019\n",
      "epoch: 509, loss: 0.6017\n",
      "epoch: 510, loss: 0.6015\n",
      "epoch: 511, loss: 0.6014\n",
      "epoch: 512, loss: 0.6012\n",
      "epoch: 513, loss: 0.6010\n",
      "epoch: 514, loss: 0.6008\n",
      "epoch: 515, loss: 0.6007\n",
      "epoch: 516, loss: 0.6005\n",
      "epoch: 517, loss: 0.6003\n",
      "epoch: 518, loss: 0.6001\n",
      "epoch: 519, loss: 0.6000\n",
      "epoch: 520, loss: 0.5998\n",
      "epoch: 521, loss: 0.5996\n",
      "epoch: 522, loss: 0.5994\n",
      "epoch: 523, loss: 0.5993\n",
      "epoch: 524, loss: 0.5991\n",
      "epoch: 525, loss: 0.5989\n",
      "epoch: 526, loss: 0.5987\n",
      "epoch: 527, loss: 0.5986\n",
      "epoch: 528, loss: 0.5984\n",
      "epoch: 529, loss: 0.5982\n",
      "epoch: 530, loss: 0.5980\n",
      "epoch: 531, loss: 0.5979\n",
      "epoch: 532, loss: 0.5977\n",
      "epoch: 533, loss: 0.5975\n",
      "epoch: 534, loss: 0.5974\n",
      "epoch: 535, loss: 0.5972\n",
      "epoch: 536, loss: 0.5970\n",
      "epoch: 537, loss: 0.5968\n",
      "epoch: 538, loss: 0.5967\n",
      "epoch: 539, loss: 0.5965\n",
      "epoch: 540, loss: 0.5963\n",
      "epoch: 541, loss: 0.5962\n",
      "epoch: 542, loss: 0.5960\n",
      "epoch: 543, loss: 0.5958\n",
      "epoch: 544, loss: 0.5957\n",
      "epoch: 545, loss: 0.5955\n",
      "epoch: 546, loss: 0.5953\n",
      "epoch: 547, loss: 0.5951\n",
      "epoch: 548, loss: 0.5950\n",
      "epoch: 549, loss: 0.5948\n",
      "epoch: 550, loss: 0.5946\n",
      "epoch: 551, loss: 0.5945\n",
      "epoch: 552, loss: 0.5943\n",
      "epoch: 553, loss: 0.5941\n",
      "epoch: 554, loss: 0.5940\n",
      "epoch: 555, loss: 0.5938\n",
      "epoch: 556, loss: 0.5936\n",
      "epoch: 557, loss: 0.5935\n",
      "epoch: 558, loss: 0.5933\n",
      "epoch: 559, loss: 0.5931\n",
      "epoch: 560, loss: 0.5930\n",
      "epoch: 561, loss: 0.5928\n",
      "epoch: 562, loss: 0.5927\n",
      "epoch: 563, loss: 0.5925\n",
      "epoch: 564, loss: 0.5923\n",
      "epoch: 565, loss: 0.5922\n",
      "epoch: 566, loss: 0.5920\n",
      "epoch: 567, loss: 0.5918\n",
      "epoch: 568, loss: 0.5917\n",
      "epoch: 569, loss: 0.5915\n",
      "epoch: 570, loss: 0.5913\n",
      "epoch: 571, loss: 0.5912\n",
      "epoch: 572, loss: 0.5910\n",
      "epoch: 573, loss: 0.5909\n",
      "epoch: 574, loss: 0.5907\n",
      "epoch: 575, loss: 0.5905\n",
      "epoch: 576, loss: 0.5904\n",
      "epoch: 577, loss: 0.5902\n",
      "epoch: 578, loss: 0.5901\n",
      "epoch: 579, loss: 0.5899\n",
      "epoch: 580, loss: 0.5897\n",
      "epoch: 581, loss: 0.5896\n",
      "epoch: 582, loss: 0.5894\n",
      "epoch: 583, loss: 0.5893\n",
      "epoch: 584, loss: 0.5891\n",
      "epoch: 585, loss: 0.5889\n",
      "epoch: 586, loss: 0.5888\n",
      "epoch: 587, loss: 0.5886\n",
      "epoch: 588, loss: 0.5885\n",
      "epoch: 589, loss: 0.5883\n",
      "epoch: 590, loss: 0.5881\n",
      "epoch: 591, loss: 0.5880\n",
      "epoch: 592, loss: 0.5878\n",
      "epoch: 593, loss: 0.5877\n",
      "epoch: 594, loss: 0.5875\n",
      "epoch: 595, loss: 0.5874\n",
      "epoch: 596, loss: 0.5872\n",
      "epoch: 597, loss: 0.5870\n",
      "epoch: 598, loss: 0.5869\n",
      "epoch: 599, loss: 0.5867\n",
      "epoch: 600, loss: 0.5866\n",
      "epoch: 601, loss: 0.5864\n",
      "epoch: 602, loss: 0.5863\n",
      "epoch: 603, loss: 0.5861\n",
      "epoch: 604, loss: 0.5860\n",
      "epoch: 605, loss: 0.5858\n",
      "epoch: 606, loss: 0.5856\n",
      "epoch: 607, loss: 0.5855\n",
      "epoch: 608, loss: 0.5853\n",
      "epoch: 609, loss: 0.5852\n",
      "epoch: 610, loss: 0.5850\n",
      "epoch: 611, loss: 0.5849\n",
      "epoch: 612, loss: 0.5847\n",
      "epoch: 613, loss: 0.5846\n",
      "epoch: 614, loss: 0.5844\n",
      "epoch: 615, loss: 0.5843\n",
      "epoch: 616, loss: 0.5841\n",
      "epoch: 617, loss: 0.5840\n",
      "epoch: 618, loss: 0.5838\n",
      "epoch: 619, loss: 0.5837\n",
      "epoch: 620, loss: 0.5835\n",
      "epoch: 621, loss: 0.5833\n",
      "epoch: 622, loss: 0.5832\n",
      "epoch: 623, loss: 0.5830\n",
      "epoch: 624, loss: 0.5829\n",
      "epoch: 625, loss: 0.5827\n",
      "epoch: 626, loss: 0.5826\n",
      "epoch: 627, loss: 0.5824\n",
      "epoch: 628, loss: 0.5823\n",
      "epoch: 629, loss: 0.5821\n",
      "epoch: 630, loss: 0.5820\n",
      "epoch: 631, loss: 0.5818\n",
      "epoch: 632, loss: 0.5817\n",
      "epoch: 633, loss: 0.5815\n",
      "epoch: 634, loss: 0.5814\n",
      "epoch: 635, loss: 0.5813\n",
      "epoch: 636, loss: 0.5811\n",
      "epoch: 637, loss: 0.5810\n",
      "epoch: 638, loss: 0.5808\n",
      "epoch: 639, loss: 0.5807\n",
      "epoch: 640, loss: 0.5805\n",
      "epoch: 641, loss: 0.5804\n",
      "epoch: 642, loss: 0.5802\n",
      "epoch: 643, loss: 0.5801\n",
      "epoch: 644, loss: 0.5799\n",
      "epoch: 645, loss: 0.5798\n",
      "epoch: 646, loss: 0.5796\n",
      "epoch: 647, loss: 0.5795\n",
      "epoch: 648, loss: 0.5793\n",
      "epoch: 649, loss: 0.5792\n",
      "epoch: 650, loss: 0.5790\n",
      "epoch: 651, loss: 0.5789\n",
      "epoch: 652, loss: 0.5788\n",
      "epoch: 653, loss: 0.5786\n",
      "epoch: 654, loss: 0.5785\n",
      "epoch: 655, loss: 0.5783\n",
      "epoch: 656, loss: 0.5782\n",
      "epoch: 657, loss: 0.5780\n",
      "epoch: 658, loss: 0.5779\n",
      "epoch: 659, loss: 0.5777\n",
      "epoch: 660, loss: 0.5776\n",
      "epoch: 661, loss: 0.5775\n",
      "epoch: 662, loss: 0.5773\n",
      "epoch: 663, loss: 0.5772\n",
      "epoch: 664, loss: 0.5770\n",
      "epoch: 665, loss: 0.5769\n",
      "epoch: 666, loss: 0.5767\n",
      "epoch: 667, loss: 0.5766\n",
      "epoch: 668, loss: 0.5765\n",
      "epoch: 669, loss: 0.5763\n",
      "epoch: 670, loss: 0.5762\n",
      "epoch: 671, loss: 0.5760\n",
      "epoch: 672, loss: 0.5759\n",
      "epoch: 673, loss: 0.5758\n",
      "epoch: 674, loss: 0.5756\n",
      "epoch: 675, loss: 0.5755\n",
      "epoch: 676, loss: 0.5753\n",
      "epoch: 677, loss: 0.5752\n",
      "epoch: 678, loss: 0.5751\n",
      "epoch: 679, loss: 0.5749\n",
      "epoch: 680, loss: 0.5748\n",
      "epoch: 681, loss: 0.5746\n",
      "epoch: 682, loss: 0.5745\n",
      "epoch: 683, loss: 0.5744\n",
      "epoch: 684, loss: 0.5742\n",
      "epoch: 685, loss: 0.5741\n",
      "epoch: 686, loss: 0.5739\n",
      "epoch: 687, loss: 0.5738\n",
      "epoch: 688, loss: 0.5737\n",
      "epoch: 689, loss: 0.5735\n",
      "epoch: 690, loss: 0.5734\n",
      "epoch: 691, loss: 0.5733\n",
      "epoch: 692, loss: 0.5731\n",
      "epoch: 693, loss: 0.5730\n",
      "epoch: 694, loss: 0.5728\n",
      "epoch: 695, loss: 0.5727\n",
      "epoch: 696, loss: 0.5726\n",
      "epoch: 697, loss: 0.5724\n",
      "epoch: 698, loss: 0.5723\n",
      "epoch: 699, loss: 0.5722\n",
      "epoch: 700, loss: 0.5720\n",
      "epoch: 701, loss: 0.5719\n",
      "epoch: 702, loss: 0.5717\n",
      "epoch: 703, loss: 0.5716\n",
      "epoch: 704, loss: 0.5715\n",
      "epoch: 705, loss: 0.5713\n",
      "epoch: 706, loss: 0.5712\n",
      "epoch: 707, loss: 0.5711\n",
      "epoch: 708, loss: 0.5709\n",
      "epoch: 709, loss: 0.5708\n",
      "epoch: 710, loss: 0.5707\n",
      "epoch: 711, loss: 0.5705\n",
      "epoch: 712, loss: 0.5704\n",
      "epoch: 713, loss: 0.5703\n",
      "epoch: 714, loss: 0.5701\n",
      "epoch: 715, loss: 0.5700\n",
      "epoch: 716, loss: 0.5699\n",
      "epoch: 717, loss: 0.5697\n",
      "epoch: 718, loss: 0.5696\n",
      "epoch: 719, loss: 0.5695\n",
      "epoch: 720, loss: 0.5693\n",
      "epoch: 721, loss: 0.5692\n",
      "epoch: 722, loss: 0.5691\n",
      "epoch: 723, loss: 0.5689\n",
      "epoch: 724, loss: 0.5688\n",
      "epoch: 725, loss: 0.5687\n",
      "epoch: 726, loss: 0.5685\n",
      "epoch: 727, loss: 0.5684\n",
      "epoch: 728, loss: 0.5683\n",
      "epoch: 729, loss: 0.5682\n",
      "epoch: 730, loss: 0.5680\n",
      "epoch: 731, loss: 0.5679\n",
      "epoch: 732, loss: 0.5678\n",
      "epoch: 733, loss: 0.5676\n",
      "epoch: 734, loss: 0.5675\n",
      "epoch: 735, loss: 0.5674\n",
      "epoch: 736, loss: 0.5672\n",
      "epoch: 737, loss: 0.5671\n",
      "epoch: 738, loss: 0.5670\n",
      "epoch: 739, loss: 0.5669\n",
      "epoch: 740, loss: 0.5667\n",
      "epoch: 741, loss: 0.5666\n",
      "epoch: 742, loss: 0.5665\n",
      "epoch: 743, loss: 0.5663\n",
      "epoch: 744, loss: 0.5662\n",
      "epoch: 745, loss: 0.5661\n",
      "epoch: 746, loss: 0.5660\n",
      "epoch: 747, loss: 0.5658\n",
      "epoch: 748, loss: 0.5657\n",
      "epoch: 749, loss: 0.5656\n",
      "epoch: 750, loss: 0.5654\n",
      "epoch: 751, loss: 0.5653\n",
      "epoch: 752, loss: 0.5652\n",
      "epoch: 753, loss: 0.5651\n",
      "epoch: 754, loss: 0.5649\n",
      "epoch: 755, loss: 0.5648\n",
      "epoch: 756, loss: 0.5647\n",
      "epoch: 757, loss: 0.5646\n",
      "epoch: 758, loss: 0.5644\n",
      "epoch: 759, loss: 0.5643\n",
      "epoch: 760, loss: 0.5642\n",
      "epoch: 761, loss: 0.5641\n",
      "epoch: 762, loss: 0.5639\n",
      "epoch: 763, loss: 0.5638\n",
      "epoch: 764, loss: 0.5637\n",
      "epoch: 765, loss: 0.5636\n",
      "epoch: 766, loss: 0.5634\n",
      "epoch: 767, loss: 0.5633\n",
      "epoch: 768, loss: 0.5632\n",
      "epoch: 769, loss: 0.5631\n",
      "epoch: 770, loss: 0.5629\n",
      "epoch: 771, loss: 0.5628\n",
      "epoch: 772, loss: 0.5627\n",
      "epoch: 773, loss: 0.5626\n",
      "epoch: 774, loss: 0.5624\n",
      "epoch: 775, loss: 0.5623\n",
      "epoch: 776, loss: 0.5622\n",
      "epoch: 777, loss: 0.5621\n",
      "epoch: 778, loss: 0.5619\n",
      "epoch: 779, loss: 0.5618\n",
      "epoch: 780, loss: 0.5617\n",
      "epoch: 781, loss: 0.5616\n",
      "epoch: 782, loss: 0.5614\n",
      "epoch: 783, loss: 0.5613\n",
      "epoch: 784, loss: 0.5612\n",
      "epoch: 785, loss: 0.5611\n",
      "epoch: 786, loss: 0.5610\n",
      "epoch: 787, loss: 0.5608\n",
      "epoch: 788, loss: 0.5607\n",
      "epoch: 789, loss: 0.5606\n",
      "epoch: 790, loss: 0.5605\n",
      "epoch: 791, loss: 0.5604\n",
      "epoch: 792, loss: 0.5602\n",
      "epoch: 793, loss: 0.5601\n",
      "epoch: 794, loss: 0.5600\n",
      "epoch: 795, loss: 0.5599\n",
      "epoch: 796, loss: 0.5598\n",
      "epoch: 797, loss: 0.5596\n",
      "epoch: 798, loss: 0.5595\n",
      "epoch: 799, loss: 0.5594\n",
      "epoch: 800, loss: 0.5593\n",
      "epoch: 801, loss: 0.5592\n",
      "epoch: 802, loss: 0.5590\n",
      "epoch: 803, loss: 0.5589\n",
      "epoch: 804, loss: 0.5588\n",
      "epoch: 805, loss: 0.5587\n",
      "epoch: 806, loss: 0.5586\n",
      "epoch: 807, loss: 0.5584\n",
      "epoch: 808, loss: 0.5583\n",
      "epoch: 809, loss: 0.5582\n",
      "epoch: 810, loss: 0.5581\n",
      "epoch: 811, loss: 0.5580\n",
      "epoch: 812, loss: 0.5578\n",
      "epoch: 813, loss: 0.5577\n",
      "epoch: 814, loss: 0.5576\n",
      "epoch: 815, loss: 0.5575\n",
      "epoch: 816, loss: 0.5574\n",
      "epoch: 817, loss: 0.5573\n",
      "epoch: 818, loss: 0.5571\n",
      "epoch: 819, loss: 0.5570\n",
      "epoch: 820, loss: 0.5569\n",
      "epoch: 821, loss: 0.5568\n",
      "epoch: 822, loss: 0.5567\n",
      "epoch: 823, loss: 0.5566\n",
      "epoch: 824, loss: 0.5564\n",
      "epoch: 825, loss: 0.5563\n",
      "epoch: 826, loss: 0.5562\n",
      "epoch: 827, loss: 0.5561\n",
      "epoch: 828, loss: 0.5560\n",
      "epoch: 829, loss: 0.5559\n",
      "epoch: 830, loss: 0.5558\n",
      "epoch: 831, loss: 0.5556\n",
      "epoch: 832, loss: 0.5555\n",
      "epoch: 833, loss: 0.5554\n",
      "epoch: 834, loss: 0.5553\n",
      "epoch: 835, loss: 0.5552\n",
      "epoch: 836, loss: 0.5551\n",
      "epoch: 837, loss: 0.5549\n",
      "epoch: 838, loss: 0.5548\n",
      "epoch: 839, loss: 0.5547\n",
      "epoch: 840, loss: 0.5546\n",
      "epoch: 841, loss: 0.5545\n",
      "epoch: 842, loss: 0.5544\n",
      "epoch: 843, loss: 0.5543\n",
      "epoch: 844, loss: 0.5542\n",
      "epoch: 845, loss: 0.5540\n",
      "epoch: 846, loss: 0.5539\n",
      "epoch: 847, loss: 0.5538\n",
      "epoch: 848, loss: 0.5537\n",
      "epoch: 849, loss: 0.5536\n",
      "epoch: 850, loss: 0.5535\n",
      "epoch: 851, loss: 0.5534\n",
      "epoch: 852, loss: 0.5533\n",
      "epoch: 853, loss: 0.5531\n",
      "epoch: 854, loss: 0.5530\n",
      "epoch: 855, loss: 0.5529\n",
      "epoch: 856, loss: 0.5528\n",
      "epoch: 857, loss: 0.5527\n",
      "epoch: 858, loss: 0.5526\n",
      "epoch: 859, loss: 0.5525\n",
      "epoch: 860, loss: 0.5524\n",
      "epoch: 861, loss: 0.5522\n",
      "epoch: 862, loss: 0.5521\n",
      "epoch: 863, loss: 0.5520\n",
      "epoch: 864, loss: 0.5519\n",
      "epoch: 865, loss: 0.5518\n",
      "epoch: 866, loss: 0.5517\n",
      "epoch: 867, loss: 0.5516\n",
      "epoch: 868, loss: 0.5515\n",
      "epoch: 869, loss: 0.5514\n",
      "epoch: 870, loss: 0.5513\n",
      "epoch: 871, loss: 0.5511\n",
      "epoch: 872, loss: 0.5510\n",
      "epoch: 873, loss: 0.5509\n",
      "epoch: 874, loss: 0.5508\n",
      "epoch: 875, loss: 0.5507\n",
      "epoch: 876, loss: 0.5506\n",
      "epoch: 877, loss: 0.5505\n",
      "epoch: 878, loss: 0.5504\n",
      "epoch: 879, loss: 0.5503\n",
      "epoch: 880, loss: 0.5502\n",
      "epoch: 881, loss: 0.5501\n",
      "epoch: 882, loss: 0.5499\n",
      "epoch: 883, loss: 0.5498\n",
      "epoch: 884, loss: 0.5497\n",
      "epoch: 885, loss: 0.5496\n",
      "epoch: 886, loss: 0.5495\n",
      "epoch: 887, loss: 0.5494\n",
      "epoch: 888, loss: 0.5493\n",
      "epoch: 889, loss: 0.5492\n",
      "epoch: 890, loss: 0.5491\n",
      "epoch: 891, loss: 0.5490\n",
      "epoch: 892, loss: 0.5489\n",
      "epoch: 893, loss: 0.5488\n",
      "epoch: 894, loss: 0.5487\n",
      "epoch: 895, loss: 0.5485\n",
      "epoch: 896, loss: 0.5484\n",
      "epoch: 897, loss: 0.5483\n",
      "epoch: 898, loss: 0.5482\n",
      "epoch: 899, loss: 0.5481\n",
      "epoch: 900, loss: 0.5480\n",
      "epoch: 901, loss: 0.5479\n",
      "epoch: 902, loss: 0.5478\n",
      "epoch: 903, loss: 0.5477\n",
      "epoch: 904, loss: 0.5476\n",
      "epoch: 905, loss: 0.5475\n",
      "epoch: 906, loss: 0.5474\n",
      "epoch: 907, loss: 0.5473\n",
      "epoch: 908, loss: 0.5472\n",
      "epoch: 909, loss: 0.5471\n",
      "epoch: 910, loss: 0.5470\n",
      "epoch: 911, loss: 0.5469\n",
      "epoch: 912, loss: 0.5468\n",
      "epoch: 913, loss: 0.5466\n",
      "epoch: 914, loss: 0.5465\n",
      "epoch: 915, loss: 0.5464\n",
      "epoch: 916, loss: 0.5463\n",
      "epoch: 917, loss: 0.5462\n",
      "epoch: 918, loss: 0.5461\n",
      "epoch: 919, loss: 0.5460\n",
      "epoch: 920, loss: 0.5459\n",
      "epoch: 921, loss: 0.5458\n",
      "epoch: 922, loss: 0.5457\n",
      "epoch: 923, loss: 0.5456\n",
      "epoch: 924, loss: 0.5455\n",
      "epoch: 925, loss: 0.5454\n",
      "epoch: 926, loss: 0.5453\n",
      "epoch: 927, loss: 0.5452\n",
      "epoch: 928, loss: 0.5451\n",
      "epoch: 929, loss: 0.5450\n",
      "epoch: 930, loss: 0.5449\n",
      "epoch: 931, loss: 0.5448\n",
      "epoch: 932, loss: 0.5447\n",
      "epoch: 933, loss: 0.5446\n",
      "epoch: 934, loss: 0.5445\n",
      "epoch: 935, loss: 0.5444\n",
      "epoch: 936, loss: 0.5443\n",
      "epoch: 937, loss: 0.5442\n",
      "epoch: 938, loss: 0.5441\n",
      "epoch: 939, loss: 0.5440\n",
      "epoch: 940, loss: 0.5439\n",
      "epoch: 941, loss: 0.5438\n",
      "epoch: 942, loss: 0.5437\n",
      "epoch: 943, loss: 0.5436\n",
      "epoch: 944, loss: 0.5435\n",
      "epoch: 945, loss: 0.5434\n",
      "epoch: 946, loss: 0.5433\n",
      "epoch: 947, loss: 0.5432\n",
      "epoch: 948, loss: 0.5431\n",
      "epoch: 949, loss: 0.5430\n",
      "epoch: 950, loss: 0.5429\n",
      "epoch: 951, loss: 0.5428\n",
      "epoch: 952, loss: 0.5427\n",
      "epoch: 953, loss: 0.5426\n",
      "epoch: 954, loss: 0.5425\n",
      "epoch: 955, loss: 0.5424\n",
      "epoch: 956, loss: 0.5423\n",
      "epoch: 957, loss: 0.5422\n",
      "epoch: 958, loss: 0.5421\n",
      "epoch: 959, loss: 0.5420\n",
      "epoch: 960, loss: 0.5419\n",
      "epoch: 961, loss: 0.5418\n",
      "epoch: 962, loss: 0.5417\n",
      "epoch: 963, loss: 0.5416\n",
      "epoch: 964, loss: 0.5415\n",
      "epoch: 965, loss: 0.5414\n",
      "epoch: 966, loss: 0.5413\n",
      "epoch: 967, loss: 0.5412\n",
      "epoch: 968, loss: 0.5411\n",
      "epoch: 969, loss: 0.5410\n",
      "epoch: 970, loss: 0.5409\n",
      "epoch: 971, loss: 0.5408\n",
      "epoch: 972, loss: 0.5407\n",
      "epoch: 973, loss: 0.5406\n",
      "epoch: 974, loss: 0.5405\n",
      "epoch: 975, loss: 0.5404\n",
      "epoch: 976, loss: 0.5403\n",
      "epoch: 977, loss: 0.5402\n",
      "epoch: 978, loss: 0.5401\n",
      "epoch: 979, loss: 0.5400\n",
      "epoch: 980, loss: 0.5399\n",
      "epoch: 981, loss: 0.5398\n",
      "epoch: 982, loss: 0.5397\n",
      "epoch: 983, loss: 0.5396\n",
      "epoch: 984, loss: 0.5395\n",
      "epoch: 985, loss: 0.5394\n",
      "epoch: 986, loss: 0.5393\n",
      "epoch: 987, loss: 0.5392\n",
      "epoch: 988, loss: 0.5391\n",
      "epoch: 989, loss: 0.5390\n",
      "epoch: 990, loss: 0.5389\n",
      "epoch: 991, loss: 0.5389\n",
      "epoch: 992, loss: 0.5388\n",
      "epoch: 993, loss: 0.5387\n",
      "epoch: 994, loss: 0.5386\n",
      "epoch: 995, loss: 0.5385\n",
      "epoch: 996, loss: 0.5384\n",
      "epoch: 997, loss: 0.5383\n",
      "epoch: 998, loss: 0.5382\n",
      "epoch: 999, loss: 0.5381\n",
      "epoch: 1000, loss: 0.5380\n",
      "epoch: 1001, loss: 0.5379\n",
      "epoch: 1002, loss: 0.5378\n",
      "epoch: 1003, loss: 0.5377\n",
      "epoch: 1004, loss: 0.5376\n",
      "epoch: 1005, loss: 0.5375\n",
      "epoch: 1006, loss: 0.5374\n",
      "epoch: 1007, loss: 0.5373\n",
      "epoch: 1008, loss: 0.5372\n",
      "epoch: 1009, loss: 0.5371\n",
      "epoch: 1010, loss: 0.5371\n",
      "epoch: 1011, loss: 0.5370\n",
      "epoch: 1012, loss: 0.5369\n",
      "epoch: 1013, loss: 0.5368\n",
      "epoch: 1014, loss: 0.5367\n",
      "epoch: 1015, loss: 0.5366\n",
      "epoch: 1016, loss: 0.5365\n",
      "epoch: 1017, loss: 0.5364\n",
      "epoch: 1018, loss: 0.5363\n",
      "epoch: 1019, loss: 0.5362\n",
      "epoch: 1020, loss: 0.5361\n",
      "epoch: 1021, loss: 0.5360\n",
      "epoch: 1022, loss: 0.5359\n",
      "epoch: 1023, loss: 0.5358\n",
      "epoch: 1024, loss: 0.5358\n",
      "epoch: 1025, loss: 0.5357\n",
      "epoch: 1026, loss: 0.5356\n",
      "epoch: 1027, loss: 0.5355\n",
      "epoch: 1028, loss: 0.5354\n",
      "epoch: 1029, loss: 0.5353\n",
      "epoch: 1030, loss: 0.5352\n",
      "epoch: 1031, loss: 0.5351\n",
      "epoch: 1032, loss: 0.5350\n",
      "epoch: 1033, loss: 0.5349\n",
      "epoch: 1034, loss: 0.5348\n",
      "epoch: 1035, loss: 0.5347\n",
      "epoch: 1036, loss: 0.5347\n",
      "epoch: 1037, loss: 0.5346\n",
      "epoch: 1038, loss: 0.5345\n",
      "epoch: 1039, loss: 0.5344\n",
      "epoch: 1040, loss: 0.5343\n",
      "epoch: 1041, loss: 0.5342\n",
      "epoch: 1042, loss: 0.5341\n",
      "epoch: 1043, loss: 0.5340\n",
      "epoch: 1044, loss: 0.5339\n",
      "epoch: 1045, loss: 0.5338\n",
      "epoch: 1046, loss: 0.5337\n",
      "epoch: 1047, loss: 0.5337\n",
      "epoch: 1048, loss: 0.5336\n",
      "epoch: 1049, loss: 0.5335\n",
      "epoch: 1050, loss: 0.5334\n",
      "epoch: 1051, loss: 0.5333\n",
      "epoch: 1052, loss: 0.5332\n",
      "epoch: 1053, loss: 0.5331\n",
      "epoch: 1054, loss: 0.5330\n",
      "epoch: 1055, loss: 0.5329\n",
      "epoch: 1056, loss: 0.5329\n",
      "epoch: 1057, loss: 0.5328\n",
      "epoch: 1058, loss: 0.5327\n",
      "epoch: 1059, loss: 0.5326\n",
      "epoch: 1060, loss: 0.5325\n",
      "epoch: 1061, loss: 0.5324\n",
      "epoch: 1062, loss: 0.5323\n",
      "epoch: 1063, loss: 0.5322\n",
      "epoch: 1064, loss: 0.5321\n",
      "epoch: 1065, loss: 0.5321\n",
      "epoch: 1066, loss: 0.5320\n",
      "epoch: 1067, loss: 0.5319\n",
      "epoch: 1068, loss: 0.5318\n",
      "epoch: 1069, loss: 0.5317\n",
      "epoch: 1070, loss: 0.5316\n",
      "epoch: 1071, loss: 0.5315\n",
      "epoch: 1072, loss: 0.5314\n",
      "epoch: 1073, loss: 0.5313\n",
      "epoch: 1074, loss: 0.5313\n",
      "epoch: 1075, loss: 0.5312\n",
      "epoch: 1076, loss: 0.5311\n",
      "epoch: 1077, loss: 0.5310\n",
      "epoch: 1078, loss: 0.5309\n",
      "epoch: 1079, loss: 0.5308\n",
      "epoch: 1080, loss: 0.5307\n",
      "epoch: 1081, loss: 0.5307\n",
      "epoch: 1082, loss: 0.5306\n",
      "epoch: 1083, loss: 0.5305\n",
      "epoch: 1084, loss: 0.5304\n",
      "epoch: 1085, loss: 0.5303\n",
      "epoch: 1086, loss: 0.5302\n",
      "epoch: 1087, loss: 0.5301\n",
      "epoch: 1088, loss: 0.5300\n",
      "epoch: 1089, loss: 0.5300\n",
      "epoch: 1090, loss: 0.5299\n",
      "epoch: 1091, loss: 0.5298\n",
      "epoch: 1092, loss: 0.5297\n",
      "epoch: 1093, loss: 0.5296\n",
      "epoch: 1094, loss: 0.5295\n",
      "epoch: 1095, loss: 0.5294\n",
      "epoch: 1096, loss: 0.5294\n",
      "epoch: 1097, loss: 0.5293\n",
      "epoch: 1098, loss: 0.5292\n",
      "epoch: 1099, loss: 0.5291\n",
      "epoch: 1100, loss: 0.5290\n",
      "epoch: 1101, loss: 0.5289\n",
      "epoch: 1102, loss: 0.5288\n",
      "epoch: 1103, loss: 0.5288\n",
      "epoch: 1104, loss: 0.5287\n",
      "epoch: 1105, loss: 0.5286\n",
      "epoch: 1106, loss: 0.5285\n",
      "epoch: 1107, loss: 0.5284\n",
      "epoch: 1108, loss: 0.5283\n",
      "epoch: 1109, loss: 0.5283\n",
      "epoch: 1110, loss: 0.5282\n",
      "epoch: 1111, loss: 0.5281\n",
      "epoch: 1112, loss: 0.5280\n",
      "epoch: 1113, loss: 0.5279\n",
      "epoch: 1114, loss: 0.5278\n",
      "epoch: 1115, loss: 0.5277\n",
      "epoch: 1116, loss: 0.5277\n",
      "epoch: 1117, loss: 0.5276\n",
      "epoch: 1118, loss: 0.5275\n",
      "epoch: 1119, loss: 0.5274\n",
      "epoch: 1120, loss: 0.5273\n",
      "epoch: 1121, loss: 0.5272\n",
      "epoch: 1122, loss: 0.5272\n",
      "epoch: 1123, loss: 0.5271\n",
      "epoch: 1124, loss: 0.5270\n",
      "epoch: 1125, loss: 0.5269\n",
      "epoch: 1126, loss: 0.5268\n",
      "epoch: 1127, loss: 0.5267\n",
      "epoch: 1128, loss: 0.5267\n",
      "epoch: 1129, loss: 0.5266\n",
      "epoch: 1130, loss: 0.5265\n",
      "epoch: 1131, loss: 0.5264\n",
      "epoch: 1132, loss: 0.5263\n",
      "epoch: 1133, loss: 0.5263\n",
      "epoch: 1134, loss: 0.5262\n",
      "epoch: 1135, loss: 0.5261\n",
      "epoch: 1136, loss: 0.5260\n",
      "epoch: 1137, loss: 0.5259\n",
      "epoch: 1138, loss: 0.5258\n",
      "epoch: 1139, loss: 0.5258\n",
      "epoch: 1140, loss: 0.5257\n",
      "epoch: 1141, loss: 0.5256\n",
      "epoch: 1142, loss: 0.5255\n",
      "epoch: 1143, loss: 0.5254\n",
      "epoch: 1144, loss: 0.5253\n",
      "epoch: 1145, loss: 0.5253\n",
      "epoch: 1146, loss: 0.5252\n",
      "epoch: 1147, loss: 0.5251\n",
      "epoch: 1148, loss: 0.5250\n",
      "epoch: 1149, loss: 0.5249\n",
      "epoch: 1150, loss: 0.5249\n",
      "epoch: 1151, loss: 0.5248\n",
      "epoch: 1152, loss: 0.5247\n",
      "epoch: 1153, loss: 0.5246\n",
      "epoch: 1154, loss: 0.5245\n",
      "epoch: 1155, loss: 0.5245\n",
      "epoch: 1156, loss: 0.5244\n",
      "epoch: 1157, loss: 0.5243\n",
      "epoch: 1158, loss: 0.5242\n",
      "epoch: 1159, loss: 0.5241\n",
      "epoch: 1160, loss: 0.5241\n",
      "epoch: 1161, loss: 0.5240\n",
      "epoch: 1162, loss: 0.5239\n",
      "epoch: 1163, loss: 0.5238\n",
      "epoch: 1164, loss: 0.5237\n",
      "epoch: 1165, loss: 0.5237\n",
      "epoch: 1166, loss: 0.5236\n",
      "epoch: 1167, loss: 0.5235\n",
      "epoch: 1168, loss: 0.5234\n",
      "epoch: 1169, loss: 0.5233\n",
      "epoch: 1170, loss: 0.5233\n",
      "epoch: 1171, loss: 0.5232\n",
      "epoch: 1172, loss: 0.5231\n",
      "epoch: 1173, loss: 0.5230\n",
      "epoch: 1174, loss: 0.5229\n",
      "epoch: 1175, loss: 0.5229\n",
      "epoch: 1176, loss: 0.5228\n",
      "epoch: 1177, loss: 0.5227\n",
      "epoch: 1178, loss: 0.5226\n",
      "epoch: 1179, loss: 0.5225\n",
      "epoch: 1180, loss: 0.5225\n",
      "epoch: 1181, loss: 0.5224\n",
      "epoch: 1182, loss: 0.5223\n",
      "epoch: 1183, loss: 0.5222\n",
      "epoch: 1184, loss: 0.5222\n",
      "epoch: 1185, loss: 0.5221\n",
      "epoch: 1186, loss: 0.5220\n",
      "epoch: 1187, loss: 0.5219\n",
      "epoch: 1188, loss: 0.5218\n",
      "epoch: 1189, loss: 0.5218\n",
      "epoch: 1190, loss: 0.5217\n",
      "epoch: 1191, loss: 0.5216\n",
      "epoch: 1192, loss: 0.5215\n",
      "epoch: 1193, loss: 0.5215\n",
      "epoch: 1194, loss: 0.5214\n",
      "epoch: 1195, loss: 0.5213\n",
      "epoch: 1196, loss: 0.5212\n",
      "epoch: 1197, loss: 0.5211\n",
      "epoch: 1198, loss: 0.5211\n",
      "epoch: 1199, loss: 0.5210\n",
      "epoch: 1200, loss: 0.5209\n",
      "epoch: 1201, loss: 0.5208\n",
      "epoch: 1202, loss: 0.5208\n",
      "epoch: 1203, loss: 0.5207\n",
      "epoch: 1204, loss: 0.5206\n",
      "epoch: 1205, loss: 0.5205\n",
      "epoch: 1206, loss: 0.5204\n",
      "epoch: 1207, loss: 0.5204\n",
      "epoch: 1208, loss: 0.5203\n",
      "epoch: 1209, loss: 0.5202\n",
      "epoch: 1210, loss: 0.5201\n",
      "epoch: 1211, loss: 0.5201\n",
      "epoch: 1212, loss: 0.5200\n",
      "epoch: 1213, loss: 0.5199\n",
      "epoch: 1214, loss: 0.5198\n",
      "epoch: 1215, loss: 0.5198\n",
      "epoch: 1216, loss: 0.5197\n",
      "epoch: 1217, loss: 0.5196\n",
      "epoch: 1218, loss: 0.5195\n",
      "epoch: 1219, loss: 0.5195\n",
      "epoch: 1220, loss: 0.5194\n",
      "epoch: 1221, loss: 0.5193\n",
      "epoch: 1222, loss: 0.5192\n",
      "epoch: 1223, loss: 0.5192\n",
      "epoch: 1224, loss: 0.5191\n",
      "epoch: 1225, loss: 0.5190\n",
      "epoch: 1226, loss: 0.5189\n",
      "epoch: 1227, loss: 0.5189\n",
      "epoch: 1228, loss: 0.5188\n",
      "epoch: 1229, loss: 0.5187\n",
      "epoch: 1230, loss: 0.5186\n",
      "epoch: 1231, loss: 0.5186\n",
      "epoch: 1232, loss: 0.5185\n",
      "epoch: 1233, loss: 0.5184\n",
      "epoch: 1234, loss: 0.5183\n",
      "epoch: 1235, loss: 0.5183\n",
      "epoch: 1236, loss: 0.5182\n",
      "epoch: 1237, loss: 0.5181\n",
      "epoch: 1238, loss: 0.5180\n",
      "epoch: 1239, loss: 0.5180\n",
      "epoch: 1240, loss: 0.5179\n",
      "epoch: 1241, loss: 0.5178\n",
      "epoch: 1242, loss: 0.5177\n",
      "epoch: 1243, loss: 0.5177\n",
      "epoch: 1244, loss: 0.5176\n",
      "epoch: 1245, loss: 0.5175\n",
      "epoch: 1246, loss: 0.5174\n",
      "epoch: 1247, loss: 0.5174\n",
      "epoch: 1248, loss: 0.5173\n",
      "epoch: 1249, loss: 0.5172\n",
      "epoch: 1250, loss: 0.5171\n",
      "epoch: 1251, loss: 0.5171\n",
      "epoch: 1252, loss: 0.5170\n",
      "epoch: 1253, loss: 0.5169\n",
      "epoch: 1254, loss: 0.5168\n",
      "epoch: 1255, loss: 0.5168\n",
      "epoch: 1256, loss: 0.5167\n",
      "epoch: 1257, loss: 0.5166\n",
      "epoch: 1258, loss: 0.5166\n",
      "epoch: 1259, loss: 0.5165\n",
      "epoch: 1260, loss: 0.5164\n",
      "epoch: 1261, loss: 0.5163\n",
      "epoch: 1262, loss: 0.5163\n",
      "epoch: 1263, loss: 0.5162\n",
      "epoch: 1264, loss: 0.5161\n",
      "epoch: 1265, loss: 0.5160\n",
      "epoch: 1266, loss: 0.5160\n",
      "epoch: 1267, loss: 0.5159\n",
      "epoch: 1268, loss: 0.5158\n",
      "epoch: 1269, loss: 0.5158\n",
      "epoch: 1270, loss: 0.5157\n",
      "epoch: 1271, loss: 0.5156\n",
      "epoch: 1272, loss: 0.5155\n",
      "epoch: 1273, loss: 0.5155\n",
      "epoch: 1274, loss: 0.5154\n",
      "epoch: 1275, loss: 0.5153\n",
      "epoch: 1276, loss: 0.5153\n",
      "epoch: 1277, loss: 0.5152\n",
      "epoch: 1278, loss: 0.5151\n",
      "epoch: 1279, loss: 0.5150\n",
      "epoch: 1280, loss: 0.5150\n",
      "epoch: 1281, loss: 0.5149\n",
      "epoch: 1282, loss: 0.5148\n",
      "epoch: 1283, loss: 0.5147\n",
      "epoch: 1284, loss: 0.5147\n",
      "epoch: 1285, loss: 0.5146\n",
      "epoch: 1286, loss: 0.5145\n",
      "epoch: 1287, loss: 0.5145\n",
      "epoch: 1288, loss: 0.5144\n",
      "epoch: 1289, loss: 0.5143\n",
      "epoch: 1290, loss: 0.5143\n",
      "epoch: 1291, loss: 0.5142\n",
      "epoch: 1292, loss: 0.5141\n",
      "epoch: 1293, loss: 0.5140\n",
      "epoch: 1294, loss: 0.5140\n",
      "epoch: 1295, loss: 0.5139\n",
      "epoch: 1296, loss: 0.5138\n",
      "epoch: 1297, loss: 0.5138\n",
      "epoch: 1298, loss: 0.5137\n",
      "epoch: 1299, loss: 0.5136\n",
      "epoch: 1300, loss: 0.5135\n",
      "epoch: 1301, loss: 0.5135\n",
      "epoch: 1302, loss: 0.5134\n",
      "epoch: 1303, loss: 0.5133\n",
      "epoch: 1304, loss: 0.5133\n",
      "epoch: 1305, loss: 0.5132\n",
      "epoch: 1306, loss: 0.5131\n",
      "epoch: 1307, loss: 0.5131\n",
      "epoch: 1308, loss: 0.5130\n",
      "epoch: 1309, loss: 0.5129\n",
      "epoch: 1310, loss: 0.5128\n",
      "epoch: 1311, loss: 0.5128\n",
      "epoch: 1312, loss: 0.5127\n",
      "epoch: 1313, loss: 0.5126\n",
      "epoch: 1314, loss: 0.5126\n",
      "epoch: 1315, loss: 0.5125\n",
      "epoch: 1316, loss: 0.5124\n",
      "epoch: 1317, loss: 0.5124\n",
      "epoch: 1318, loss: 0.5123\n",
      "epoch: 1319, loss: 0.5122\n",
      "epoch: 1320, loss: 0.5122\n",
      "epoch: 1321, loss: 0.5121\n",
      "epoch: 1322, loss: 0.5120\n",
      "epoch: 1323, loss: 0.5119\n",
      "epoch: 1324, loss: 0.5119\n",
      "epoch: 1325, loss: 0.5118\n",
      "epoch: 1326, loss: 0.5117\n",
      "epoch: 1327, loss: 0.5117\n",
      "epoch: 1328, loss: 0.5116\n",
      "epoch: 1329, loss: 0.5115\n",
      "epoch: 1330, loss: 0.5115\n",
      "epoch: 1331, loss: 0.5114\n",
      "epoch: 1332, loss: 0.5113\n",
      "epoch: 1333, loss: 0.5113\n",
      "epoch: 1334, loss: 0.5112\n",
      "epoch: 1335, loss: 0.5111\n",
      "epoch: 1336, loss: 0.5111\n",
      "epoch: 1337, loss: 0.5110\n",
      "epoch: 1338, loss: 0.5109\n",
      "epoch: 1339, loss: 0.5108\n",
      "epoch: 1340, loss: 0.5108\n",
      "epoch: 1341, loss: 0.5107\n",
      "epoch: 1342, loss: 0.5106\n",
      "epoch: 1343, loss: 0.5106\n",
      "epoch: 1344, loss: 0.5105\n",
      "epoch: 1345, loss: 0.5104\n",
      "epoch: 1346, loss: 0.5104\n",
      "epoch: 1347, loss: 0.5103\n",
      "epoch: 1348, loss: 0.5102\n",
      "epoch: 1349, loss: 0.5102\n",
      "epoch: 1350, loss: 0.5101\n",
      "epoch: 1351, loss: 0.5100\n",
      "epoch: 1352, loss: 0.5100\n",
      "epoch: 1353, loss: 0.5099\n",
      "epoch: 1354, loss: 0.5098\n",
      "epoch: 1355, loss: 0.5098\n",
      "epoch: 1356, loss: 0.5097\n",
      "epoch: 1357, loss: 0.5096\n",
      "epoch: 1358, loss: 0.5096\n",
      "epoch: 1359, loss: 0.5095\n",
      "epoch: 1360, loss: 0.5094\n",
      "epoch: 1361, loss: 0.5094\n",
      "epoch: 1362, loss: 0.5093\n",
      "epoch: 1363, loss: 0.5092\n",
      "epoch: 1364, loss: 0.5092\n",
      "epoch: 1365, loss: 0.5091\n",
      "epoch: 1366, loss: 0.5090\n",
      "epoch: 1367, loss: 0.5090\n",
      "epoch: 1368, loss: 0.5089\n",
      "epoch: 1369, loss: 0.5088\n",
      "epoch: 1370, loss: 0.5088\n",
      "epoch: 1371, loss: 0.5087\n",
      "epoch: 1372, loss: 0.5086\n",
      "epoch: 1373, loss: 0.5086\n",
      "epoch: 1374, loss: 0.5085\n",
      "epoch: 1375, loss: 0.5084\n",
      "epoch: 1376, loss: 0.5084\n",
      "epoch: 1377, loss: 0.5083\n",
      "epoch: 1378, loss: 0.5082\n",
      "epoch: 1379, loss: 0.5082\n",
      "epoch: 1380, loss: 0.5081\n",
      "epoch: 1381, loss: 0.5081\n",
      "epoch: 1382, loss: 0.5080\n",
      "epoch: 1383, loss: 0.5079\n",
      "epoch: 1384, loss: 0.5079\n",
      "epoch: 1385, loss: 0.5078\n",
      "epoch: 1386, loss: 0.5077\n",
      "epoch: 1387, loss: 0.5077\n",
      "epoch: 1388, loss: 0.5076\n",
      "epoch: 1389, loss: 0.5075\n",
      "epoch: 1390, loss: 0.5075\n",
      "epoch: 1391, loss: 0.5074\n",
      "epoch: 1392, loss: 0.5073\n",
      "epoch: 1393, loss: 0.5073\n",
      "epoch: 1394, loss: 0.5072\n",
      "epoch: 1395, loss: 0.5071\n",
      "epoch: 1396, loss: 0.5071\n",
      "epoch: 1397, loss: 0.5070\n",
      "epoch: 1398, loss: 0.5069\n",
      "epoch: 1399, loss: 0.5069\n",
      "epoch: 1400, loss: 0.5068\n",
      "epoch: 1401, loss: 0.5068\n",
      "epoch: 1402, loss: 0.5067\n",
      "epoch: 1403, loss: 0.5066\n",
      "epoch: 1404, loss: 0.5066\n",
      "epoch: 1405, loss: 0.5065\n",
      "epoch: 1406, loss: 0.5064\n",
      "epoch: 1407, loss: 0.5064\n",
      "epoch: 1408, loss: 0.5063\n",
      "epoch: 1409, loss: 0.5062\n",
      "epoch: 1410, loss: 0.5062\n",
      "epoch: 1411, loss: 0.5061\n",
      "epoch: 1412, loss: 0.5060\n",
      "epoch: 1413, loss: 0.5060\n",
      "epoch: 1414, loss: 0.5059\n",
      "epoch: 1415, loss: 0.5059\n",
      "epoch: 1416, loss: 0.5058\n",
      "epoch: 1417, loss: 0.5057\n",
      "epoch: 1418, loss: 0.5057\n",
      "epoch: 1419, loss: 0.5056\n",
      "epoch: 1420, loss: 0.5055\n",
      "epoch: 1421, loss: 0.5055\n",
      "epoch: 1422, loss: 0.5054\n",
      "epoch: 1423, loss: 0.5053\n",
      "epoch: 1424, loss: 0.5053\n",
      "epoch: 1425, loss: 0.5052\n",
      "epoch: 1426, loss: 0.5052\n",
      "epoch: 1427, loss: 0.5051\n",
      "epoch: 1428, loss: 0.5050\n",
      "epoch: 1429, loss: 0.5050\n",
      "epoch: 1430, loss: 0.5049\n",
      "epoch: 1431, loss: 0.5048\n",
      "epoch: 1432, loss: 0.5048\n",
      "epoch: 1433, loss: 0.5047\n",
      "epoch: 1434, loss: 0.5047\n",
      "epoch: 1435, loss: 0.5046\n",
      "epoch: 1436, loss: 0.5045\n",
      "epoch: 1437, loss: 0.5045\n",
      "epoch: 1438, loss: 0.5044\n",
      "epoch: 1439, loss: 0.5043\n",
      "epoch: 1440, loss: 0.5043\n",
      "epoch: 1441, loss: 0.5042\n",
      "epoch: 1442, loss: 0.5042\n",
      "epoch: 1443, loss: 0.5041\n",
      "epoch: 1444, loss: 0.5040\n",
      "epoch: 1445, loss: 0.5040\n",
      "epoch: 1446, loss: 0.5039\n",
      "epoch: 1447, loss: 0.5038\n",
      "epoch: 1448, loss: 0.5038\n",
      "epoch: 1449, loss: 0.5037\n",
      "epoch: 1450, loss: 0.5037\n",
      "epoch: 1451, loss: 0.5036\n",
      "epoch: 1452, loss: 0.5035\n",
      "epoch: 1453, loss: 0.5035\n",
      "epoch: 1454, loss: 0.5034\n",
      "epoch: 1455, loss: 0.5034\n",
      "epoch: 1456, loss: 0.5033\n",
      "epoch: 1457, loss: 0.5032\n",
      "epoch: 1458, loss: 0.5032\n",
      "epoch: 1459, loss: 0.5031\n",
      "epoch: 1460, loss: 0.5030\n",
      "epoch: 1461, loss: 0.5030\n",
      "epoch: 1462, loss: 0.5029\n",
      "epoch: 1463, loss: 0.5029\n",
      "epoch: 1464, loss: 0.5028\n",
      "epoch: 1465, loss: 0.5027\n",
      "epoch: 1466, loss: 0.5027\n",
      "epoch: 1467, loss: 0.5026\n",
      "epoch: 1468, loss: 0.5026\n",
      "epoch: 1469, loss: 0.5025\n",
      "epoch: 1470, loss: 0.5024\n",
      "epoch: 1471, loss: 0.5024\n",
      "epoch: 1472, loss: 0.5023\n",
      "epoch: 1473, loss: 0.5023\n",
      "epoch: 1474, loss: 0.5022\n",
      "epoch: 1475, loss: 0.5021\n",
      "epoch: 1476, loss: 0.5021\n",
      "epoch: 1477, loss: 0.5020\n",
      "epoch: 1478, loss: 0.5020\n",
      "epoch: 1479, loss: 0.5019\n",
      "epoch: 1480, loss: 0.5018\n",
      "epoch: 1481, loss: 0.5018\n",
      "epoch: 1482, loss: 0.5017\n",
      "epoch: 1483, loss: 0.5017\n",
      "epoch: 1484, loss: 0.5016\n",
      "epoch: 1485, loss: 0.5015\n",
      "epoch: 1486, loss: 0.5015\n",
      "epoch: 1487, loss: 0.5014\n",
      "epoch: 1488, loss: 0.5014\n",
      "epoch: 1489, loss: 0.5013\n",
      "epoch: 1490, loss: 0.5012\n",
      "epoch: 1491, loss: 0.5012\n",
      "epoch: 1492, loss: 0.5011\n",
      "epoch: 1493, loss: 0.5011\n",
      "epoch: 1494, loss: 0.5010\n",
      "epoch: 1495, loss: 0.5009\n",
      "epoch: 1496, loss: 0.5009\n",
      "epoch: 1497, loss: 0.5008\n",
      "epoch: 1498, loss: 0.5008\n",
      "epoch: 1499, loss: 0.5007\n",
      "epoch: 1500, loss: 0.5006\n",
      "epoch: 1501, loss: 0.5006\n",
      "epoch: 1502, loss: 0.5005\n",
      "epoch: 1503, loss: 0.5005\n",
      "epoch: 1504, loss: 0.5004\n",
      "epoch: 1505, loss: 0.5003\n",
      "epoch: 1506, loss: 0.5003\n",
      "epoch: 1507, loss: 0.5002\n",
      "epoch: 1508, loss: 0.5002\n",
      "epoch: 1509, loss: 0.5001\n",
      "epoch: 1510, loss: 0.5000\n",
      "epoch: 1511, loss: 0.5000\n",
      "epoch: 1512, loss: 0.4999\n",
      "epoch: 1513, loss: 0.4999\n",
      "epoch: 1514, loss: 0.4998\n",
      "epoch: 1515, loss: 0.4998\n",
      "epoch: 1516, loss: 0.4997\n",
      "epoch: 1517, loss: 0.4996\n",
      "epoch: 1518, loss: 0.4996\n",
      "epoch: 1519, loss: 0.4995\n",
      "epoch: 1520, loss: 0.4995\n",
      "epoch: 1521, loss: 0.4994\n",
      "epoch: 1522, loss: 0.4993\n",
      "epoch: 1523, loss: 0.4993\n",
      "epoch: 1524, loss: 0.4992\n",
      "epoch: 1525, loss: 0.4992\n",
      "epoch: 1526, loss: 0.4991\n",
      "epoch: 1527, loss: 0.4991\n",
      "epoch: 1528, loss: 0.4990\n",
      "epoch: 1529, loss: 0.4989\n",
      "epoch: 1530, loss: 0.4989\n",
      "epoch: 1531, loss: 0.4988\n",
      "epoch: 1532, loss: 0.4988\n",
      "epoch: 1533, loss: 0.4987\n",
      "epoch: 1534, loss: 0.4986\n",
      "epoch: 1535, loss: 0.4986\n",
      "epoch: 1536, loss: 0.4985\n",
      "epoch: 1537, loss: 0.4985\n",
      "epoch: 1538, loss: 0.4984\n",
      "epoch: 1539, loss: 0.4984\n",
      "epoch: 1540, loss: 0.4983\n",
      "epoch: 1541, loss: 0.4982\n",
      "epoch: 1542, loss: 0.4982\n",
      "epoch: 1543, loss: 0.4981\n",
      "epoch: 1544, loss: 0.4981\n",
      "epoch: 1545, loss: 0.4980\n",
      "epoch: 1546, loss: 0.4980\n",
      "epoch: 1547, loss: 0.4979\n",
      "epoch: 1548, loss: 0.4978\n",
      "epoch: 1549, loss: 0.4978\n",
      "epoch: 1550, loss: 0.4977\n",
      "epoch: 1551, loss: 0.4977\n",
      "epoch: 1552, loss: 0.4976\n",
      "epoch: 1553, loss: 0.4976\n",
      "epoch: 1554, loss: 0.4975\n",
      "epoch: 1555, loss: 0.4974\n",
      "epoch: 1556, loss: 0.4974\n",
      "epoch: 1557, loss: 0.4973\n",
      "epoch: 1558, loss: 0.4973\n",
      "epoch: 1559, loss: 0.4972\n",
      "epoch: 1560, loss: 0.4972\n",
      "epoch: 1561, loss: 0.4971\n",
      "epoch: 1562, loss: 0.4971\n",
      "epoch: 1563, loss: 0.4970\n",
      "epoch: 1564, loss: 0.4969\n",
      "epoch: 1565, loss: 0.4969\n",
      "epoch: 1566, loss: 0.4968\n",
      "epoch: 1567, loss: 0.4968\n",
      "epoch: 1568, loss: 0.4967\n",
      "epoch: 1569, loss: 0.4967\n",
      "epoch: 1570, loss: 0.4966\n",
      "epoch: 1571, loss: 0.4965\n",
      "epoch: 1572, loss: 0.4965\n",
      "epoch: 1573, loss: 0.4964\n",
      "epoch: 1574, loss: 0.4964\n",
      "epoch: 1575, loss: 0.4963\n",
      "epoch: 1576, loss: 0.4963\n",
      "epoch: 1577, loss: 0.4962\n",
      "epoch: 1578, loss: 0.4962\n",
      "epoch: 1579, loss: 0.4961\n",
      "epoch: 1580, loss: 0.4960\n",
      "epoch: 1581, loss: 0.4960\n",
      "epoch: 1582, loss: 0.4959\n",
      "epoch: 1583, loss: 0.4959\n",
      "epoch: 1584, loss: 0.4958\n",
      "epoch: 1585, loss: 0.4958\n",
      "epoch: 1586, loss: 0.4957\n",
      "epoch: 1587, loss: 0.4957\n",
      "epoch: 1588, loss: 0.4956\n",
      "epoch: 1589, loss: 0.4955\n",
      "epoch: 1590, loss: 0.4955\n",
      "epoch: 1591, loss: 0.4954\n",
      "epoch: 1592, loss: 0.4954\n",
      "epoch: 1593, loss: 0.4953\n",
      "epoch: 1594, loss: 0.4953\n",
      "epoch: 1595, loss: 0.4952\n",
      "epoch: 1596, loss: 0.4952\n",
      "epoch: 1597, loss: 0.4951\n",
      "epoch: 1598, loss: 0.4950\n",
      "epoch: 1599, loss: 0.4950\n",
      "epoch: 1600, loss: 0.4949\n",
      "epoch: 1601, loss: 0.4949\n",
      "epoch: 1602, loss: 0.4948\n",
      "epoch: 1603, loss: 0.4948\n",
      "epoch: 1604, loss: 0.4947\n",
      "epoch: 1605, loss: 0.4947\n",
      "epoch: 1606, loss: 0.4946\n",
      "epoch: 1607, loss: 0.4946\n",
      "epoch: 1608, loss: 0.4945\n",
      "epoch: 1609, loss: 0.4944\n",
      "epoch: 1610, loss: 0.4944\n",
      "epoch: 1611, loss: 0.4943\n",
      "epoch: 1612, loss: 0.4943\n",
      "epoch: 1613, loss: 0.4942\n",
      "epoch: 1614, loss: 0.4942\n",
      "epoch: 1615, loss: 0.4941\n",
      "epoch: 1616, loss: 0.4941\n",
      "epoch: 1617, loss: 0.4940\n",
      "epoch: 1618, loss: 0.4940\n",
      "epoch: 1619, loss: 0.4939\n",
      "epoch: 1620, loss: 0.4938\n",
      "epoch: 1621, loss: 0.4938\n",
      "epoch: 1622, loss: 0.4937\n",
      "epoch: 1623, loss: 0.4937\n",
      "epoch: 1624, loss: 0.4936\n",
      "epoch: 1625, loss: 0.4936\n",
      "epoch: 1626, loss: 0.4935\n",
      "epoch: 1627, loss: 0.4935\n",
      "epoch: 1628, loss: 0.4934\n",
      "epoch: 1629, loss: 0.4934\n",
      "epoch: 1630, loss: 0.4933\n",
      "epoch: 1631, loss: 0.4933\n",
      "epoch: 1632, loss: 0.4932\n",
      "epoch: 1633, loss: 0.4931\n",
      "epoch: 1634, loss: 0.4931\n",
      "epoch: 1635, loss: 0.4930\n",
      "epoch: 1636, loss: 0.4930\n",
      "epoch: 1637, loss: 0.4929\n",
      "epoch: 1638, loss: 0.4929\n",
      "epoch: 1639, loss: 0.4928\n",
      "epoch: 1640, loss: 0.4928\n",
      "epoch: 1641, loss: 0.4927\n",
      "epoch: 1642, loss: 0.4927\n",
      "epoch: 1643, loss: 0.4926\n",
      "epoch: 1644, loss: 0.4926\n",
      "epoch: 1645, loss: 0.4925\n",
      "epoch: 1646, loss: 0.4925\n",
      "epoch: 1647, loss: 0.4924\n",
      "epoch: 1648, loss: 0.4924\n",
      "epoch: 1649, loss: 0.4923\n",
      "epoch: 1650, loss: 0.4922\n",
      "epoch: 1651, loss: 0.4922\n",
      "epoch: 1652, loss: 0.4921\n",
      "epoch: 1653, loss: 0.4921\n",
      "epoch: 1654, loss: 0.4920\n",
      "epoch: 1655, loss: 0.4920\n",
      "epoch: 1656, loss: 0.4919\n",
      "epoch: 1657, loss: 0.4919\n",
      "epoch: 1658, loss: 0.4918\n",
      "epoch: 1659, loss: 0.4918\n",
      "epoch: 1660, loss: 0.4917\n",
      "epoch: 1661, loss: 0.4917\n",
      "epoch: 1662, loss: 0.4916\n",
      "epoch: 1663, loss: 0.4916\n",
      "epoch: 1664, loss: 0.4915\n",
      "epoch: 1665, loss: 0.4915\n",
      "epoch: 1666, loss: 0.4914\n",
      "epoch: 1667, loss: 0.4914\n",
      "epoch: 1668, loss: 0.4913\n",
      "epoch: 1669, loss: 0.4912\n",
      "epoch: 1670, loss: 0.4912\n",
      "epoch: 1671, loss: 0.4911\n",
      "epoch: 1672, loss: 0.4911\n",
      "epoch: 1673, loss: 0.4910\n",
      "epoch: 1674, loss: 0.4910\n",
      "epoch: 1675, loss: 0.4909\n",
      "epoch: 1676, loss: 0.4909\n",
      "epoch: 1677, loss: 0.4908\n",
      "epoch: 1678, loss: 0.4908\n",
      "epoch: 1679, loss: 0.4907\n",
      "epoch: 1680, loss: 0.4907\n",
      "epoch: 1681, loss: 0.4906\n",
      "epoch: 1682, loss: 0.4906\n",
      "epoch: 1683, loss: 0.4905\n",
      "epoch: 1684, loss: 0.4905\n",
      "epoch: 1685, loss: 0.4904\n",
      "epoch: 1686, loss: 0.4904\n",
      "epoch: 1687, loss: 0.4903\n",
      "epoch: 1688, loss: 0.4903\n",
      "epoch: 1689, loss: 0.4902\n",
      "epoch: 1690, loss: 0.4902\n",
      "epoch: 1691, loss: 0.4901\n",
      "epoch: 1692, loss: 0.4901\n",
      "epoch: 1693, loss: 0.4900\n",
      "epoch: 1694, loss: 0.4900\n",
      "epoch: 1695, loss: 0.4899\n",
      "epoch: 1696, loss: 0.4899\n",
      "epoch: 1697, loss: 0.4898\n",
      "epoch: 1698, loss: 0.4898\n",
      "epoch: 1699, loss: 0.4897\n",
      "epoch: 1700, loss: 0.4897\n",
      "epoch: 1701, loss: 0.4896\n",
      "epoch: 1702, loss: 0.4896\n",
      "epoch: 1703, loss: 0.4895\n",
      "epoch: 1704, loss: 0.4894\n",
      "epoch: 1705, loss: 0.4894\n",
      "epoch: 1706, loss: 0.4893\n",
      "epoch: 1707, loss: 0.4893\n",
      "epoch: 1708, loss: 0.4892\n",
      "epoch: 1709, loss: 0.4892\n",
      "epoch: 1710, loss: 0.4891\n",
      "epoch: 1711, loss: 0.4891\n",
      "epoch: 1712, loss: 0.4890\n",
      "epoch: 1713, loss: 0.4890\n",
      "epoch: 1714, loss: 0.4889\n",
      "epoch: 1715, loss: 0.4889\n",
      "epoch: 1716, loss: 0.4888\n",
      "epoch: 1717, loss: 0.4888\n",
      "epoch: 1718, loss: 0.4887\n",
      "epoch: 1719, loss: 0.4887\n",
      "epoch: 1720, loss: 0.4886\n",
      "epoch: 1721, loss: 0.4886\n",
      "epoch: 1722, loss: 0.4885\n",
      "epoch: 1723, loss: 0.4885\n",
      "epoch: 1724, loss: 0.4884\n",
      "epoch: 1725, loss: 0.4884\n",
      "epoch: 1726, loss: 0.4883\n",
      "epoch: 1727, loss: 0.4883\n",
      "epoch: 1728, loss: 0.4882\n",
      "epoch: 1729, loss: 0.4882\n",
      "epoch: 1730, loss: 0.4881\n",
      "epoch: 1731, loss: 0.4881\n",
      "epoch: 1732, loss: 0.4880\n",
      "epoch: 1733, loss: 0.4880\n",
      "epoch: 1734, loss: 0.4879\n",
      "epoch: 1735, loss: 0.4879\n",
      "epoch: 1736, loss: 0.4878\n",
      "epoch: 1737, loss: 0.4878\n",
      "epoch: 1738, loss: 0.4877\n",
      "epoch: 1739, loss: 0.4877\n",
      "epoch: 1740, loss: 0.4876\n",
      "epoch: 1741, loss: 0.4876\n",
      "epoch: 1742, loss: 0.4875\n",
      "epoch: 1743, loss: 0.4875\n",
      "epoch: 1744, loss: 0.4874\n",
      "epoch: 1745, loss: 0.4874\n",
      "epoch: 1746, loss: 0.4873\n",
      "epoch: 1747, loss: 0.4873\n",
      "epoch: 1748, loss: 0.4872\n",
      "epoch: 1749, loss: 0.4872\n",
      "epoch: 1750, loss: 0.4872\n",
      "epoch: 1751, loss: 0.4871\n",
      "epoch: 1752, loss: 0.4871\n",
      "epoch: 1753, loss: 0.4870\n",
      "epoch: 1754, loss: 0.4870\n",
      "epoch: 1755, loss: 0.4869\n",
      "epoch: 1756, loss: 0.4869\n",
      "epoch: 1757, loss: 0.4868\n",
      "epoch: 1758, loss: 0.4868\n",
      "epoch: 1759, loss: 0.4867\n",
      "epoch: 1760, loss: 0.4867\n",
      "epoch: 1761, loss: 0.4866\n",
      "epoch: 1762, loss: 0.4866\n",
      "epoch: 1763, loss: 0.4865\n",
      "epoch: 1764, loss: 0.4865\n",
      "epoch: 1765, loss: 0.4864\n",
      "epoch: 1766, loss: 0.4864\n",
      "epoch: 1767, loss: 0.4863\n",
      "epoch: 1768, loss: 0.4863\n",
      "epoch: 1769, loss: 0.4862\n",
      "epoch: 1770, loss: 0.4862\n",
      "epoch: 1771, loss: 0.4861\n",
      "epoch: 1772, loss: 0.4861\n",
      "epoch: 1773, loss: 0.4860\n",
      "epoch: 1774, loss: 0.4860\n",
      "epoch: 1775, loss: 0.4859\n",
      "epoch: 1776, loss: 0.4859\n",
      "epoch: 1777, loss: 0.4858\n",
      "epoch: 1778, loss: 0.4858\n",
      "epoch: 1779, loss: 0.4857\n",
      "epoch: 1780, loss: 0.4857\n",
      "epoch: 1781, loss: 0.4856\n",
      "epoch: 1782, loss: 0.4856\n",
      "epoch: 1783, loss: 0.4855\n",
      "epoch: 1784, loss: 0.4855\n",
      "epoch: 1785, loss: 0.4855\n",
      "epoch: 1786, loss: 0.4854\n",
      "epoch: 1787, loss: 0.4854\n",
      "epoch: 1788, loss: 0.4853\n",
      "epoch: 1789, loss: 0.4853\n",
      "epoch: 1790, loss: 0.4852\n",
      "epoch: 1791, loss: 0.4852\n",
      "epoch: 1792, loss: 0.4851\n",
      "epoch: 1793, loss: 0.4851\n",
      "epoch: 1794, loss: 0.4850\n",
      "epoch: 1795, loss: 0.4850\n",
      "epoch: 1796, loss: 0.4849\n",
      "epoch: 1797, loss: 0.4849\n",
      "epoch: 1798, loss: 0.4848\n",
      "epoch: 1799, loss: 0.4848\n",
      "epoch: 1800, loss: 0.4847\n",
      "epoch: 1801, loss: 0.4847\n",
      "epoch: 1802, loss: 0.4846\n",
      "epoch: 1803, loss: 0.4846\n",
      "epoch: 1804, loss: 0.4845\n",
      "epoch: 1805, loss: 0.4845\n",
      "epoch: 1806, loss: 0.4845\n",
      "epoch: 1807, loss: 0.4844\n",
      "epoch: 1808, loss: 0.4844\n",
      "epoch: 1809, loss: 0.4843\n",
      "epoch: 1810, loss: 0.4843\n",
      "epoch: 1811, loss: 0.4842\n",
      "epoch: 1812, loss: 0.4842\n",
      "epoch: 1813, loss: 0.4841\n",
      "epoch: 1814, loss: 0.4841\n",
      "epoch: 1815, loss: 0.4840\n",
      "epoch: 1816, loss: 0.4840\n",
      "epoch: 1817, loss: 0.4839\n",
      "epoch: 1818, loss: 0.4839\n",
      "epoch: 1819, loss: 0.4838\n",
      "epoch: 1820, loss: 0.4838\n",
      "epoch: 1821, loss: 0.4837\n",
      "epoch: 1822, loss: 0.4837\n",
      "epoch: 1823, loss: 0.4837\n",
      "epoch: 1824, loss: 0.4836\n",
      "epoch: 1825, loss: 0.4836\n",
      "epoch: 1826, loss: 0.4835\n",
      "epoch: 1827, loss: 0.4835\n",
      "epoch: 1828, loss: 0.4834\n",
      "epoch: 1829, loss: 0.4834\n",
      "epoch: 1830, loss: 0.4833\n",
      "epoch: 1831, loss: 0.4833\n",
      "epoch: 1832, loss: 0.4832\n",
      "epoch: 1833, loss: 0.4832\n",
      "epoch: 1834, loss: 0.4831\n",
      "epoch: 1835, loss: 0.4831\n",
      "epoch: 1836, loss: 0.4830\n",
      "epoch: 1837, loss: 0.4830\n",
      "epoch: 1838, loss: 0.4830\n",
      "epoch: 1839, loss: 0.4829\n",
      "epoch: 1840, loss: 0.4829\n",
      "epoch: 1841, loss: 0.4828\n",
      "epoch: 1842, loss: 0.4828\n",
      "epoch: 1843, loss: 0.4827\n",
      "epoch: 1844, loss: 0.4827\n",
      "epoch: 1845, loss: 0.4826\n",
      "epoch: 1846, loss: 0.4826\n",
      "epoch: 1847, loss: 0.4825\n",
      "epoch: 1848, loss: 0.4825\n",
      "epoch: 1849, loss: 0.4824\n",
      "epoch: 1850, loss: 0.4824\n",
      "epoch: 1851, loss: 0.4824\n",
      "epoch: 1852, loss: 0.4823\n",
      "epoch: 1853, loss: 0.4823\n",
      "epoch: 1854, loss: 0.4822\n",
      "epoch: 1855, loss: 0.4822\n",
      "epoch: 1856, loss: 0.4821\n",
      "epoch: 1857, loss: 0.4821\n",
      "epoch: 1858, loss: 0.4820\n",
      "epoch: 1859, loss: 0.4820\n",
      "epoch: 1860, loss: 0.4819\n",
      "epoch: 1861, loss: 0.4819\n",
      "epoch: 1862, loss: 0.4819\n",
      "epoch: 1863, loss: 0.4818\n",
      "epoch: 1864, loss: 0.4818\n",
      "epoch: 1865, loss: 0.4817\n",
      "epoch: 1866, loss: 0.4817\n",
      "epoch: 1867, loss: 0.4816\n",
      "epoch: 1868, loss: 0.4816\n",
      "epoch: 1869, loss: 0.4815\n",
      "epoch: 1870, loss: 0.4815\n",
      "epoch: 1871, loss: 0.4814\n",
      "epoch: 1872, loss: 0.4814\n",
      "epoch: 1873, loss: 0.4814\n",
      "epoch: 1874, loss: 0.4813\n",
      "epoch: 1875, loss: 0.4813\n",
      "epoch: 1876, loss: 0.4812\n",
      "epoch: 1877, loss: 0.4812\n",
      "epoch: 1878, loss: 0.4811\n",
      "epoch: 1879, loss: 0.4811\n",
      "epoch: 1880, loss: 0.4810\n",
      "epoch: 1881, loss: 0.4810\n",
      "epoch: 1882, loss: 0.4809\n",
      "epoch: 1883, loss: 0.4809\n",
      "epoch: 1884, loss: 0.4809\n",
      "epoch: 1885, loss: 0.4808\n",
      "epoch: 1886, loss: 0.4808\n",
      "epoch: 1887, loss: 0.4807\n",
      "epoch: 1888, loss: 0.4807\n",
      "epoch: 1889, loss: 0.4806\n",
      "epoch: 1890, loss: 0.4806\n",
      "epoch: 1891, loss: 0.4805\n",
      "epoch: 1892, loss: 0.4805\n",
      "epoch: 1893, loss: 0.4805\n",
      "epoch: 1894, loss: 0.4804\n",
      "epoch: 1895, loss: 0.4804\n",
      "epoch: 1896, loss: 0.4803\n",
      "epoch: 1897, loss: 0.4803\n",
      "epoch: 1898, loss: 0.4802\n",
      "epoch: 1899, loss: 0.4802\n",
      "epoch: 1900, loss: 0.4801\n",
      "epoch: 1901, loss: 0.4801\n",
      "epoch: 1902, loss: 0.4801\n",
      "epoch: 1903, loss: 0.4800\n",
      "epoch: 1904, loss: 0.4800\n",
      "epoch: 1905, loss: 0.4799\n",
      "epoch: 1906, loss: 0.4799\n",
      "epoch: 1907, loss: 0.4798\n",
      "epoch: 1908, loss: 0.4798\n",
      "epoch: 1909, loss: 0.4797\n",
      "epoch: 1910, loss: 0.4797\n",
      "epoch: 1911, loss: 0.4797\n",
      "epoch: 1912, loss: 0.4796\n",
      "epoch: 1913, loss: 0.4796\n",
      "epoch: 1914, loss: 0.4795\n",
      "epoch: 1915, loss: 0.4795\n",
      "epoch: 1916, loss: 0.4794\n",
      "epoch: 1917, loss: 0.4794\n",
      "epoch: 1918, loss: 0.4793\n",
      "epoch: 1919, loss: 0.4793\n",
      "epoch: 1920, loss: 0.4793\n",
      "epoch: 1921, loss: 0.4792\n",
      "epoch: 1922, loss: 0.4792\n",
      "epoch: 1923, loss: 0.4791\n",
      "epoch: 1924, loss: 0.4791\n",
      "epoch: 1925, loss: 0.4790\n",
      "epoch: 1926, loss: 0.4790\n",
      "epoch: 1927, loss: 0.4790\n",
      "epoch: 1928, loss: 0.4789\n",
      "epoch: 1929, loss: 0.4789\n",
      "epoch: 1930, loss: 0.4788\n",
      "epoch: 1931, loss: 0.4788\n",
      "epoch: 1932, loss: 0.4787\n",
      "epoch: 1933, loss: 0.4787\n",
      "epoch: 1934, loss: 0.4787\n",
      "epoch: 1935, loss: 0.4786\n",
      "epoch: 1936, loss: 0.4786\n",
      "epoch: 1937, loss: 0.4785\n",
      "epoch: 1938, loss: 0.4785\n",
      "epoch: 1939, loss: 0.4784\n",
      "epoch: 1940, loss: 0.4784\n",
      "epoch: 1941, loss: 0.4783\n",
      "epoch: 1942, loss: 0.4783\n",
      "epoch: 1943, loss: 0.4783\n",
      "epoch: 1944, loss: 0.4782\n",
      "epoch: 1945, loss: 0.4782\n",
      "epoch: 1946, loss: 0.4781\n",
      "epoch: 1947, loss: 0.4781\n",
      "epoch: 1948, loss: 0.4780\n",
      "epoch: 1949, loss: 0.4780\n",
      "epoch: 1950, loss: 0.4780\n",
      "epoch: 1951, loss: 0.4779\n",
      "epoch: 1952, loss: 0.4779\n",
      "epoch: 1953, loss: 0.4778\n",
      "epoch: 1954, loss: 0.4778\n",
      "epoch: 1955, loss: 0.4777\n",
      "epoch: 1956, loss: 0.4777\n",
      "epoch: 1957, loss: 0.4777\n",
      "epoch: 1958, loss: 0.4776\n",
      "epoch: 1959, loss: 0.4776\n",
      "epoch: 1960, loss: 0.4775\n",
      "epoch: 1961, loss: 0.4775\n",
      "epoch: 1962, loss: 0.4774\n",
      "epoch: 1963, loss: 0.4774\n",
      "epoch: 1964, loss: 0.4774\n",
      "epoch: 1965, loss: 0.4773\n",
      "epoch: 1966, loss: 0.4773\n",
      "epoch: 1967, loss: 0.4772\n",
      "epoch: 1968, loss: 0.4772\n",
      "epoch: 1969, loss: 0.4771\n",
      "epoch: 1970, loss: 0.4771\n",
      "epoch: 1971, loss: 0.4771\n",
      "epoch: 1972, loss: 0.4770\n",
      "epoch: 1973, loss: 0.4770\n",
      "epoch: 1974, loss: 0.4769\n",
      "epoch: 1975, loss: 0.4769\n",
      "epoch: 1976, loss: 0.4769\n",
      "epoch: 1977, loss: 0.4768\n",
      "epoch: 1978, loss: 0.4768\n",
      "epoch: 1979, loss: 0.4767\n",
      "epoch: 1980, loss: 0.4767\n",
      "epoch: 1981, loss: 0.4766\n",
      "epoch: 1982, loss: 0.4766\n",
      "epoch: 1983, loss: 0.4766\n",
      "epoch: 1984, loss: 0.4765\n",
      "epoch: 1985, loss: 0.4765\n",
      "epoch: 1986, loss: 0.4764\n",
      "epoch: 1987, loss: 0.4764\n",
      "epoch: 1988, loss: 0.4763\n",
      "epoch: 1989, loss: 0.4763\n",
      "epoch: 1990, loss: 0.4763\n",
      "epoch: 1991, loss: 0.4762\n",
      "epoch: 1992, loss: 0.4762\n",
      "epoch: 1993, loss: 0.4761\n",
      "epoch: 1994, loss: 0.4761\n",
      "epoch: 1995, loss: 0.4761\n",
      "epoch: 1996, loss: 0.4760\n",
      "epoch: 1997, loss: 0.4760\n",
      "epoch: 1998, loss: 0.4759\n",
      "epoch: 1999, loss: 0.4759\n",
      "epoch: 2000, loss: 0.4758\n",
      "epoch: 2001, loss: 0.4758\n",
      "epoch: 2002, loss: 0.4758\n",
      "epoch: 2003, loss: 0.4757\n",
      "epoch: 2004, loss: 0.4757\n",
      "epoch: 2005, loss: 0.4756\n",
      "epoch: 2006, loss: 0.4756\n",
      "epoch: 2007, loss: 0.4756\n",
      "epoch: 2008, loss: 0.4755\n",
      "epoch: 2009, loss: 0.4755\n",
      "epoch: 2010, loss: 0.4754\n",
      "epoch: 2011, loss: 0.4754\n",
      "epoch: 2012, loss: 0.4753\n",
      "epoch: 2013, loss: 0.4753\n",
      "epoch: 2014, loss: 0.4753\n",
      "epoch: 2015, loss: 0.4752\n",
      "epoch: 2016, loss: 0.4752\n",
      "epoch: 2017, loss: 0.4751\n",
      "epoch: 2018, loss: 0.4751\n",
      "epoch: 2019, loss: 0.4751\n",
      "epoch: 2020, loss: 0.4750\n",
      "epoch: 2021, loss: 0.4750\n",
      "epoch: 2022, loss: 0.4749\n",
      "epoch: 2023, loss: 0.4749\n",
      "epoch: 2024, loss: 0.4749\n",
      "epoch: 2025, loss: 0.4748\n",
      "epoch: 2026, loss: 0.4748\n",
      "epoch: 2027, loss: 0.4747\n",
      "epoch: 2028, loss: 0.4747\n",
      "epoch: 2029, loss: 0.4746\n",
      "epoch: 2030, loss: 0.4746\n",
      "epoch: 2031, loss: 0.4746\n",
      "epoch: 2032, loss: 0.4745\n",
      "epoch: 2033, loss: 0.4745\n",
      "epoch: 2034, loss: 0.4744\n",
      "epoch: 2035, loss: 0.4744\n",
      "epoch: 2036, loss: 0.4744\n",
      "epoch: 2037, loss: 0.4743\n",
      "epoch: 2038, loss: 0.4743\n",
      "epoch: 2039, loss: 0.4742\n",
      "epoch: 2040, loss: 0.4742\n",
      "epoch: 2041, loss: 0.4742\n",
      "epoch: 2042, loss: 0.4741\n",
      "epoch: 2043, loss: 0.4741\n",
      "epoch: 2044, loss: 0.4740\n",
      "epoch: 2045, loss: 0.4740\n",
      "epoch: 2046, loss: 0.4740\n",
      "epoch: 2047, loss: 0.4739\n",
      "epoch: 2048, loss: 0.4739\n",
      "epoch: 2049, loss: 0.4738\n",
      "epoch: 2050, loss: 0.4738\n",
      "epoch: 2051, loss: 0.4738\n",
      "epoch: 2052, loss: 0.4737\n",
      "epoch: 2053, loss: 0.4737\n",
      "epoch: 2054, loss: 0.4736\n",
      "epoch: 2055, loss: 0.4736\n",
      "epoch: 2056, loss: 0.4736\n",
      "epoch: 2057, loss: 0.4735\n",
      "epoch: 2058, loss: 0.4735\n",
      "epoch: 2059, loss: 0.4734\n",
      "epoch: 2060, loss: 0.4734\n",
      "epoch: 2061, loss: 0.4733\n",
      "epoch: 2062, loss: 0.4733\n",
      "epoch: 2063, loss: 0.4733\n",
      "epoch: 2064, loss: 0.4732\n",
      "epoch: 2065, loss: 0.4732\n",
      "epoch: 2066, loss: 0.4731\n",
      "epoch: 2067, loss: 0.4731\n",
      "epoch: 2068, loss: 0.4731\n",
      "epoch: 2069, loss: 0.4730\n",
      "epoch: 2070, loss: 0.4730\n",
      "epoch: 2071, loss: 0.4729\n",
      "epoch: 2072, loss: 0.4729\n",
      "epoch: 2073, loss: 0.4729\n",
      "epoch: 2074, loss: 0.4728\n",
      "epoch: 2075, loss: 0.4728\n",
      "epoch: 2076, loss: 0.4728\n",
      "epoch: 2077, loss: 0.4727\n",
      "epoch: 2078, loss: 0.4727\n",
      "epoch: 2079, loss: 0.4726\n",
      "epoch: 2080, loss: 0.4726\n",
      "epoch: 2081, loss: 0.4726\n",
      "epoch: 2082, loss: 0.4725\n",
      "epoch: 2083, loss: 0.4725\n",
      "epoch: 2084, loss: 0.4724\n",
      "epoch: 2085, loss: 0.4724\n",
      "epoch: 2086, loss: 0.4724\n",
      "epoch: 2087, loss: 0.4723\n",
      "epoch: 2088, loss: 0.4723\n",
      "epoch: 2089, loss: 0.4722\n",
      "epoch: 2090, loss: 0.4722\n",
      "epoch: 2091, loss: 0.4722\n",
      "epoch: 2092, loss: 0.4721\n",
      "epoch: 2093, loss: 0.4721\n",
      "epoch: 2094, loss: 0.4720\n",
      "epoch: 2095, loss: 0.4720\n",
      "epoch: 2096, loss: 0.4720\n",
      "epoch: 2097, loss: 0.4719\n",
      "epoch: 2098, loss: 0.4719\n",
      "epoch: 2099, loss: 0.4718\n",
      "epoch: 2100, loss: 0.4718\n",
      "epoch: 2101, loss: 0.4718\n",
      "epoch: 2102, loss: 0.4717\n",
      "epoch: 2103, loss: 0.4717\n",
      "epoch: 2104, loss: 0.4716\n",
      "epoch: 2105, loss: 0.4716\n",
      "epoch: 2106, loss: 0.4716\n",
      "epoch: 2107, loss: 0.4715\n",
      "epoch: 2108, loss: 0.4715\n",
      "epoch: 2109, loss: 0.4715\n",
      "epoch: 2110, loss: 0.4714\n",
      "epoch: 2111, loss: 0.4714\n",
      "epoch: 2112, loss: 0.4713\n",
      "epoch: 2113, loss: 0.4713\n",
      "epoch: 2114, loss: 0.4713\n",
      "epoch: 2115, loss: 0.4712\n",
      "epoch: 2116, loss: 0.4712\n",
      "epoch: 2117, loss: 0.4711\n",
      "epoch: 2118, loss: 0.4711\n",
      "epoch: 2119, loss: 0.4711\n",
      "epoch: 2120, loss: 0.4710\n",
      "epoch: 2121, loss: 0.4710\n",
      "epoch: 2122, loss: 0.4709\n",
      "epoch: 2123, loss: 0.4709\n",
      "epoch: 2124, loss: 0.4709\n",
      "epoch: 2125, loss: 0.4708\n",
      "epoch: 2126, loss: 0.4708\n",
      "epoch: 2127, loss: 0.4708\n",
      "epoch: 2128, loss: 0.4707\n",
      "epoch: 2129, loss: 0.4707\n",
      "epoch: 2130, loss: 0.4706\n",
      "epoch: 2131, loss: 0.4706\n",
      "epoch: 2132, loss: 0.4706\n",
      "epoch: 2133, loss: 0.4705\n",
      "epoch: 2134, loss: 0.4705\n",
      "epoch: 2135, loss: 0.4704\n",
      "epoch: 2136, loss: 0.4704\n",
      "epoch: 2137, loss: 0.4704\n",
      "epoch: 2138, loss: 0.4703\n",
      "epoch: 2139, loss: 0.4703\n",
      "epoch: 2140, loss: 0.4703\n",
      "epoch: 2141, loss: 0.4702\n",
      "epoch: 2142, loss: 0.4702\n",
      "epoch: 2143, loss: 0.4701\n",
      "epoch: 2144, loss: 0.4701\n",
      "epoch: 2145, loss: 0.4701\n",
      "epoch: 2146, loss: 0.4700\n",
      "epoch: 2147, loss: 0.4700\n",
      "epoch: 2148, loss: 0.4699\n",
      "epoch: 2149, loss: 0.4699\n",
      "epoch: 2150, loss: 0.4699\n",
      "epoch: 2151, loss: 0.4698\n",
      "epoch: 2152, loss: 0.4698\n",
      "epoch: 2153, loss: 0.4698\n",
      "epoch: 2154, loss: 0.4697\n",
      "epoch: 2155, loss: 0.4697\n",
      "epoch: 2156, loss: 0.4696\n",
      "epoch: 2157, loss: 0.4696\n",
      "epoch: 2158, loss: 0.4696\n",
      "epoch: 2159, loss: 0.4695\n",
      "epoch: 2160, loss: 0.4695\n",
      "epoch: 2161, loss: 0.4695\n",
      "epoch: 2162, loss: 0.4694\n",
      "epoch: 2163, loss: 0.4694\n",
      "epoch: 2164, loss: 0.4693\n",
      "epoch: 2165, loss: 0.4693\n",
      "epoch: 2166, loss: 0.4693\n",
      "epoch: 2167, loss: 0.4692\n",
      "epoch: 2168, loss: 0.4692\n",
      "epoch: 2169, loss: 0.4692\n",
      "epoch: 2170, loss: 0.4691\n",
      "epoch: 2171, loss: 0.4691\n",
      "epoch: 2172, loss: 0.4690\n",
      "epoch: 2173, loss: 0.4690\n",
      "epoch: 2174, loss: 0.4690\n",
      "epoch: 2175, loss: 0.4689\n",
      "epoch: 2176, loss: 0.4689\n",
      "epoch: 2177, loss: 0.4689\n",
      "epoch: 2178, loss: 0.4688\n",
      "epoch: 2179, loss: 0.4688\n",
      "epoch: 2180, loss: 0.4687\n",
      "epoch: 2181, loss: 0.4687\n",
      "epoch: 2182, loss: 0.4687\n",
      "epoch: 2183, loss: 0.4686\n",
      "epoch: 2184, loss: 0.4686\n",
      "epoch: 2185, loss: 0.4686\n",
      "epoch: 2186, loss: 0.4685\n",
      "epoch: 2187, loss: 0.4685\n",
      "epoch: 2188, loss: 0.4684\n",
      "epoch: 2189, loss: 0.4684\n",
      "epoch: 2190, loss: 0.4684\n",
      "epoch: 2191, loss: 0.4683\n",
      "epoch: 2192, loss: 0.4683\n",
      "epoch: 2193, loss: 0.4683\n",
      "epoch: 2194, loss: 0.4682\n",
      "epoch: 2195, loss: 0.4682\n",
      "epoch: 2196, loss: 0.4681\n",
      "epoch: 2197, loss: 0.4681\n",
      "epoch: 2198, loss: 0.4681\n",
      "epoch: 2199, loss: 0.4680\n",
      "epoch: 2200, loss: 0.4680\n",
      "epoch: 2201, loss: 0.4680\n",
      "epoch: 2202, loss: 0.4679\n",
      "epoch: 2203, loss: 0.4679\n",
      "epoch: 2204, loss: 0.4678\n",
      "epoch: 2205, loss: 0.4678\n",
      "epoch: 2206, loss: 0.4678\n",
      "epoch: 2207, loss: 0.4677\n",
      "epoch: 2208, loss: 0.4677\n",
      "epoch: 2209, loss: 0.4677\n",
      "epoch: 2210, loss: 0.4676\n",
      "epoch: 2211, loss: 0.4676\n",
      "epoch: 2212, loss: 0.4676\n",
      "epoch: 2213, loss: 0.4675\n",
      "epoch: 2214, loss: 0.4675\n",
      "epoch: 2215, loss: 0.4674\n",
      "epoch: 2216, loss: 0.4674\n",
      "epoch: 2217, loss: 0.4674\n",
      "epoch: 2218, loss: 0.4673\n",
      "epoch: 2219, loss: 0.4673\n",
      "epoch: 2220, loss: 0.4673\n",
      "epoch: 2221, loss: 0.4672\n",
      "epoch: 2222, loss: 0.4672\n",
      "epoch: 2223, loss: 0.4672\n",
      "epoch: 2224, loss: 0.4671\n",
      "epoch: 2225, loss: 0.4671\n",
      "epoch: 2226, loss: 0.4670\n",
      "epoch: 2227, loss: 0.4670\n",
      "epoch: 2228, loss: 0.4670\n",
      "epoch: 2229, loss: 0.4669\n",
      "epoch: 2230, loss: 0.4669\n",
      "epoch: 2231, loss: 0.4669\n",
      "epoch: 2232, loss: 0.4668\n",
      "epoch: 2233, loss: 0.4668\n",
      "epoch: 2234, loss: 0.4668\n",
      "epoch: 2235, loss: 0.4667\n",
      "epoch: 2236, loss: 0.4667\n",
      "epoch: 2237, loss: 0.4666\n",
      "epoch: 2238, loss: 0.4666\n",
      "epoch: 2239, loss: 0.4666\n",
      "epoch: 2240, loss: 0.4665\n",
      "epoch: 2241, loss: 0.4665\n",
      "epoch: 2242, loss: 0.4665\n",
      "epoch: 2243, loss: 0.4664\n",
      "epoch: 2244, loss: 0.4664\n",
      "epoch: 2245, loss: 0.4664\n",
      "epoch: 2246, loss: 0.4663\n",
      "epoch: 2247, loss: 0.4663\n",
      "epoch: 2248, loss: 0.4662\n",
      "epoch: 2249, loss: 0.4662\n",
      "epoch: 2250, loss: 0.4662\n",
      "epoch: 2251, loss: 0.4661\n",
      "epoch: 2252, loss: 0.4661\n",
      "epoch: 2253, loss: 0.4661\n",
      "epoch: 2254, loss: 0.4660\n",
      "epoch: 2255, loss: 0.4660\n",
      "epoch: 2256, loss: 0.4660\n",
      "epoch: 2257, loss: 0.4659\n",
      "epoch: 2258, loss: 0.4659\n",
      "epoch: 2259, loss: 0.4659\n",
      "epoch: 2260, loss: 0.4658\n",
      "epoch: 2261, loss: 0.4658\n",
      "epoch: 2262, loss: 0.4657\n",
      "epoch: 2263, loss: 0.4657\n",
      "epoch: 2264, loss: 0.4657\n",
      "epoch: 2265, loss: 0.4656\n",
      "epoch: 2266, loss: 0.4656\n",
      "epoch: 2267, loss: 0.4656\n",
      "epoch: 2268, loss: 0.4655\n",
      "epoch: 2269, loss: 0.4655\n",
      "epoch: 2270, loss: 0.4655\n",
      "epoch: 2271, loss: 0.4654\n",
      "epoch: 2272, loss: 0.4654\n",
      "epoch: 2273, loss: 0.4654\n",
      "epoch: 2274, loss: 0.4653\n",
      "epoch: 2275, loss: 0.4653\n",
      "epoch: 2276, loss: 0.4652\n",
      "epoch: 2277, loss: 0.4652\n",
      "epoch: 2278, loss: 0.4652\n",
      "epoch: 2279, loss: 0.4651\n",
      "epoch: 2280, loss: 0.4651\n",
      "epoch: 2281, loss: 0.4651\n",
      "epoch: 2282, loss: 0.4650\n",
      "epoch: 2283, loss: 0.4650\n",
      "epoch: 2284, loss: 0.4650\n",
      "epoch: 2285, loss: 0.4649\n",
      "epoch: 2286, loss: 0.4649\n",
      "epoch: 2287, loss: 0.4649\n",
      "epoch: 2288, loss: 0.4648\n",
      "epoch: 2289, loss: 0.4648\n",
      "epoch: 2290, loss: 0.4648\n",
      "epoch: 2291, loss: 0.4647\n",
      "epoch: 2292, loss: 0.4647\n",
      "epoch: 2293, loss: 0.4646\n",
      "epoch: 2294, loss: 0.4646\n",
      "epoch: 2295, loss: 0.4646\n",
      "epoch: 2296, loss: 0.4645\n",
      "epoch: 2297, loss: 0.4645\n",
      "epoch: 2298, loss: 0.4645\n",
      "epoch: 2299, loss: 0.4644\n",
      "epoch: 2300, loss: 0.4644\n",
      "epoch: 2301, loss: 0.4644\n",
      "epoch: 2302, loss: 0.4643\n",
      "epoch: 2303, loss: 0.4643\n",
      "epoch: 2304, loss: 0.4643\n",
      "epoch: 2305, loss: 0.4642\n",
      "epoch: 2306, loss: 0.4642\n",
      "epoch: 2307, loss: 0.4642\n",
      "epoch: 2308, loss: 0.4641\n",
      "epoch: 2309, loss: 0.4641\n",
      "epoch: 2310, loss: 0.4641\n",
      "epoch: 2311, loss: 0.4640\n",
      "epoch: 2312, loss: 0.4640\n",
      "epoch: 2313, loss: 0.4640\n",
      "epoch: 2314, loss: 0.4639\n",
      "epoch: 2315, loss: 0.4639\n",
      "epoch: 2316, loss: 0.4638\n",
      "epoch: 2317, loss: 0.4638\n",
      "epoch: 2318, loss: 0.4638\n",
      "epoch: 2319, loss: 0.4637\n",
      "epoch: 2320, loss: 0.4637\n",
      "epoch: 2321, loss: 0.4637\n",
      "epoch: 2322, loss: 0.4636\n",
      "epoch: 2323, loss: 0.4636\n",
      "epoch: 2324, loss: 0.4636\n",
      "epoch: 2325, loss: 0.4635\n",
      "epoch: 2326, loss: 0.4635\n",
      "epoch: 2327, loss: 0.4635\n",
      "epoch: 2328, loss: 0.4634\n",
      "epoch: 2329, loss: 0.4634\n",
      "epoch: 2330, loss: 0.4634\n",
      "epoch: 2331, loss: 0.4633\n",
      "epoch: 2332, loss: 0.4633\n",
      "epoch: 2333, loss: 0.4633\n",
      "epoch: 2334, loss: 0.4632\n",
      "epoch: 2335, loss: 0.4632\n",
      "epoch: 2336, loss: 0.4632\n",
      "epoch: 2337, loss: 0.4631\n",
      "epoch: 2338, loss: 0.4631\n",
      "epoch: 2339, loss: 0.4631\n",
      "epoch: 2340, loss: 0.4630\n",
      "epoch: 2341, loss: 0.4630\n",
      "epoch: 2342, loss: 0.4630\n",
      "epoch: 2343, loss: 0.4629\n",
      "epoch: 2344, loss: 0.4629\n",
      "epoch: 2345, loss: 0.4629\n",
      "epoch: 2346, loss: 0.4628\n",
      "epoch: 2347, loss: 0.4628\n",
      "epoch: 2348, loss: 0.4627\n",
      "epoch: 2349, loss: 0.4627\n",
      "epoch: 2350, loss: 0.4627\n",
      "epoch: 2351, loss: 0.4626\n",
      "epoch: 2352, loss: 0.4626\n",
      "epoch: 2353, loss: 0.4626\n",
      "epoch: 2354, loss: 0.4625\n",
      "epoch: 2355, loss: 0.4625\n",
      "epoch: 2356, loss: 0.4625\n",
      "epoch: 2357, loss: 0.4624\n",
      "epoch: 2358, loss: 0.4624\n",
      "epoch: 2359, loss: 0.4624\n",
      "epoch: 2360, loss: 0.4623\n",
      "epoch: 2361, loss: 0.4623\n",
      "epoch: 2362, loss: 0.4623\n",
      "epoch: 2363, loss: 0.4622\n",
      "epoch: 2364, loss: 0.4622\n",
      "epoch: 2365, loss: 0.4622\n",
      "epoch: 2366, loss: 0.4621\n",
      "epoch: 2367, loss: 0.4621\n",
      "epoch: 2368, loss: 0.4621\n",
      "epoch: 2369, loss: 0.4620\n",
      "epoch: 2370, loss: 0.4620\n",
      "epoch: 2371, loss: 0.4620\n",
      "epoch: 2372, loss: 0.4619\n",
      "epoch: 2373, loss: 0.4619\n",
      "epoch: 2374, loss: 0.4619\n",
      "epoch: 2375, loss: 0.4618\n",
      "epoch: 2376, loss: 0.4618\n",
      "epoch: 2377, loss: 0.4618\n",
      "epoch: 2378, loss: 0.4617\n",
      "epoch: 2379, loss: 0.4617\n",
      "epoch: 2380, loss: 0.4617\n",
      "epoch: 2381, loss: 0.4616\n",
      "epoch: 2382, loss: 0.4616\n",
      "epoch: 2383, loss: 0.4616\n",
      "epoch: 2384, loss: 0.4615\n",
      "epoch: 2385, loss: 0.4615\n",
      "epoch: 2386, loss: 0.4615\n",
      "epoch: 2387, loss: 0.4614\n",
      "epoch: 2388, loss: 0.4614\n",
      "epoch: 2389, loss: 0.4614\n",
      "epoch: 2390, loss: 0.4613\n",
      "epoch: 2391, loss: 0.4613\n",
      "epoch: 2392, loss: 0.4613\n",
      "epoch: 2393, loss: 0.4612\n",
      "epoch: 2394, loss: 0.4612\n",
      "epoch: 2395, loss: 0.4612\n",
      "epoch: 2396, loss: 0.4611\n",
      "epoch: 2397, loss: 0.4611\n",
      "epoch: 2398, loss: 0.4611\n",
      "epoch: 2399, loss: 0.4610\n",
      "epoch: 2400, loss: 0.4610\n",
      "epoch: 2401, loss: 0.4610\n",
      "epoch: 2402, loss: 0.4609\n",
      "epoch: 2403, loss: 0.4609\n",
      "epoch: 2404, loss: 0.4609\n",
      "epoch: 2405, loss: 0.4608\n",
      "epoch: 2406, loss: 0.4608\n",
      "epoch: 2407, loss: 0.4608\n",
      "epoch: 2408, loss: 0.4607\n",
      "epoch: 2409, loss: 0.4607\n",
      "epoch: 2410, loss: 0.4607\n",
      "epoch: 2411, loss: 0.4606\n",
      "epoch: 2412, loss: 0.4606\n",
      "epoch: 2413, loss: 0.4606\n",
      "epoch: 2414, loss: 0.4605\n",
      "epoch: 2415, loss: 0.4605\n",
      "epoch: 2416, loss: 0.4605\n",
      "epoch: 2417, loss: 0.4604\n",
      "epoch: 2418, loss: 0.4604\n",
      "epoch: 2419, loss: 0.4604\n",
      "epoch: 2420, loss: 0.4603\n",
      "epoch: 2421, loss: 0.4603\n",
      "epoch: 2422, loss: 0.4603\n",
      "epoch: 2423, loss: 0.4602\n",
      "epoch: 2424, loss: 0.4602\n",
      "epoch: 2425, loss: 0.4602\n",
      "epoch: 2426, loss: 0.4601\n",
      "epoch: 2427, loss: 0.4601\n",
      "epoch: 2428, loss: 0.4601\n",
      "epoch: 2429, loss: 0.4601\n",
      "epoch: 2430, loss: 0.4600\n",
      "epoch: 2431, loss: 0.4600\n",
      "epoch: 2432, loss: 0.4600\n",
      "epoch: 2433, loss: 0.4599\n",
      "epoch: 2434, loss: 0.4599\n",
      "epoch: 2435, loss: 0.4599\n",
      "epoch: 2436, loss: 0.4598\n",
      "epoch: 2437, loss: 0.4598\n",
      "epoch: 2438, loss: 0.4598\n",
      "epoch: 2439, loss: 0.4597\n",
      "epoch: 2440, loss: 0.4597\n",
      "epoch: 2441, loss: 0.4597\n",
      "epoch: 2442, loss: 0.4596\n",
      "epoch: 2443, loss: 0.4596\n",
      "epoch: 2444, loss: 0.4596\n",
      "epoch: 2445, loss: 0.4595\n",
      "epoch: 2446, loss: 0.4595\n",
      "epoch: 2447, loss: 0.4595\n",
      "epoch: 2448, loss: 0.4594\n",
      "epoch: 2449, loss: 0.4594\n",
      "epoch: 2450, loss: 0.4594\n",
      "epoch: 2451, loss: 0.4593\n",
      "epoch: 2452, loss: 0.4593\n",
      "epoch: 2453, loss: 0.4593\n",
      "epoch: 2454, loss: 0.4592\n",
      "epoch: 2455, loss: 0.4592\n",
      "epoch: 2456, loss: 0.4592\n",
      "epoch: 2457, loss: 0.4591\n",
      "epoch: 2458, loss: 0.4591\n",
      "epoch: 2459, loss: 0.4591\n",
      "epoch: 2460, loss: 0.4590\n",
      "epoch: 2461, loss: 0.4590\n",
      "epoch: 2462, loss: 0.4590\n",
      "epoch: 2463, loss: 0.4590\n",
      "epoch: 2464, loss: 0.4589\n",
      "epoch: 2465, loss: 0.4589\n",
      "epoch: 2466, loss: 0.4589\n",
      "epoch: 2467, loss: 0.4588\n",
      "epoch: 2468, loss: 0.4588\n",
      "epoch: 2469, loss: 0.4588\n",
      "epoch: 2470, loss: 0.4587\n",
      "epoch: 2471, loss: 0.4587\n",
      "epoch: 2472, loss: 0.4587\n",
      "epoch: 2473, loss: 0.4586\n",
      "epoch: 2474, loss: 0.4586\n",
      "epoch: 2475, loss: 0.4586\n",
      "epoch: 2476, loss: 0.4585\n",
      "epoch: 2477, loss: 0.4585\n",
      "epoch: 2478, loss: 0.4585\n",
      "epoch: 2479, loss: 0.4584\n",
      "epoch: 2480, loss: 0.4584\n",
      "epoch: 2481, loss: 0.4584\n",
      "epoch: 2482, loss: 0.4583\n",
      "epoch: 2483, loss: 0.4583\n",
      "epoch: 2484, loss: 0.4583\n",
      "epoch: 2485, loss: 0.4583\n",
      "epoch: 2486, loss: 0.4582\n",
      "epoch: 2487, loss: 0.4582\n",
      "epoch: 2488, loss: 0.4582\n",
      "epoch: 2489, loss: 0.4581\n",
      "epoch: 2490, loss: 0.4581\n",
      "epoch: 2491, loss: 0.4581\n",
      "epoch: 2492, loss: 0.4580\n",
      "epoch: 2493, loss: 0.4580\n",
      "epoch: 2494, loss: 0.4580\n",
      "epoch: 2495, loss: 0.4579\n",
      "epoch: 2496, loss: 0.4579\n",
      "epoch: 2497, loss: 0.4579\n",
      "epoch: 2498, loss: 0.4578\n",
      "epoch: 2499, loss: 0.4578\n",
      "epoch: 2500, loss: 0.4578\n",
      "epoch: 2501, loss: 0.4577\n",
      "epoch: 2502, loss: 0.4577\n",
      "epoch: 2503, loss: 0.4577\n",
      "epoch: 2504, loss: 0.4577\n",
      "epoch: 2505, loss: 0.4576\n",
      "epoch: 2506, loss: 0.4576\n",
      "epoch: 2507, loss: 0.4576\n",
      "epoch: 2508, loss: 0.4575\n",
      "epoch: 2509, loss: 0.4575\n",
      "epoch: 2510, loss: 0.4575\n",
      "epoch: 2511, loss: 0.4574\n",
      "epoch: 2512, loss: 0.4574\n",
      "epoch: 2513, loss: 0.4574\n",
      "epoch: 2514, loss: 0.4573\n",
      "epoch: 2515, loss: 0.4573\n",
      "epoch: 2516, loss: 0.4573\n",
      "epoch: 2517, loss: 0.4572\n",
      "epoch: 2518, loss: 0.4572\n",
      "epoch: 2519, loss: 0.4572\n",
      "epoch: 2520, loss: 0.4572\n",
      "epoch: 2521, loss: 0.4571\n",
      "epoch: 2522, loss: 0.4571\n",
      "epoch: 2523, loss: 0.4571\n",
      "epoch: 2524, loss: 0.4570\n",
      "epoch: 2525, loss: 0.4570\n",
      "epoch: 2526, loss: 0.4570\n",
      "epoch: 2527, loss: 0.4569\n",
      "epoch: 2528, loss: 0.4569\n",
      "epoch: 2529, loss: 0.4569\n",
      "epoch: 2530, loss: 0.4568\n",
      "epoch: 2531, loss: 0.4568\n",
      "epoch: 2532, loss: 0.4568\n",
      "epoch: 2533, loss: 0.4568\n",
      "epoch: 2534, loss: 0.4567\n",
      "epoch: 2535, loss: 0.4567\n",
      "epoch: 2536, loss: 0.4567\n",
      "epoch: 2537, loss: 0.4566\n",
      "epoch: 2538, loss: 0.4566\n",
      "epoch: 2539, loss: 0.4566\n",
      "epoch: 2540, loss: 0.4565\n",
      "epoch: 2541, loss: 0.4565\n",
      "epoch: 2542, loss: 0.4565\n",
      "epoch: 2543, loss: 0.4564\n",
      "epoch: 2544, loss: 0.4564\n",
      "epoch: 2545, loss: 0.4564\n",
      "epoch: 2546, loss: 0.4564\n",
      "epoch: 2547, loss: 0.4563\n",
      "epoch: 2548, loss: 0.4563\n",
      "epoch: 2549, loss: 0.4563\n",
      "epoch: 2550, loss: 0.4562\n",
      "epoch: 2551, loss: 0.4562\n",
      "epoch: 2552, loss: 0.4562\n",
      "epoch: 2553, loss: 0.4561\n",
      "epoch: 2554, loss: 0.4561\n",
      "epoch: 2555, loss: 0.4561\n",
      "epoch: 2556, loss: 0.4560\n",
      "epoch: 2557, loss: 0.4560\n",
      "epoch: 2558, loss: 0.4560\n",
      "epoch: 2559, loss: 0.4560\n",
      "epoch: 2560, loss: 0.4559\n",
      "epoch: 2561, loss: 0.4559\n",
      "epoch: 2562, loss: 0.4559\n",
      "epoch: 2563, loss: 0.4558\n",
      "epoch: 2564, loss: 0.4558\n",
      "epoch: 2565, loss: 0.4558\n",
      "epoch: 2566, loss: 0.4557\n",
      "epoch: 2567, loss: 0.4557\n",
      "epoch: 2568, loss: 0.4557\n",
      "epoch: 2569, loss: 0.4557\n",
      "epoch: 2570, loss: 0.4556\n",
      "epoch: 2571, loss: 0.4556\n",
      "epoch: 2572, loss: 0.4556\n",
      "epoch: 2573, loss: 0.4555\n",
      "epoch: 2574, loss: 0.4555\n",
      "epoch: 2575, loss: 0.4555\n",
      "epoch: 2576, loss: 0.4554\n",
      "epoch: 2577, loss: 0.4554\n",
      "epoch: 2578, loss: 0.4554\n",
      "epoch: 2579, loss: 0.4553\n",
      "epoch: 2580, loss: 0.4553\n",
      "epoch: 2581, loss: 0.4553\n",
      "epoch: 2582, loss: 0.4553\n",
      "epoch: 2583, loss: 0.4552\n",
      "epoch: 2584, loss: 0.4552\n",
      "epoch: 2585, loss: 0.4552\n",
      "epoch: 2586, loss: 0.4551\n",
      "epoch: 2587, loss: 0.4551\n",
      "epoch: 2588, loss: 0.4551\n",
      "epoch: 2589, loss: 0.4550\n",
      "epoch: 2590, loss: 0.4550\n",
      "epoch: 2591, loss: 0.4550\n",
      "epoch: 2592, loss: 0.4550\n",
      "epoch: 2593, loss: 0.4549\n",
      "epoch: 2594, loss: 0.4549\n",
      "epoch: 2595, loss: 0.4549\n",
      "epoch: 2596, loss: 0.4548\n",
      "epoch: 2597, loss: 0.4548\n",
      "epoch: 2598, loss: 0.4548\n",
      "epoch: 2599, loss: 0.4547\n",
      "epoch: 2600, loss: 0.4547\n",
      "epoch: 2601, loss: 0.4547\n",
      "epoch: 2602, loss: 0.4547\n",
      "epoch: 2603, loss: 0.4546\n",
      "epoch: 2604, loss: 0.4546\n",
      "epoch: 2605, loss: 0.4546\n",
      "epoch: 2606, loss: 0.4545\n",
      "epoch: 2607, loss: 0.4545\n",
      "epoch: 2608, loss: 0.4545\n",
      "epoch: 2609, loss: 0.4545\n",
      "epoch: 2610, loss: 0.4544\n",
      "epoch: 2611, loss: 0.4544\n",
      "epoch: 2612, loss: 0.4544\n",
      "epoch: 2613, loss: 0.4543\n",
      "epoch: 2614, loss: 0.4543\n",
      "epoch: 2615, loss: 0.4543\n",
      "epoch: 2616, loss: 0.4542\n",
      "epoch: 2617, loss: 0.4542\n",
      "epoch: 2618, loss: 0.4542\n",
      "epoch: 2619, loss: 0.4542\n",
      "epoch: 2620, loss: 0.4541\n",
      "epoch: 2621, loss: 0.4541\n",
      "epoch: 2622, loss: 0.4541\n",
      "epoch: 2623, loss: 0.4540\n",
      "epoch: 2624, loss: 0.4540\n",
      "epoch: 2625, loss: 0.4540\n",
      "epoch: 2626, loss: 0.4539\n",
      "epoch: 2627, loss: 0.4539\n",
      "epoch: 2628, loss: 0.4539\n",
      "epoch: 2629, loss: 0.4539\n",
      "epoch: 2630, loss: 0.4538\n",
      "epoch: 2631, loss: 0.4538\n",
      "epoch: 2632, loss: 0.4538\n",
      "epoch: 2633, loss: 0.4537\n",
      "epoch: 2634, loss: 0.4537\n",
      "epoch: 2635, loss: 0.4537\n",
      "epoch: 2636, loss: 0.4537\n",
      "epoch: 2637, loss: 0.4536\n",
      "epoch: 2638, loss: 0.4536\n",
      "epoch: 2639, loss: 0.4536\n",
      "epoch: 2640, loss: 0.4535\n",
      "epoch: 2641, loss: 0.4535\n",
      "epoch: 2642, loss: 0.4535\n",
      "epoch: 2643, loss: 0.4534\n",
      "epoch: 2644, loss: 0.4534\n",
      "epoch: 2645, loss: 0.4534\n",
      "epoch: 2646, loss: 0.4534\n",
      "epoch: 2647, loss: 0.4533\n",
      "epoch: 2648, loss: 0.4533\n",
      "epoch: 2649, loss: 0.4533\n",
      "epoch: 2650, loss: 0.4532\n",
      "epoch: 2651, loss: 0.4532\n",
      "epoch: 2652, loss: 0.4532\n",
      "epoch: 2653, loss: 0.4532\n",
      "epoch: 2654, loss: 0.4531\n",
      "epoch: 2655, loss: 0.4531\n",
      "epoch: 2656, loss: 0.4531\n",
      "epoch: 2657, loss: 0.4530\n",
      "epoch: 2658, loss: 0.4530\n",
      "epoch: 2659, loss: 0.4530\n",
      "epoch: 2660, loss: 0.4530\n",
      "epoch: 2661, loss: 0.4529\n",
      "epoch: 2662, loss: 0.4529\n",
      "epoch: 2663, loss: 0.4529\n",
      "epoch: 2664, loss: 0.4528\n",
      "epoch: 2665, loss: 0.4528\n",
      "epoch: 2666, loss: 0.4528\n",
      "epoch: 2667, loss: 0.4528\n",
      "epoch: 2668, loss: 0.4527\n",
      "epoch: 2669, loss: 0.4527\n",
      "epoch: 2670, loss: 0.4527\n",
      "epoch: 2671, loss: 0.4526\n",
      "epoch: 2672, loss: 0.4526\n",
      "epoch: 2673, loss: 0.4526\n",
      "epoch: 2674, loss: 0.4525\n",
      "epoch: 2675, loss: 0.4525\n",
      "epoch: 2676, loss: 0.4525\n",
      "epoch: 2677, loss: 0.4525\n",
      "epoch: 2678, loss: 0.4524\n",
      "epoch: 2679, loss: 0.4524\n",
      "epoch: 2680, loss: 0.4524\n",
      "epoch: 2681, loss: 0.4523\n",
      "epoch: 2682, loss: 0.4523\n",
      "epoch: 2683, loss: 0.4523\n",
      "epoch: 2684, loss: 0.4523\n",
      "epoch: 2685, loss: 0.4522\n",
      "epoch: 2686, loss: 0.4522\n",
      "epoch: 2687, loss: 0.4522\n",
      "epoch: 2688, loss: 0.4521\n",
      "epoch: 2689, loss: 0.4521\n",
      "epoch: 2690, loss: 0.4521\n",
      "epoch: 2691, loss: 0.4521\n",
      "epoch: 2692, loss: 0.4520\n",
      "epoch: 2693, loss: 0.4520\n",
      "epoch: 2694, loss: 0.4520\n",
      "epoch: 2695, loss: 0.4519\n",
      "epoch: 2696, loss: 0.4519\n",
      "epoch: 2697, loss: 0.4519\n",
      "epoch: 2698, loss: 0.4519\n",
      "epoch: 2699, loss: 0.4518\n",
      "epoch: 2700, loss: 0.4518\n",
      "epoch: 2701, loss: 0.4518\n",
      "epoch: 2702, loss: 0.4517\n",
      "epoch: 2703, loss: 0.4517\n",
      "epoch: 2704, loss: 0.4517\n",
      "epoch: 2705, loss: 0.4517\n",
      "epoch: 2706, loss: 0.4516\n",
      "epoch: 2707, loss: 0.4516\n",
      "epoch: 2708, loss: 0.4516\n",
      "epoch: 2709, loss: 0.4516\n",
      "epoch: 2710, loss: 0.4515\n",
      "epoch: 2711, loss: 0.4515\n",
      "epoch: 2712, loss: 0.4515\n",
      "epoch: 2713, loss: 0.4514\n",
      "epoch: 2714, loss: 0.4514\n",
      "epoch: 2715, loss: 0.4514\n",
      "epoch: 2716, loss: 0.4514\n",
      "epoch: 2717, loss: 0.4513\n",
      "epoch: 2718, loss: 0.4513\n",
      "epoch: 2719, loss: 0.4513\n",
      "epoch: 2720, loss: 0.4512\n",
      "epoch: 2721, loss: 0.4512\n",
      "epoch: 2722, loss: 0.4512\n",
      "epoch: 2723, loss: 0.4512\n",
      "epoch: 2724, loss: 0.4511\n",
      "epoch: 2725, loss: 0.4511\n",
      "epoch: 2726, loss: 0.4511\n",
      "epoch: 2727, loss: 0.4510\n",
      "epoch: 2728, loss: 0.4510\n",
      "epoch: 2729, loss: 0.4510\n",
      "epoch: 2730, loss: 0.4510\n",
      "epoch: 2731, loss: 0.4509\n",
      "epoch: 2732, loss: 0.4509\n",
      "epoch: 2733, loss: 0.4509\n",
      "epoch: 2734, loss: 0.4508\n",
      "epoch: 2735, loss: 0.4508\n",
      "epoch: 2736, loss: 0.4508\n",
      "epoch: 2737, loss: 0.4508\n",
      "epoch: 2738, loss: 0.4507\n",
      "epoch: 2739, loss: 0.4507\n",
      "epoch: 2740, loss: 0.4507\n",
      "epoch: 2741, loss: 0.4507\n",
      "epoch: 2742, loss: 0.4506\n",
      "epoch: 2743, loss: 0.4506\n",
      "epoch: 2744, loss: 0.4506\n",
      "epoch: 2745, loss: 0.4505\n",
      "epoch: 2746, loss: 0.4505\n",
      "epoch: 2747, loss: 0.4505\n",
      "epoch: 2748, loss: 0.4505\n",
      "epoch: 2749, loss: 0.4504\n",
      "epoch: 2750, loss: 0.4504\n",
      "epoch: 2751, loss: 0.4504\n",
      "epoch: 2752, loss: 0.4503\n",
      "epoch: 2753, loss: 0.4503\n",
      "epoch: 2754, loss: 0.4503\n",
      "epoch: 2755, loss: 0.4503\n",
      "epoch: 2756, loss: 0.4502\n",
      "epoch: 2757, loss: 0.4502\n",
      "epoch: 2758, loss: 0.4502\n",
      "epoch: 2759, loss: 0.4502\n",
      "epoch: 2760, loss: 0.4501\n",
      "epoch: 2761, loss: 0.4501\n",
      "epoch: 2762, loss: 0.4501\n",
      "epoch: 2763, loss: 0.4500\n",
      "epoch: 2764, loss: 0.4500\n",
      "epoch: 2765, loss: 0.4500\n",
      "epoch: 2766, loss: 0.4500\n",
      "epoch: 2767, loss: 0.4499\n",
      "epoch: 2768, loss: 0.4499\n",
      "epoch: 2769, loss: 0.4499\n",
      "epoch: 2770, loss: 0.4498\n",
      "epoch: 2771, loss: 0.4498\n",
      "epoch: 2772, loss: 0.4498\n",
      "epoch: 2773, loss: 0.4498\n",
      "epoch: 2774, loss: 0.4497\n",
      "epoch: 2775, loss: 0.4497\n",
      "epoch: 2776, loss: 0.4497\n",
      "epoch: 2777, loss: 0.4497\n",
      "epoch: 2778, loss: 0.4496\n",
      "epoch: 2779, loss: 0.4496\n",
      "epoch: 2780, loss: 0.4496\n",
      "epoch: 2781, loss: 0.4495\n",
      "epoch: 2782, loss: 0.4495\n",
      "epoch: 2783, loss: 0.4495\n",
      "epoch: 2784, loss: 0.4495\n",
      "epoch: 2785, loss: 0.4494\n",
      "epoch: 2786, loss: 0.4494\n",
      "epoch: 2787, loss: 0.4494\n",
      "epoch: 2788, loss: 0.4494\n",
      "epoch: 2789, loss: 0.4493\n",
      "epoch: 2790, loss: 0.4493\n",
      "epoch: 2791, loss: 0.4493\n",
      "epoch: 2792, loss: 0.4492\n",
      "epoch: 2793, loss: 0.4492\n",
      "epoch: 2794, loss: 0.4492\n",
      "epoch: 2795, loss: 0.4492\n",
      "epoch: 2796, loss: 0.4491\n",
      "epoch: 2797, loss: 0.4491\n",
      "epoch: 2798, loss: 0.4491\n",
      "epoch: 2799, loss: 0.4491\n",
      "epoch: 2800, loss: 0.4490\n",
      "epoch: 2801, loss: 0.4490\n",
      "epoch: 2802, loss: 0.4490\n",
      "epoch: 2803, loss: 0.4489\n",
      "epoch: 2804, loss: 0.4489\n",
      "epoch: 2805, loss: 0.4489\n",
      "epoch: 2806, loss: 0.4489\n",
      "epoch: 2807, loss: 0.4488\n",
      "epoch: 2808, loss: 0.4488\n",
      "epoch: 2809, loss: 0.4488\n",
      "epoch: 2810, loss: 0.4488\n",
      "epoch: 2811, loss: 0.4487\n",
      "epoch: 2812, loss: 0.4487\n",
      "epoch: 2813, loss: 0.4487\n",
      "epoch: 2814, loss: 0.4487\n",
      "epoch: 2815, loss: 0.4486\n",
      "epoch: 2816, loss: 0.4486\n",
      "epoch: 2817, loss: 0.4486\n",
      "epoch: 2818, loss: 0.4485\n",
      "epoch: 2819, loss: 0.4485\n",
      "epoch: 2820, loss: 0.4485\n",
      "epoch: 2821, loss: 0.4485\n",
      "epoch: 2822, loss: 0.4484\n",
      "epoch: 2823, loss: 0.4484\n",
      "epoch: 2824, loss: 0.4484\n",
      "epoch: 2825, loss: 0.4484\n",
      "epoch: 2826, loss: 0.4483\n",
      "epoch: 2827, loss: 0.4483\n",
      "epoch: 2828, loss: 0.4483\n",
      "epoch: 2829, loss: 0.4483\n",
      "epoch: 2830, loss: 0.4482\n",
      "epoch: 2831, loss: 0.4482\n",
      "epoch: 2832, loss: 0.4482\n",
      "epoch: 2833, loss: 0.4481\n",
      "epoch: 2834, loss: 0.4481\n",
      "epoch: 2835, loss: 0.4481\n",
      "epoch: 2836, loss: 0.4481\n",
      "epoch: 2837, loss: 0.4480\n",
      "epoch: 2838, loss: 0.4480\n",
      "epoch: 2839, loss: 0.4480\n",
      "epoch: 2840, loss: 0.4480\n",
      "epoch: 2841, loss: 0.4479\n",
      "epoch: 2842, loss: 0.4479\n",
      "epoch: 2843, loss: 0.4479\n",
      "epoch: 2844, loss: 0.4479\n",
      "epoch: 2845, loss: 0.4478\n",
      "epoch: 2846, loss: 0.4478\n",
      "epoch: 2847, loss: 0.4478\n",
      "epoch: 2848, loss: 0.4477\n",
      "epoch: 2849, loss: 0.4477\n",
      "epoch: 2850, loss: 0.4477\n",
      "epoch: 2851, loss: 0.4477\n",
      "epoch: 2852, loss: 0.4476\n",
      "epoch: 2853, loss: 0.4476\n",
      "epoch: 2854, loss: 0.4476\n",
      "epoch: 2855, loss: 0.4476\n",
      "epoch: 2856, loss: 0.4475\n",
      "epoch: 2857, loss: 0.4475\n",
      "epoch: 2858, loss: 0.4475\n",
      "epoch: 2859, loss: 0.4475\n",
      "epoch: 2860, loss: 0.4474\n",
      "epoch: 2861, loss: 0.4474\n",
      "epoch: 2862, loss: 0.4474\n",
      "epoch: 2863, loss: 0.4473\n",
      "epoch: 2864, loss: 0.4473\n",
      "epoch: 2865, loss: 0.4473\n",
      "epoch: 2866, loss: 0.4473\n",
      "epoch: 2867, loss: 0.4472\n",
      "epoch: 2868, loss: 0.4472\n",
      "epoch: 2869, loss: 0.4472\n",
      "epoch: 2870, loss: 0.4472\n",
      "epoch: 2871, loss: 0.4471\n",
      "epoch: 2872, loss: 0.4471\n",
      "epoch: 2873, loss: 0.4471\n",
      "epoch: 2874, loss: 0.4471\n",
      "epoch: 2875, loss: 0.4470\n",
      "epoch: 2876, loss: 0.4470\n",
      "epoch: 2877, loss: 0.4470\n",
      "epoch: 2878, loss: 0.4470\n",
      "epoch: 2879, loss: 0.4469\n",
      "epoch: 2880, loss: 0.4469\n",
      "epoch: 2881, loss: 0.4469\n",
      "epoch: 2882, loss: 0.4469\n",
      "epoch: 2883, loss: 0.4468\n",
      "epoch: 2884, loss: 0.4468\n",
      "epoch: 2885, loss: 0.4468\n",
      "epoch: 2886, loss: 0.4467\n",
      "epoch: 2887, loss: 0.4467\n",
      "epoch: 2888, loss: 0.4467\n",
      "epoch: 2889, loss: 0.4467\n",
      "epoch: 2890, loss: 0.4466\n",
      "epoch: 2891, loss: 0.4466\n",
      "epoch: 2892, loss: 0.4466\n",
      "epoch: 2893, loss: 0.4466\n",
      "epoch: 2894, loss: 0.4465\n",
      "epoch: 2895, loss: 0.4465\n",
      "epoch: 2896, loss: 0.4465\n",
      "epoch: 2897, loss: 0.4465\n",
      "epoch: 2898, loss: 0.4464\n",
      "epoch: 2899, loss: 0.4464\n",
      "epoch: 2900, loss: 0.4464\n",
      "epoch: 2901, loss: 0.4464\n",
      "epoch: 2902, loss: 0.4463\n",
      "epoch: 2903, loss: 0.4463\n",
      "epoch: 2904, loss: 0.4463\n",
      "epoch: 2905, loss: 0.4463\n",
      "epoch: 2906, loss: 0.4462\n",
      "epoch: 2907, loss: 0.4462\n",
      "epoch: 2908, loss: 0.4462\n",
      "epoch: 2909, loss: 0.4462\n",
      "epoch: 2910, loss: 0.4461\n",
      "epoch: 2911, loss: 0.4461\n",
      "epoch: 2912, loss: 0.4461\n",
      "epoch: 2913, loss: 0.4460\n",
      "epoch: 2914, loss: 0.4460\n",
      "epoch: 2915, loss: 0.4460\n",
      "epoch: 2916, loss: 0.4460\n",
      "epoch: 2917, loss: 0.4459\n",
      "epoch: 2918, loss: 0.4459\n",
      "epoch: 2919, loss: 0.4459\n",
      "epoch: 2920, loss: 0.4459\n",
      "epoch: 2921, loss: 0.4458\n",
      "epoch: 2922, loss: 0.4458\n",
      "epoch: 2923, loss: 0.4458\n",
      "epoch: 2924, loss: 0.4458\n",
      "epoch: 2925, loss: 0.4457\n",
      "epoch: 2926, loss: 0.4457\n",
      "epoch: 2927, loss: 0.4457\n",
      "epoch: 2928, loss: 0.4457\n",
      "epoch: 2929, loss: 0.4456\n",
      "epoch: 2930, loss: 0.4456\n",
      "epoch: 2931, loss: 0.4456\n",
      "epoch: 2932, loss: 0.4456\n",
      "epoch: 2933, loss: 0.4455\n",
      "epoch: 2934, loss: 0.4455\n",
      "epoch: 2935, loss: 0.4455\n",
      "epoch: 2936, loss: 0.4455\n",
      "epoch: 2937, loss: 0.4454\n",
      "epoch: 2938, loss: 0.4454\n",
      "epoch: 2939, loss: 0.4454\n",
      "epoch: 2940, loss: 0.4454\n",
      "epoch: 2941, loss: 0.4453\n",
      "epoch: 2942, loss: 0.4453\n",
      "epoch: 2943, loss: 0.4453\n",
      "epoch: 2944, loss: 0.4453\n",
      "epoch: 2945, loss: 0.4452\n",
      "epoch: 2946, loss: 0.4452\n",
      "epoch: 2947, loss: 0.4452\n",
      "epoch: 2948, loss: 0.4452\n",
      "epoch: 2949, loss: 0.4451\n",
      "epoch: 2950, loss: 0.4451\n",
      "epoch: 2951, loss: 0.4451\n",
      "epoch: 2952, loss: 0.4451\n",
      "epoch: 2953, loss: 0.4450\n",
      "epoch: 2954, loss: 0.4450\n",
      "epoch: 2955, loss: 0.4450\n",
      "epoch: 2956, loss: 0.4450\n",
      "epoch: 2957, loss: 0.4449\n",
      "epoch: 2958, loss: 0.4449\n",
      "epoch: 2959, loss: 0.4449\n",
      "epoch: 2960, loss: 0.4449\n",
      "epoch: 2961, loss: 0.4448\n",
      "epoch: 2962, loss: 0.4448\n",
      "epoch: 2963, loss: 0.4448\n",
      "epoch: 2964, loss: 0.4448\n",
      "epoch: 2965, loss: 0.4447\n",
      "epoch: 2966, loss: 0.4447\n",
      "epoch: 2967, loss: 0.4447\n",
      "epoch: 2968, loss: 0.4447\n",
      "epoch: 2969, loss: 0.4446\n",
      "epoch: 2970, loss: 0.4446\n",
      "epoch: 2971, loss: 0.4446\n",
      "epoch: 2972, loss: 0.4446\n",
      "epoch: 2973, loss: 0.4445\n",
      "epoch: 2974, loss: 0.4445\n",
      "epoch: 2975, loss: 0.4445\n",
      "epoch: 2976, loss: 0.4445\n",
      "epoch: 2977, loss: 0.4444\n",
      "epoch: 2978, loss: 0.4444\n",
      "epoch: 2979, loss: 0.4444\n",
      "epoch: 2980, loss: 0.4444\n",
      "epoch: 2981, loss: 0.4443\n",
      "epoch: 2982, loss: 0.4443\n",
      "epoch: 2983, loss: 0.4443\n",
      "epoch: 2984, loss: 0.4443\n",
      "epoch: 2985, loss: 0.4442\n",
      "epoch: 2986, loss: 0.4442\n",
      "epoch: 2987, loss: 0.4442\n",
      "epoch: 2988, loss: 0.4442\n",
      "epoch: 2989, loss: 0.4441\n",
      "epoch: 2990, loss: 0.4441\n",
      "epoch: 2991, loss: 0.4441\n",
      "epoch: 2992, loss: 0.4441\n",
      "epoch: 2993, loss: 0.4440\n",
      "epoch: 2994, loss: 0.4440\n",
      "epoch: 2995, loss: 0.4440\n",
      "epoch: 2996, loss: 0.4440\n",
      "epoch: 2997, loss: 0.4439\n",
      "epoch: 2998, loss: 0.4439\n",
      "epoch: 2999, loss: 0.4439\n",
      "final loss: 0.4439\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "model = nn.Linear(X_train.shape[1], 1)\n",
    "activation = nn.Sigmoid()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "#implement me!\n",
    "# raise NotImplementedError\n",
    "\n",
    "for epoch in range(3000):\n",
    "    #implement me!\n",
    "    # raise NotImplementedError\n",
    "    y_pred = activation(model(X_train))\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(f\"epoch: {epoch}, loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz trzeba sprawdzić, jak poszło naszej sieci. W PyTorchu sieć pracuje zawsze w jednym z dwóch trybów: treningowym lub ewaluacyjnym (predykcyjnym). Ten drugi wyłącza niektóre mechanizmy, które są używane tylko podczas treningu, w szczególności regularyzację dropout. Do przełączania służą metody modelu `.train()` i `.eval()`.\n",
    "\n",
    "Dodatkowo podczas liczenia predykcji dobrze jest wyłączyć liczenie gradientów, bo nie będą potrzebne, a oszczędza to czas i pamięć. Używa się do tego menadżera kontekstu `with torch.no_grad():`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH37zDX4LAs2",
    "outputId": "b1f93309-6f04-4ffc-b0ca-08d0a32120a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 85.12%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_score = activation(model(X_test))\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to całkiem dobry wynik, a może być jeszcze lepszy. Sprawdźmy dla pewności jeszcze inne metryki: precyzję, recall oraz F1-score. Dodatkowo narysujemy krzywą precision-recall, czyli jak zmieniają się te metryki w zależności od przyjętego progu (threshold) prawdopodobieństwa, powyżej którego przyjmujemy klasę pozytywną. Taką krzywą należy rysować na zbiorze walidacyjnym, bo później chcemy wykorzystać tę informację do doboru progu, a nie chcemy mieć wycieku danych testowych (data leakage).\n",
    "\n",
    "Poniżej zaimplementowano także funkcję `get_optimal_threshold()`, która sprawdza, dla którego progu uzyskujemy maksymalny F1-score, i zwraca indeks oraz wartość optymalnego progu. Przyda ci się ona w dalszej części laboratorium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "def get_optimal_threshold(\n",
    "    precisions: np.array, \n",
    "    recalls: np.array, \n",
    "    thresholds: np.array\n",
    ") -> Tuple[int, float]:\n",
    "    f1_scores = 2 * precisions * recalls / (precisions + recalls)\n",
    "    \n",
    "    optimal_idx = np.nanargmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    return optimal_idx, optimal_threshold\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred_score) -> None:\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_score)\n",
    "    optimal_idx, optimal_threshold = get_optimal_threshold(precisions, recalls, thresholds)\n",
    "\n",
    "    disp = PrecisionRecallDisplay(precisions, recalls)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Precision-recall curve (opt. thresh.: {optimal_threshold:.4f})\")\n",
    "    plt.axvline(recalls[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.axhline(precisions[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid_score = activation(model(X_valid))\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfQPIUQ_LAs2"
   },
   "source": [
    "Jak widać, chociaż AUROC jest wysokie, to dla optymalnego F1-score recall nie jest zbyt wysoki, a precyzja jest już dość niska. Być może wynik uda się poprawić, używając modelu o większej pojemności - pełnej, głębokiej sieci neuronowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP298w6Cq7T6"
   },
   "source": [
    "Wszystko zaczęło się od inspirowanych biologią [sztucznych neuronów](https://en.wikipedia.org/wiki/Artificial_neuron), których próbowano użyć do symulacji mózgu. Naukowcy szybko odeszli od tego podejścia (sam problem modelowania okazał się też znacznie trudniejszy, niż sądzono), zamiast tego używając neuronów jako jednostek reprezentującą dowolną funkcję parametryczną $f(x, \\Theta)$. Każdy neuron jest zatem bardzo elastyczny, bo jedyne wymagania to funkcja różniczkowalna, a mamy do tego wektor parametrów $\\Theta$.\n",
    "\n",
    "W praktyce najczęściej można spotkać się z kilkoma rodzinami sieci neuronowych:\n",
    "1. Perceptrony wielowarstwowe (*MultiLayer Perceptron*, MLP) - najbardziej podobne do powyższego opisu, niezbędne do klasyfikacji i regresji\n",
    "2. Konwolucyjne (*Convolutional Neural Networks*, CNNs) - do przetwarzania danych z zależnościami przestrzennymi, np. obrazów czy dźwięku\n",
    "3. Rekurencyjne (*Recurrent Neural Networks*, RNNs) - do przetwarzania danych z zależnościami sekwencyjnymi, np. szeregi czasowe, oraz kiedyś do języka naturalnego\n",
    "4. Transformacyjne (*Transformers*), oparte o mechanizm atencji (*attention*) - do przetwarzania języka naturalnego (NLP), z którego wyparły RNNs, a coraz częściej także do wszelkich innych danych, np. obrazów, dźwięku\n",
    "5. Grafowe (*Graph Neural Networks*, GNNS) - do przetwarzania grafów\n",
    "\n",
    "Na tym laboratorium skupimy się na najprostszej architekturze, czyli MLP. Jest ona powszechnie łączona z wszelkimi innymi architekturami, bo pozwala dokonywać klasyfikacji i regresji. Przykładowo, klasyfikacja obrazów to zwykle CNN + MLP, klasyfikacja tekstów to transformer + MLP, a regresja na grafach to GNN + MLP.\n",
    "\n",
    "Dodatkowo, pomimo prostoty MLP są bardzo potężne - udowodniono, że perceptrony (ich powszechna nazwa) są [uniwersalnym aproksymatorem](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208), będącym w stanie przybliżyć dowolną funkcję z odpowiednio małym błędem, zakładając wystarczającą wielkość warstw sieci. Szczególne ich wersje potrafią nawet [reprezentować drzewa decyzyjne](https://www.youtube.com/watch?v=_okxGdHM5b8).\n",
    "\n",
    "Dla zainteresowanych polecamy [doskonałą książkę \"Dive into Deep Learning\", z implementacjami w PyTorchu](https://d2l.ai/chapter_multilayer-perceptrons/index.html), [klasyczną książkę \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/mlp.html), oraz [ten filmik](https://www.youtube.com/watch?v=BFHrIxKcLjA), jeśli zastanawiałeś/-aś się, czemu używamy deep learning, a nie naprzykład (wide?) learning. (aka. czemu staramy się budować głębokie sieci, a nie płytkie za to szerokie)"
   ]
  },
  {
   "attachments": {
    "1_x-3NGQv0pRIab8xDT-f_Hg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ZjoGBU5upj"
   },
   "source": [
    "### Sieci MLP\n",
    "\n",
    "Dla przypomnienia, na wejściu mamy punkty ze zbioru treningowego, czyli $d$-wymiarowe wektory. W klasyfikacji chcemy znaleźć granicę decyzyjną, czyli krzywą, która oddzieli od siebie klasy. W wejściowej przestrzeni może być to trudne, bo chmury punktów z poszczególnych klas mogą być ze sobą dość pomieszane. Pamiętajmy też, że regresja logistyczna jest klasyfikatorem liniowym, czyli w danej przestrzeni potrafi oddzielić punkty tylko linią prostą.\n",
    "\n",
    "Sieć MLP składa się z warstw. Każda z nich dokonuje nieliniowego przekształcenia przestrzeni (można o tym myśleć jak o składaniu przestrzeni jakąś prostą/łamaną), tak, aby w finalnej przestrzeni nasze punkty były możliwie liniowo separowalne. Wtedy ostatnia warstwa z sigmoidą będzie potrafiła je rozdzielić od siebie.\n",
    "\n",
    "![1_x-3NGQv0pRIab8xDT-f_Hg.png](attachment:1_x-3NGQv0pRIab8xDT-f_Hg.png)\n",
    "\n",
    "Poszczególne neurony składają się z iloczynu skalarnego wejść z wagami neuronu, oraz nieliniowej funkcji aktywacji. W PyTorchu są to osobne obiekty - `nn.Linear` oraz np. `nn.Sigmoid`. Funkcja aktywacji przyjmuje wynik iloczynu skalarnego i przekształca go, aby sprawdzić, jak mocno reaguje neuron na dane wejście. Musi być nieliniowa z dwóch powodów. Po pierwsze, tylko nieliniowe przekształcenia są na tyle potężne, żeby umożliwić liniową separację danych w ostatniej warstwie. Po drugie, liniowe przekształcenia zwyczajnie nie działają. Aby zrozumieć czemu, trzeba zobaczyć, co matematycznie oznacza sieć MLP.\n",
    "\n",
    "![perceptron](https://www.saedsayad.com/images/Perceptron_bkp_1.png)\n",
    "\n",
    "Zapisane matematycznie MLP to:\n",
    "$\n",
    "h_1 = f_1(x) \\\\\n",
    "h_2 = f_2(h_1) \\\\\n",
    "h_3 = f_3(h_2) \\\\\n",
    "...\n",
    "h_n = f_n(h_{n-1})\n",
    "$\n",
    "gdzie $x$ to wejście $f_i$ to funkcja aktywacji $i$-tej warstwy, a $h_i$ to wyjście $i$-tej warstwy, nazywane **ukrytą reprezentacją (hidden representation)**, lub *latent representation*. Nazwa bierze się z tego, że w środku sieci wyciągamy cechy i wzorce w danych, które nie są widoczne na pierwszy rzut oka na wejściu.\n",
    "\n",
    "Załóżmy, że nie mamy funkcji aktywacji, czyli mamy aktywację liniową $f(x) = x$. Zobaczmy na początku sieci:\n",
    "$\n",
    "h_1 = f_1(x) = x\n",
    "h_2 = f_2(f_1) = f_2(x) = x\n",
    "...\n",
    "h_n = f_n(f_{n-1}) = f_n(x) = x\n",
    "$\n",
    "Jak widać, taka sieć niczego się nie nauczy. Wynika to z tego, że złożenie funkcji liniowych jest także funkcją liniową - patrz notatki z algebry :)\n",
    "\n",
    "Jeżeli natomiast użyjemy nieliniowej funkcji aktywacji, często oznaczanej jako $\\sigma$, to wszystko będzie działać. Co ważne, ostatnia warstwa, dająca wyjście sieci, ma zwykle inną aktywację od warstw wewnątrz sieci, bo też ma inne zadanie - zwrócić wartość dla klasyfikacji lub regresji. Na wyjściu korzysta się z funkcji liniowej (regresja), sigmoidalnej (klasyfikacja binarna) lub softmax (klasyfikacja wieloklasowa).\n",
    "\n",
    "Wewnątrz sieci używano kiedyś sigmoidy oraz tangensa hiperbolicznego `tanh`, ale okazało się to nieefektywne przy uczeniu głębokich sieci o wielu warstwach. Nowoczesne sieci korzystają zwykle z funkcji ReLU (*rectified linear unit*), która jest zaskakująco prosta: $ReLU(x) = \\max(0, x)$. Okazało się, że bardzo dobrze nadaje się do treningu nawet bardzo głębokich sieci neuronowych. Nowsze funkcje aktywacji są głównie modyfikacjami ReLU.\n",
    "\n",
    "![relu](https://www.nomidl.com/wp-content/uploads/2022/04/image-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP w PyTorchu\n",
    "\n",
    "Warstwę neuronów w MLP nazywa się warstwą gęstą (*dense layer*) lub warstwą w pełni połączoną (*fully-connected layer*), i taki opis oznacza zwykle same neurony oraz funkcję aktywacji. PyTorch, jak już widzieliśmy, definiuje osobno transformację liniową oraz aktywację, a więc jedna warstwa składa się de facto z 2 obiektów, wywoływanych jeden po drugim. Inne frameworki, szczególnie wysokopoziomowe (np. Keras) łączą to często w jeden obiekt.\n",
    "\n",
    "MLP składa się zatem z sekwencji obiektów, które potem wywołuje się jeden po drugim, gdzie wyjście poprzedniego to wejście kolejnego. Ale nie można tutaj używać Pythonowych list! Z perspektywy PyTorcha to wtedy niezależne obiekty i nie zostanie wtedy przekazany między nimi gradient. Trzeba tutaj skorzystać z `nn.Sequential`, aby tworzyć taki pipeline.\n",
    "\n",
    "Rozmiary wejścia i wyjścia dla każdej warstwy trzeba w PyTorchu podawać explicite. Jest to po pierwsze edukacyjne, a po drugie często ułatwia wnioskowanie o działaniu sieci oraz jej debugowanie - mamy jasno podane, czego oczekujemy. Niektóre frameworki (np. Keras) obliczają to automatycznie.\n",
    "\n",
    "Co ważne, ostatnia warstwa zwykle nie ma funkcji aktywacji. Wynika to z tego, że obliczanie wielu funkcji kosztu (np. entropii krzyżowej) na aktywacjach jest często niestabilne numerycznie. Z tego powodu PyTorch oferuje funkcje kosztu zawierające w środku aktywację dla ostatniej warstwy, a ich implementacje są stabilne numerycznie. Przykładowo, `nn.BCELoss` przyjmuje wejście z zaaplikowanymi już aktywacjami, ale może skutkować under/overflow, natomiast `nn.BCEWithLogitsLoss` przyjmuje wejście bez aktywacji, a w środku ma specjalną implementację łączącą binarną entropię krzyżową z aktywacją sigmoidalną. Oczywiście w związku z tym aby dokonać potem predykcji w praktyce, trzeba pamiętać o użyciu funkcji aktywacji. Często korzysta się przy tym z funkcji z modułu `torch.nn.functional`, które są w tym wypadku nieco wygodniejsze od klas wywoływalnych z `torch.nn`.\n",
    "\n",
    "Całe sieci w PyTorchu tworzy się jako klasy dziedziczące po `nn.Module`. Co ważne, obiekty, z których tworzymy sieć, np. `nn.Linear`, także dziedziczą po tej klasie. Pozwala to na bardzo modułową budowę kodu, zgodną z zasadami OOP. W konstruktorze najpierw trzeba zawsze wywołać konstruktor rodzica - `super().__init__()`, a później tworzy się potrzebne obiekty i zapisuje jako atrybuty. Musimy też zdefiniować metodę `forward()`, która przyjmuje tensor `x` i zwraca wynik. Typowo ta metoda po prostu używa obiektów zdefiniowanych w konstruktorze.\n",
    "\n",
    "\n",
    "**UWAGA: nigdy w normalnych warunkach się nie woła metody `forward` ręcznie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8niDgExAMDO"
   },
   "source": [
    "#### Zadanie 4 (1 punkt)\n",
    "\n",
    "Uzupełnij implementację 3-warstwowej sieci MLP. Użyj rozmiarów:\n",
    "* pierwsza warstwa: input_size x 256\n",
    "* druga warstwa: 256 x 128\n",
    "* trzecia warstwa: 128 x 1\n",
    "\n",
    "Użyj funkcji aktywacji ReLU.\n",
    "\n",
    "Przydatne klasy:\n",
    "- `nn.Sequential`\n",
    "- `nn.Linear`\n",
    "- `nn.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZpuVDz1ALU5",
    "outputId": "cfe0d6ac-d2ce-43dd-cc22-837063f0f6bf"
   },
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # # implement me!\n",
    "        # raise NotImplementedError\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # implement me!\n",
    "        # raise NotImplementedError\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6700\n",
      "Epoch 200 train loss: 0.6500\n",
      "Epoch 400 train loss: 0.6328\n",
      "Epoch 600 train loss: 0.6177\n",
      "Epoch 800 train loss: 0.6043\n",
      "Epoch 1000 train loss: 0.5924\n",
      "Epoch 1200 train loss: 0.5817\n",
      "Epoch 1400 train loss: 0.5722\n",
      "Epoch 1600 train loss: 0.5635\n",
      "Epoch 1800 train loss: 0.5556\n",
      "final loss: 0.5484\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = MLP(input_size=X_train.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "num_epochs = 2000\n",
    "evaluation_steps = 200\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % evaluation_steps == 0:\n",
    "        print(f\"Epoch {i} train loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP5GSup24dXU",
    "outputId": "05f332c4-5d94-41f6-f85b-17793d3c4b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 80.22%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # positive class probabilities\n",
    "    y_pred_valid_score = model.predict_proba(X_valid)\n",
    "    y_pred_test_score = model.predict_proba(X_test)\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_test_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC jest podobne, a precision i recall spadły - wypadamy wręcz gorzej od regresji liniowej! Skoro dodaliśmy więcej warstw, to może pojemność modelu jest teraz za duża i trzeba by go zregularyzować?\n",
    "\n",
    "Sieci neuronowe bardzo łatwo przeuczają, bo są bardzo elastycznymi i pojemnymi modelami. Dlatego mają wiele różnych rodzajów regularyzacji, których używa się razem. Co ciekawe, udowodniono eksperymentalnie, że zbyt duże sieci z mocną regularyzacją działają lepiej niż mniejsze sieci, odpowiedniego rozmiaru, za to ze słabszą regularyzacją.\n",
    "\n",
    "Pierwszy rodzaj regularyzacji to znana nam już **regularyzacja L2**, czyli penalizacja zbyt dużych wag. W kontekście sieci neuronowych nazywa się też ją czasem *weight decay*. W PyTorchu dodaje się ją jako argument do optymalizatora.\n",
    "\n",
    "Regularyzacja specyficzna dla sieci neuronowych to **dropout**. Polega on na losowym wyłączaniu zadanego procenta neuronów podczas treningu. Pomimo prostoty okazała się niesamowicie skuteczna, szczególnie w treningu bardzo głębokich sieci. Co ważne, jest to mechanizm używany tylko podczas treningu - w trakcie predykcji za pomocą sieci wyłącza się ten mechanizm i dokonuje normalnie predykcji całą siecią. Podejście to można potraktować jak ensemble learning, podobny do lasów losowych - wyłączając losowe części sieci, w każdej iteracji trenujemy nieco inną sieć, co odpowiada uśrednianiu predykcji różnych algorytmów. Typowo stosuje się dość mocny dropout, rzędu 25-50%. W PyTorchu implementuje go warstwa `nn.Dropout`, aplikowana zazwyczaj po funkcji aktywacji.\n",
    "\n",
    "Ostatni, a być może najważniejszy rodzaj regularyzacji to **wczesny stop (early stopping)**. W każdym kroku mocniej dostosowujemy terenową sieć do zbioru treningowego, a więc zbyt długi trening będzie skutkował przeuczeniem. W metodzie wczesnego stopu używamy wydzielonego zbioru walidacyjnego (pojedynczego, metoda holdout), sprawdzając co określoną liczbę epok wynik na tym zbiorze. Jeżeli nie uzyskamy wyniku lepszego od najlepszego dotychczas uzyskanego przez określoną liczbę epok, to przerywamy trening. Okres, przez który czekamy na uzyskanie lepszego wyniku, to cierpliwość (*patience*). Im mniejsze, tym mocniejszy jest ten rodzaj regularyzacji, ale trzeba z tym uważać, bo łatwo jest przesadzić i zbyt szybko przerywać trening. Niektóre implementacje uwzględniają tzw. *grace period*, czyli gwarantowaną minimalną liczbę epok, przez którą będziemy trenować sieć, niezależnie od wybranej cierpliwości.\n",
    "\n",
    "Dodatkowo ryzyko przeuczenia można zmniejszyć, używając mniejszej stałej uczącej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 5 (1 punkt)\n",
    "\n",
    "Zaimplementuj funkcję `evaluate_model()`, obliczającą metryki na zbiorze testowym:\n",
    "- wartość funkcji kosztu (loss)\n",
    "- AUROC\n",
    "- optymalny próg\n",
    "- F1-score przy optymalnym progu\n",
    "- precyzję oraz recall dla optymalnego progu\n",
    "\n",
    "Jeżeli podana jest wartość argumentu `threshold`, to użyj jej do zamiany prawdopodobieństw na twarde predykcje. W przeciwnym razie użyj funkcji `get_optimal_threshold` i oblicz optymalną wartość progu.\n",
    "\n",
    "Pamiętaj o przełączeniu modelu w tryb ewaluacji oraz o wyłączeniu obliczania gradientów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import sigmoid\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module, \n",
    "    X: torch.Tensor, \n",
    "    y: torch.Tensor, \n",
    "    loss_fn: nn.Module,\n",
    "    threshold: Optional[float]= None\n",
    ") -> Dict[str, float]:\n",
    "    # implement me!\n",
    "    model.eval()\n",
    "    # raise NotImplementedError\n",
    "    with torch.no_grad():\n",
    "        y_pred = activation(model(X))\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "    auroc = roc_auc_score(y, y_pred)\n",
    "    \n",
    "    if threshold is None:\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y, y_pred)\n",
    "        _, threshold = get_optimal_threshold(precisions, recalls, thresholds)\n",
    "    \n",
    "    y_pred = (y_pred > threshold).float()\n",
    "    \n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        \"loss\": loss,\n",
    "        \"AUROC\": auroc,\n",
    "        \"optimal_threshold\": threshold,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 6 (1 punkt)\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP z regularyzacją L2 oraz dropout (50%). Rozmiary warstw ukrytych mają wynosić 256 i 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # implement me!\n",
    "        # raise NotImplementedError\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # implement me!\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEk9azaULAsz"
   },
   "source": [
    "Opisaliśmy wcześniej podstawowy optymalizator w sieciach neuronowych - spadek wzdłuż gradientu. Jednak wymaga on użycia całego zbioru danych, aby obliczyć gradient, co jest często niewykonalne przez rozmiar zbioru. Dlatego wymyślono **stochastyczny spadek wzdłuż gradientu (stochastic gradient descent, SGD)**, w którym używamy 1 przykładu naraz, liczymy gradient tylko po nim i aktualizujemy parametry. Jest to oczywiście dość grube przybliżenie gradientu, ale pozwala robić szybko dużo małych kroków. Kompromisem, którego używa się w praktyce, jest **minibatch gradient descent**, czyli używanie batchy np. 32, 64 czy 128 przykładów.\n",
    "\n",
    "Rzadko wspominanym, a ważnym faktem jest także to, że stochastyczność metody optymalizacji jest sama w sobie też [metodą regularyzacji](https://arxiv.org/abs/2101.12176), a więc `batch_size` to także hiperparametr.\n",
    "\n",
    "Obecnie najpopularniejszą odmianą SGD jest [Adam](https://arxiv.org/abs/1412.6980), gdyż uczy on szybko sieć oraz daje bardzo dobre wyniki nawet przy niekoniecznie idealnie dobranych hiperparametrach. W PyTorchu najlepiej korzystać z jego implementacji `AdamW`, która jest nieco lepsza niż implementacja `Adam`. Jest to zasadniczo zawsze wybór domyślny przy treningu współczesnych sieci neuronowych.\n",
    "\n",
    "Na razie użyjemy jednak minibatch SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się implementacja prostej klasy dziedziczącej po `Dataset` - tak w PyTorchu implementuje się własne zbiory danych. Użycie takich klas umożliwia użycie klas ładujących dane (`DataLoader`), które z kolei pozwalają łatwo ładować batche danych. Trzeba w takiej klasie zaimplementować metody:\n",
    "- `__len__` - zwraca ilość punktów w zbiorze\n",
    "- `__getitem__` - zwraca przykład ze zbioru pod danym indeksem oraz jego klasę\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = data\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 7 (2 punkty)\n",
    "\n",
    "Zaimplementuj pętlę treningowo-walidacyjną dla sieci neuronowej. Wykorzystaj podane wartości hiperparametrów do treningu (stała ucząca, prawdopodobieństwo dropoutu, regularyzacja L2, rozmiar batcha, maksymalna liczba epok). Użyj optymalizatora SGD.\n",
    "\n",
    "Dodatkowo zaimplementuj regularyzację przez early stopping. Sprawdzaj co epokę wynik na zbiorze walidacyjnym. Użyj podanej wartości patience, a jako metryki po prostu wartości funkcji kosztu. Może się tutaj przydać zaimplementowana funkcja `evaluate_model()`.\n",
    "\n",
    "Pamiętaj o tym, aby przechowywać najlepszy dotychczasowy wynik walidacyjny oraz najlepszy dotychczasowy model. Zapamiętaj też optymalny próg do klasyfikacji dla najlepszego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6936, eval loss 0.8519192934036255\n",
      "Epoch 1 train loss: 0.6745, eval loss 0.8452033400535583\n",
      "Epoch 2 train loss: 0.6514, eval loss 0.8389194011688232\n",
      "Epoch 3 train loss: 0.6389, eval loss 0.8330116271972656\n",
      "Epoch 4 train loss: 0.6208, eval loss 0.8273993134498596\n",
      "Epoch 5 train loss: 0.6079, eval loss 0.8220474720001221\n",
      "Epoch 6 train loss: 0.6080, eval loss 0.8169332146644592\n",
      "Epoch 7 train loss: 0.5962, eval loss 0.8120569586753845\n",
      "Epoch 8 train loss: 0.5826, eval loss 0.8073332905769348\n",
      "Epoch 9 train loss: 0.5714, eval loss 0.8028753995895386\n",
      "Epoch 10 train loss: 0.5664, eval loss 0.7985824942588806\n",
      "Epoch 11 train loss: 0.5599, eval loss 0.794499933719635\n",
      "Epoch 12 train loss: 0.5498, eval loss 0.79063481092453\n",
      "Epoch 13 train loss: 0.5496, eval loss 0.7869313955307007\n",
      "Epoch 14 train loss: 0.5584, eval loss 0.7834812998771667\n",
      "Epoch 15 train loss: 0.5399, eval loss 0.7802322506904602\n",
      "Epoch 16 train loss: 0.5388, eval loss 0.7771589159965515\n",
      "Epoch 17 train loss: 0.5265, eval loss 0.7742586731910706\n",
      "Epoch 18 train loss: 0.5247, eval loss 0.771560549736023\n",
      "Epoch 19 train loss: 0.5168, eval loss 0.7689768671989441\n",
      "Epoch 20 train loss: 0.5134, eval loss 0.7665742635726929\n",
      "Epoch 21 train loss: 0.5081, eval loss 0.7643022537231445\n",
      "Epoch 22 train loss: 0.5105, eval loss 0.7621423006057739\n",
      "Epoch 23 train loss: 0.5135, eval loss 0.7601304650306702\n",
      "Epoch 24 train loss: 0.5057, eval loss 0.7582178115844727\n",
      "Epoch 25 train loss: 0.5010, eval loss 0.7564281821250916\n",
      "Epoch 26 train loss: 0.5021, eval loss 0.7547510862350464\n",
      "Epoch 27 train loss: 0.4884, eval loss 0.7531248927116394\n",
      "Epoch 28 train loss: 0.4850, eval loss 0.751585841178894\n",
      "Epoch 29 train loss: 0.4885, eval loss 0.7501122355461121\n",
      "Epoch 30 train loss: 0.4831, eval loss 0.7486693263053894\n",
      "Epoch 31 train loss: 0.4870, eval loss 0.7473036050796509\n",
      "Epoch 32 train loss: 0.4997, eval loss 0.7459424138069153\n",
      "Epoch 33 train loss: 0.4701, eval loss 0.7446426749229431\n",
      "Epoch 34 train loss: 0.4921, eval loss 0.7433986663818359\n",
      "Epoch 35 train loss: 0.4682, eval loss 0.7421084046363831\n",
      "Epoch 36 train loss: 0.4522, eval loss 0.7409310340881348\n",
      "Epoch 37 train loss: 0.4522, eval loss 0.7397889494895935\n",
      "Epoch 38 train loss: 0.4545, eval loss 0.7387052178382874\n",
      "Epoch 39 train loss: 0.4678, eval loss 0.7376074194908142\n",
      "Epoch 40 train loss: 0.4659, eval loss 0.7365279197692871\n",
      "Epoch 41 train loss: 0.4559, eval loss 0.735504686832428\n",
      "Epoch 42 train loss: 0.4535, eval loss 0.7344657182693481\n",
      "Epoch 43 train loss: 0.4553, eval loss 0.7334807515144348\n",
      "Epoch 44 train loss: 0.4673, eval loss 0.7325348854064941\n",
      "Epoch 45 train loss: 0.4366, eval loss 0.7315930724143982\n",
      "Epoch 46 train loss: 0.4677, eval loss 0.7307389974594116\n",
      "Epoch 47 train loss: 0.4520, eval loss 0.7298574447631836\n",
      "Epoch 48 train loss: 0.4496, eval loss 0.728970468044281\n",
      "Epoch 49 train loss: 0.4346, eval loss 0.7281202673912048\n",
      "Epoch 50 train loss: 0.4438, eval loss 0.7273492813110352\n",
      "Epoch 51 train loss: 0.4441, eval loss 0.7265923023223877\n",
      "Epoch 52 train loss: 0.4422, eval loss 0.725803017616272\n",
      "Epoch 53 train loss: 0.4322, eval loss 0.7251078486442566\n",
      "Epoch 54 train loss: 0.4292, eval loss 0.7243866920471191\n",
      "Epoch 55 train loss: 0.4311, eval loss 0.723658561706543\n",
      "Epoch 56 train loss: 0.4343, eval loss 0.722958505153656\n",
      "Epoch 57 train loss: 0.4488, eval loss 0.7223486304283142\n",
      "Epoch 58 train loss: 0.4428, eval loss 0.7216631174087524\n",
      "Epoch 59 train loss: 0.4368, eval loss 0.7210210561752319\n",
      "Epoch 60 train loss: 0.4243, eval loss 0.7204096913337708\n",
      "Epoch 61 train loss: 0.4285, eval loss 0.7198590636253357\n",
      "Epoch 62 train loss: 0.4239, eval loss 0.7192699909210205\n",
      "Epoch 63 train loss: 0.4250, eval loss 0.7187535166740417\n",
      "Epoch 64 train loss: 0.4046, eval loss 0.7181902527809143\n",
      "Epoch 65 train loss: 0.4293, eval loss 0.7176734209060669\n",
      "Epoch 66 train loss: 0.4220, eval loss 0.717179536819458\n",
      "Epoch 67 train loss: 0.4179, eval loss 0.7166855335235596\n",
      "Epoch 68 train loss: 0.4102, eval loss 0.7161586284637451\n",
      "Epoch 69 train loss: 0.4041, eval loss 0.7157621383666992\n",
      "Epoch 70 train loss: 0.4099, eval loss 0.7153330445289612\n",
      "Epoch 71 train loss: 0.3993, eval loss 0.7148910760879517\n",
      "Epoch 72 train loss: 0.4288, eval loss 0.7144516706466675\n",
      "Epoch 73 train loss: 0.4125, eval loss 0.7140554189682007\n",
      "Epoch 74 train loss: 0.4072, eval loss 0.7136063575744629\n",
      "Epoch 75 train loss: 0.4174, eval loss 0.7132411599159241\n",
      "Epoch 76 train loss: 0.4178, eval loss 0.7129096388816833\n",
      "Epoch 77 train loss: 0.4150, eval loss 0.7125165462493896\n",
      "Epoch 78 train loss: 0.3910, eval loss 0.7121689319610596\n",
      "Epoch 79 train loss: 0.4306, eval loss 0.711787760257721\n",
      "Epoch 80 train loss: 0.4046, eval loss 0.7114256620407104\n",
      "Epoch 81 train loss: 0.4077, eval loss 0.7110933661460876\n",
      "Epoch 82 train loss: 0.3935, eval loss 0.7107754349708557\n",
      "Epoch 83 train loss: 0.4005, eval loss 0.7104475498199463\n",
      "Epoch 84 train loss: 0.4082, eval loss 0.7100562453269958\n",
      "Epoch 85 train loss: 0.3941, eval loss 0.7097572088241577\n",
      "Epoch 86 train loss: 0.3895, eval loss 0.7094331979751587\n",
      "Epoch 87 train loss: 0.3894, eval loss 0.7092238068580627\n",
      "Epoch 88 train loss: 0.3968, eval loss 0.7089706063270569\n",
      "Epoch 89 train loss: 0.3948, eval loss 0.7087535262107849\n",
      "Epoch 90 train loss: 0.3788, eval loss 0.7084354758262634\n",
      "Epoch 91 train loss: 0.3993, eval loss 0.7081445455551147\n",
      "Epoch 92 train loss: 0.4055, eval loss 0.7079211473464966\n",
      "Epoch 93 train loss: 0.3819, eval loss 0.7076324820518494\n",
      "Epoch 94 train loss: 0.3882, eval loss 0.7073875069618225\n",
      "Epoch 95 train loss: 0.4217, eval loss 0.7071655988693237\n",
      "Epoch 96 train loss: 0.4080, eval loss 0.7069413065910339\n",
      "Epoch 97 train loss: 0.4126, eval loss 0.7067301273345947\n",
      "Epoch 98 train loss: 0.4323, eval loss 0.7065584063529968\n",
      "Epoch 99 train loss: 0.3957, eval loss 0.7063390612602234\n",
      "Epoch 100 train loss: 0.3838, eval loss 0.7060957551002502\n",
      "Epoch 101 train loss: 0.4105, eval loss 0.7058939337730408\n",
      "Epoch 102 train loss: 0.3999, eval loss 0.7057044506072998\n",
      "Epoch 103 train loss: 0.3875, eval loss 0.7055586576461792\n",
      "Epoch 104 train loss: 0.3715, eval loss 0.7053486704826355\n",
      "Epoch 105 train loss: 0.4177, eval loss 0.7052304148674011\n",
      "Epoch 106 train loss: 0.3966, eval loss 0.7050911784172058\n",
      "Epoch 107 train loss: 0.3954, eval loss 0.7049595713615417\n",
      "Epoch 108 train loss: 0.4025, eval loss 0.7047654986381531\n",
      "Epoch 109 train loss: 0.4119, eval loss 0.7045556902885437\n",
      "Epoch 110 train loss: 0.3838, eval loss 0.7043828368186951\n",
      "Epoch 111 train loss: 0.3687, eval loss 0.704197347164154\n",
      "Epoch 112 train loss: 0.3903, eval loss 0.7040044069290161\n",
      "Epoch 113 train loss: 0.3988, eval loss 0.7039215564727783\n",
      "Epoch 114 train loss: 0.4240, eval loss 0.7038213014602661\n",
      "Epoch 115 train loss: 0.3975, eval loss 0.7037186026573181\n",
      "Epoch 116 train loss: 0.3739, eval loss 0.7036056518554688\n",
      "Epoch 117 train loss: 0.3878, eval loss 0.7034168243408203\n",
      "Epoch 118 train loss: 0.3772, eval loss 0.7032848000526428\n",
      "Epoch 119 train loss: 0.3626, eval loss 0.70321124792099\n",
      "Epoch 120 train loss: 0.3746, eval loss 0.703082263469696\n",
      "Epoch 121 train loss: 0.4076, eval loss 0.7028998136520386\n",
      "Epoch 122 train loss: 0.4245, eval loss 0.7027773261070251\n",
      "Epoch 123 train loss: 0.4129, eval loss 0.7026819586753845\n",
      "Epoch 124 train loss: 0.3766, eval loss 0.7025870680809021\n",
      "Epoch 125 train loss: 0.4056, eval loss 0.7024624943733215\n",
      "Epoch 126 train loss: 0.3977, eval loss 0.7023391127586365\n",
      "Epoch 127 train loss: 0.3871, eval loss 0.7022114396095276\n",
      "Epoch 128 train loss: 0.3576, eval loss 0.7021230459213257\n",
      "Epoch 129 train loss: 0.3787, eval loss 0.7020208835601807\n",
      "Epoch 130 train loss: 0.3678, eval loss 0.7018923163414001\n",
      "Epoch 131 train loss: 0.3886, eval loss 0.7017704248428345\n",
      "Epoch 132 train loss: 0.3778, eval loss 0.7016385197639465\n",
      "Epoch 133 train loss: 0.3515, eval loss 0.701582670211792\n",
      "Epoch 134 train loss: 0.3728, eval loss 0.7014836668968201\n",
      "Epoch 135 train loss: 0.3841, eval loss 0.701445996761322\n",
      "Epoch 136 train loss: 0.3781, eval loss 0.7013422846794128\n",
      "Epoch 137 train loss: 0.3891, eval loss 0.7012541890144348\n",
      "Epoch 138 train loss: 0.4114, eval loss 0.7011688351631165\n",
      "Epoch 139 train loss: 0.4078, eval loss 0.701127827167511\n",
      "Epoch 140 train loss: 0.3676, eval loss 0.7010537385940552\n",
      "Epoch 141 train loss: 0.3992, eval loss 0.7009907960891724\n",
      "Epoch 142 train loss: 0.3864, eval loss 0.700844943523407\n",
      "Epoch 143 train loss: 0.3887, eval loss 0.7007573246955872\n",
      "Epoch 144 train loss: 0.4022, eval loss 0.7006886601448059\n",
      "Epoch 145 train loss: 0.3857, eval loss 0.7006378173828125\n",
      "Epoch 146 train loss: 0.3954, eval loss 0.7005175948143005\n",
      "Epoch 147 train loss: 0.3609, eval loss 0.7004709839820862\n",
      "Epoch 148 train loss: 0.3796, eval loss 0.7004004120826721\n",
      "Epoch 149 train loss: 0.3401, eval loss 0.700304388999939\n",
      "Epoch 150 train loss: 0.4136, eval loss 0.7002570033073425\n",
      "Epoch 151 train loss: 0.3936, eval loss 0.7002038955688477\n",
      "Epoch 152 train loss: 0.3816, eval loss 0.7001029849052429\n",
      "Epoch 153 train loss: 0.3815, eval loss 0.7000243663787842\n",
      "Epoch 154 train loss: 0.3602, eval loss 0.6999486684799194\n",
      "Epoch 155 train loss: 0.4065, eval loss 0.6999740600585938\n",
      "Epoch 156 train loss: 0.3919, eval loss 0.699897050857544\n",
      "Epoch 157 train loss: 0.3635, eval loss 0.6997255682945251\n",
      "Epoch 158 train loss: 0.3709, eval loss 0.6996738314628601\n",
      "Epoch 159 train loss: 0.3842, eval loss 0.6995735764503479\n",
      "Epoch 160 train loss: 0.4056, eval loss 0.6996277570724487\n",
      "Epoch 161 train loss: 0.4036, eval loss 0.6994874477386475\n",
      "Epoch 162 train loss: 0.3768, eval loss 0.699451744556427\n",
      "Epoch 163 train loss: 0.3682, eval loss 0.6994026303291321\n",
      "Epoch 164 train loss: 0.4138, eval loss 0.6992992758750916\n",
      "Epoch 165 train loss: 0.3769, eval loss 0.6991960406303406\n",
      "Epoch 166 train loss: 0.3813, eval loss 0.6991794109344482\n",
      "Epoch 167 train loss: 0.3419, eval loss 0.6991204023361206\n",
      "Epoch 168 train loss: 0.3879, eval loss 0.6990838646888733\n",
      "Epoch 169 train loss: 0.3655, eval loss 0.6989642381668091\n",
      "Epoch 170 train loss: 0.3474, eval loss 0.69891756772995\n",
      "Epoch 171 train loss: 0.3799, eval loss 0.698870837688446\n",
      "Epoch 172 train loss: 0.3630, eval loss 0.6987767815589905\n",
      "Epoch 173 train loss: 0.3620, eval loss 0.6987152099609375\n",
      "Epoch 174 train loss: 0.3923, eval loss 0.6987188458442688\n",
      "Epoch 175 train loss: 0.4037, eval loss 0.6987224221229553\n",
      "Epoch 176 train loss: 0.3814, eval loss 0.6986057758331299\n",
      "Epoch 177 train loss: 0.3893, eval loss 0.6985437273979187\n",
      "Epoch 178 train loss: 0.3774, eval loss 0.6984501481056213\n",
      "Epoch 179 train loss: 0.3694, eval loss 0.6983848810195923\n",
      "Epoch 180 train loss: 0.3754, eval loss 0.6982709765434265\n",
      "Epoch 181 train loss: 0.3706, eval loss 0.6982764601707458\n",
      "Epoch 182 train loss: 0.3986, eval loss 0.6981853246688843\n",
      "Epoch 183 train loss: 0.3734, eval loss 0.6982179880142212\n",
      "Epoch 184 train loss: 0.3724, eval loss 0.6981837749481201\n",
      "Epoch 185 train loss: 0.3997, eval loss 0.6981923580169678\n",
      "Epoch 186 train loss: 0.3819, eval loss 0.6980853080749512\n",
      "Epoch 187 train loss: 0.3730, eval loss 0.6980088353157043\n",
      "Epoch 188 train loss: 0.3464, eval loss 0.6980503797531128\n",
      "Epoch 189 train loss: 0.3718, eval loss 0.6978849768638611\n",
      "Epoch 190 train loss: 0.3639, eval loss 0.6978592276573181\n",
      "Epoch 191 train loss: 0.3764, eval loss 0.6978601813316345\n",
      "Epoch 192 train loss: 0.3748, eval loss 0.6978585124015808\n",
      "Epoch 193 train loss: 0.3899, eval loss 0.6977861523628235\n",
      "Epoch 194 train loss: 0.4016, eval loss 0.6976748108863831\n",
      "Epoch 195 train loss: 0.3571, eval loss 0.6976140737533569\n",
      "Epoch 196 train loss: 0.3667, eval loss 0.6975479125976562\n",
      "Epoch 197 train loss: 0.3537, eval loss 0.6975436210632324\n",
      "Epoch 198 train loss: 0.3632, eval loss 0.6974666118621826\n",
      "Epoch 199 train loss: 0.3684, eval loss 0.6974380612373352\n",
      "Epoch 200 train loss: 0.3641, eval loss 0.6974298357963562\n",
      "Epoch 201 train loss: 0.3862, eval loss 0.6973432898521423\n",
      "Epoch 202 train loss: 0.3556, eval loss 0.6973114609718323\n",
      "Epoch 203 train loss: 0.3803, eval loss 0.6972145438194275\n",
      "Epoch 204 train loss: 0.3686, eval loss 0.6971448063850403\n",
      "Epoch 205 train loss: 0.3819, eval loss 0.6970426440238953\n",
      "Epoch 206 train loss: 0.3581, eval loss 0.6970298290252686\n",
      "Epoch 207 train loss: 0.3760, eval loss 0.696951687335968\n",
      "Epoch 208 train loss: 0.3681, eval loss 0.6968921422958374\n",
      "Epoch 209 train loss: 0.3642, eval loss 0.6969037055969238\n",
      "Epoch 210 train loss: 0.3399, eval loss 0.6968570351600647\n",
      "Epoch 211 train loss: 0.3762, eval loss 0.69682776927948\n",
      "Epoch 212 train loss: 0.3874, eval loss 0.6967625021934509\n",
      "Epoch 213 train loss: 0.3602, eval loss 0.6967124938964844\n",
      "Epoch 214 train loss: 0.3629, eval loss 0.6967134475708008\n",
      "Epoch 215 train loss: 0.3536, eval loss 0.6966837048530579\n",
      "Epoch 216 train loss: 0.3760, eval loss 0.6965814232826233\n",
      "Epoch 217 train loss: 0.3665, eval loss 0.6964921355247498\n",
      "Epoch 218 train loss: 0.3526, eval loss 0.6964576244354248\n",
      "Epoch 219 train loss: 0.3738, eval loss 0.6964903473854065\n",
      "Epoch 220 train loss: 0.3957, eval loss 0.6964629292488098\n",
      "Epoch 221 train loss: 0.4034, eval loss 0.6964514851570129\n",
      "Epoch 222 train loss: 0.3621, eval loss 0.6964624524116516\n",
      "Epoch 223 train loss: 0.3600, eval loss 0.6963899731636047\n",
      "Epoch 224 train loss: 0.3881, eval loss 0.6964104175567627\n",
      "Epoch 225 train loss: 0.3913, eval loss 0.6963704228401184\n",
      "Epoch 226 train loss: 0.4126, eval loss 0.6963182091712952\n",
      "Epoch 227 train loss: 0.3580, eval loss 0.6962723135948181\n",
      "Epoch 228 train loss: 0.3740, eval loss 0.696216881275177\n",
      "Epoch 229 train loss: 0.3856, eval loss 0.6961687207221985\n",
      "Epoch 230 train loss: 0.3871, eval loss 0.6961616277694702\n",
      "Epoch 231 train loss: 0.3942, eval loss 0.6960856318473816\n",
      "Epoch 232 train loss: 0.4082, eval loss 0.6960539817810059\n",
      "Epoch 233 train loss: 0.3781, eval loss 0.6959511041641235\n",
      "Epoch 234 train loss: 0.3486, eval loss 0.6959035992622375\n",
      "Epoch 235 train loss: 0.3316, eval loss 0.6958714127540588\n",
      "Epoch 236 train loss: 0.3397, eval loss 0.6958789825439453\n",
      "Epoch 237 train loss: 0.4056, eval loss 0.6958128809928894\n",
      "Epoch 238 train loss: 0.3677, eval loss 0.6957292556762695\n",
      "Epoch 239 train loss: 0.3725, eval loss 0.6956661343574524\n",
      "Epoch 240 train loss: 0.3885, eval loss 0.6957101225852966\n",
      "Epoch 241 train loss: 0.3700, eval loss 0.695675790309906\n",
      "Epoch 242 train loss: 0.3479, eval loss 0.6956911087036133\n"
     ]
    }
   ],
   "source": [
    "model = RegularizedMLP(\n",
    "    input_size=X_train.shape[1], \n",
    "    dropout_p=dropout_p\n",
    ")\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=l2_reg\n",
    ")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # note that we are using DataLoader to get batches\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # model training\n",
    "        # implement me!\n",
    "        # raise NotImplementedError\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # model evaluation, early stopping\n",
    "    # implement me!\n",
    "    \n",
    "    model.eval()\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    if valid_metrics['loss'] < best_val_loss:\n",
    "        # raise NotImplementedError\n",
    "        best_val_loss = valid_metrics['loss']\n",
    "        best_model = deepcopy(model)\n",
    "        best_threshold = valid_metrics['optimal_threshold']\n",
    "        steps_without_improvement = 0\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        # raise NotImplementedError\n",
    "        if steps_without_improvement == early_stopping_patience:\n",
    "            break\n",
    "    \n",
    "    print(f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 89.81%\n",
      "F1: 67.83%\n",
      "Precision: 60.66%\n",
      "Recall: 76.91%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")\n",
    "print(f\"Precision: {100 * test_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {100 * test_metrics['recall']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki wyglądają już dużo lepiej.\n",
    "\n",
    "Na koniec laboratorium dołożymy do naszego modelu jeszcze 3 powrzechnie używane techniki, które są bardzo proste, a pozwalają często ulepszyć wynik modelu.\n",
    "\n",
    "Pierwszą z nich są **warstwy normalizacji (normalization layers)**. Powstały one początkowo z założeniem, że przez przekształcenia przestrzeni dokonywane przez sieć zmienia się rozkład prawdopodobieństw pomiędzy warstwami, czyli tzw. *internal covariate shift*. Później okazało się, że zastosowanie takiej normalizacji wygładza powierzchnię funkcji kosztu, co ułatwia i przyspiesza optymalizację. Najpowszechniej używaną normalizacją jest **batch normalization (batch norm)**.\n",
    "\n",
    "Drugim ulepszeniem jest dodanie **wag klas (class weights)**. Mamy do czynienia z problemem klasyfikacji niezbalansowanej, więc klasa mniejszościowa, ważniejsza dla nas, powinna dostać większą wagę. Implementuje się to trywialnie prosto - po prostu mnożymy wartość funkcji kosztu dla danego przykładu przez wagę dla prawdziwej klasy tego przykładu. Praktycznie każdy klasyfikator operujący na jakiejś ważonej funkcji może działać w ten sposób, nie tylko sieci neuronowe.\n",
    "\n",
    "Ostatnim ulepszeniem jest zamiana SGD na optymalizator Adam, a konkretnie na optymalizator `AdamW`. Jest to przykład **optymalizatora adaptacyjnego (adaptive optimizer)**, który potrafi zaadaptować stałą uczącą dla każdego parametru z osobna w trakcie treningu. Wykorzystuje do tego gradienty - w uproszczeniu, im większa wariancja gradientu, tym mniejsze kroki w tym kierunku robimy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 8 (1 punkt)\n",
    "\n",
    "Zaimplementuj model `NormalizingMLP`, o takiej samej strukturze jak `RegularizedMLP`, ale dodatkowo z warstwami `BatchNorm1d` pomiędzy warstwami `Linear` oraz `ReLU`.\n",
    "\n",
    "Za pomocą funkcji `compute_class_weight()` oblicz wagi dla poszczególnych klas. Użyj opcji `\"balanced\"`. Przekaż do funkcji kosztu wagę klasy pozytywnej (pamiętaj, aby zamienić ją na tensor).\n",
    "\n",
    "Zamień używany optymalizator na `AdamW`.\n",
    "\n",
    "Na koniec skopiuj resztę kodu do treningu z poprzedniego zadania, wytrenuj sieć i oblicz wyniki na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # implement me!\n",
    "        # raise NotImplementedError\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # raise NotImplementedError\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.5904, eval loss 0.8208534717559814\n",
      "Epoch 1 train loss: 0.5051, eval loss 0.8174512386322021\n",
      "Epoch 2 train loss: 0.5515, eval loss 0.8151342868804932\n",
      "Epoch 3 train loss: 0.5248, eval loss 0.8134300112724304\n",
      "Epoch 4 train loss: 0.5591, eval loss 0.8130418658256531\n",
      "Epoch 5 train loss: 0.5558, eval loss 0.8116326928138733\n",
      "Epoch 6 train loss: 0.4968, eval loss 0.8124681115150452\n",
      "Epoch 7 train loss: 0.5393, eval loss 0.8114404082298279\n",
      "Epoch 8 train loss: 0.5539, eval loss 0.8111186623573303\n",
      "Epoch 9 train loss: 0.5767, eval loss 0.8119686841964722\n",
      "Epoch 10 train loss: 0.6004, eval loss 0.810889720916748\n",
      "Epoch 11 train loss: 0.4733, eval loss 0.8102673888206482\n",
      "Epoch 12 train loss: 0.5429, eval loss 0.8100055456161499\n",
      "Epoch 13 train loss: 0.5160, eval loss 0.8096197247505188\n",
      "Epoch 14 train loss: 0.4903, eval loss 0.8093515038490295\n",
      "Epoch 15 train loss: 0.4695, eval loss 0.8093981742858887\n",
      "Epoch 16 train loss: 0.5197, eval loss 0.8094775080680847\n",
      "Epoch 17 train loss: 0.5465, eval loss 0.8096718788146973\n",
      "Epoch 18 train loss: 0.4745, eval loss 0.8091040849685669\n",
      "Epoch 19 train loss: 0.5145, eval loss 0.8079286217689514\n",
      "Epoch 20 train loss: 0.4600, eval loss 0.8089995384216309\n",
      "Epoch 21 train loss: 0.4899, eval loss 0.8076968789100647\n",
      "Epoch 22 train loss: 0.4743, eval loss 0.8092487454414368\n",
      "Epoch 23 train loss: 0.5033, eval loss 0.808677613735199\n",
      "Epoch 24 train loss: 0.4855, eval loss 0.8086439967155457\n"
     ]
    }
   ],
   "source": [
    "model = NormalizingMLP(\n",
    "    input_size=X_train.shape[1], \n",
    "    dropout_p=dropout_p\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=l2_reg\n",
    ")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1])\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # note that we are using DataLoader to get batches\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        # model training\n",
    "        # implement me!\n",
    "        # raise NotImplementedError\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # model evaluation, early stopping\n",
    "    # implement me!\n",
    "    \n",
    "    model.eval()\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    if valid_metrics['loss'] < best_val_loss:\n",
    "        # raise NotImplementedError \n",
    "        best_val_loss = valid_metrics['loss']\n",
    "        steps_without_improvement = 0\n",
    "        best_model = deepcopy(model)\n",
    "        best_threshold = valid_metrics['optimal_threshold']\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        # raise NotImplementedError\n",
    "        if steps_without_improvement == early_stopping_patience:\n",
    "            break\n",
    "    \n",
    "    print(f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 90.67%\n",
      "F1: 69.43%\n",
      "Precision: 63.23%\n",
      "Recall: 76.98%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")\n",
    "print(f\"Precision: {100 * test_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {100 * test_metrics['recall']:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytania kontrolne (1 punkt)\n",
    "\n",
    "1. Wymień 4 najważniejsze twoim zdaniem hiperparametry sieci neuronowej.\n",
    "2. Czy widzisz jakiś problem w użyciu regularyzacji L1 w treningu sieci neuronowych? Czy dropout może twoim zdaniem stanowić alternatywę dla tego rodzaju regularyzacji?\n",
    "3. Czy użycie innej metryki do wczesnego stopu da taki sam model końcowy? Czemu?\n",
    "\n",
    "\n",
    "## Odpowiedzi\n",
    "1. Liczba warstw, liczba neuronów dla każdej z nich, funkcja aktywacyjna, dodatkowe warstwy typu dropout i parametr dropout_p.\n",
    "2. W pewnym sensie robi to samo, bo sprawia, że efektywne wagi sa równe zero. Problemem w regularyzacji L1 może być fakt, że wszystkie wagi będą dążyć do zera.\n",
    "3. Pewnie nie. W tym przypadku bezpośrednio w X krokach po pogorszeniu się kończymy pracę, a potencjalnie minimum funkcji straty może być dalej. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyoRnHT4GFR9"
   },
   "source": [
    "## Akceleracja sprzętowa (dla zainteresowanych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wcześniej wspominaliśmy, użycie akceleracji sprzętowej, czyli po prostu GPU do obliczeń, jest bardzo efektywne w przypadku sieci neuronowych. Karty graficzne bardzo efektywnie mnożą macierze, a sieci neuronowe to, jak można było się przekonać, dużo mnożenia macierzy.\n",
    "\n",
    "W PyTorchu jest to dosyć łatwe, ale trzeba robić to explicite. Służy do tego metoda `.to()`, która przenosi tensory między CPU i GPU. Poniżej przykład, jak to się robi (oczywiście trzeba mieć skonfigurowane GPU, żeby działało):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.9403, time: 0.26154661178588867\n",
      "Epoch 1 train loss: 0.4740, time: 0.5825843811035156\n",
      "Epoch 2 train loss: 0.4713, time: 0.5621592998504639\n",
      "Epoch 3 train loss: 0.4288, time: 0.6667187213897705\n",
      "Epoch 4 train loss: 0.6754, time: 0.5703341960906982\n",
      "Epoch 6 train loss: 0.3388, time: 0.6292016506195068\n",
      "Epoch 7 train loss: 0.4154, time: 0.6077597141265869\n",
      "Epoch 8 train loss: 0.4496, time: 0.576446533203125\n",
      "Epoch 9 train loss: 0.4236, time: 0.5904619693756104\n",
      "Epoch 11 train loss: 0.4711, time: 0.5483715534210205\n",
      "Epoch 12 train loss: 0.3967, time: 0.5502223968505859\n",
      "Epoch 13 train loss: 0.4795, time: 0.5979127883911133\n",
      "Epoch 14 train loss: 0.3781, time: 0.6137664318084717\n",
      "Epoch 15 train loss: 0.4519, time: 0.5810389518737793\n",
      "Epoch 17 train loss: 0.3557, time: 0.5913853645324707\n",
      "Epoch 18 train loss: 0.4773, time: 0.5605125427246094\n",
      "Epoch 19 train loss: 0.4318, time: 0.6335625648498535\n",
      "Epoch 20 train loss: 0.4091, time: 0.6045641899108887\n",
      "Epoch 22 train loss: 0.4752, time: 0.6681110858917236\n",
      "Epoch 23 train loss: 0.4557, time: 0.6950774192810059\n",
      "Epoch 24 train loss: 0.3588, time: 0.5619401931762695\n",
      "Epoch 25 train loss: 0.4731, time: 0.6056251525878906\n",
      "Epoch 26 train loss: 0.3809, time: 0.598773717880249\n",
      "Epoch 28 train loss: 0.5106, time: 0.6663391590118408\n",
      "Epoch 29 train loss: 0.4984, time: 0.6083922386169434\n",
      "AUROC: 90.67%\n",
      "F1: 69.43%\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "model = NormalizingMLP(\n",
    "    input_size=X_train.shape[1], \n",
    "    dropout_p=dropout_p\n",
    ").to('cuda')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1].to('cuda'))\n",
    "\n",
    "step_counter = 0\n",
    "time_from_eval = time.time()\n",
    "for epoch_id in range(30):\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to('cuda')\n",
    "        batch_y = batch_y.to('cuda')\n",
    "        \n",
    "        loss = loss_fn(model(batch_x), batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if step_counter % evaluation_steps == 0:\n",
    "            print(f\"Epoch {epoch_id} train loss: {loss.item():.4f}, time: {time.time() - time_from_eval}\")\n",
    "            time_from_eval = time.time()\n",
    "\n",
    "        step_counter += 1\n",
    "\n",
    "test_res = evaluate_model(model.to('cpu'), X_test, y_test, loss_fn.to('cpu'), threshold=0.5)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki mogą się różnić z modelem na CPU, zauważ o ile szybszy jest ten model w porównaniu z CPU (przynajmniej w przypadków scenariuszy tak będzie ;)).\n",
    "\n",
    "Dla zainteresowanych polecamy [tę serie artykułów](https://medium.com/@adi.fu7/ai-accelerators-part-i-intro-822c2cdb4ca4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dla chętnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzieliśmy, sieci neuronowe mają bardzo dużo hiperparametrów. Przeszukiwanie ich grid search'em jest więc niewykonalne, a chociaż random search by działał, to potrzebowałby wielu iteracji, co też jest kosztowne obliczeniowo.\n",
    "\n",
    "Zaimplementuj inteligentne przeszukiwanie przestrzeni hiperparametrów za pomocą biblioteki [Optuna](https://optuna.org/). Implementuje ona między innymi algorytm Tree Parzen Estimator (TPE), należący do grupy algorytmów typu Bayesian search. Typowo osiągają one bardzo dobre wyniki, a właściwie zawsze lepsze od przeszukiwania losowego. Do tego wystarcza im często niewielka liczba kroków.\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP, gdzie pierwsza warstwa ma rozmiar ukryty N, a druga N // 2. Ucz ją optymalizatorem Adam przez maksymalnie 300 epok z cierpliwością 10.\n",
    "\n",
    "Przeszukaj wybrane zakresy dla hiperparametrów:\n",
    "- rozmiar warstw ukrytych (N)\n",
    "- stała ucząca\n",
    "- batch size\n",
    "- siła regularyzacji L2\n",
    "- prawdopodobieństwo dropoutu\n",
    "\n",
    "Wykorzystaj przynajmniej 30 iteracji. Następnie przełącz algorytm na losowy (Optuna także jego implementuje), wykonaj 30 iteracji i porównaj jakość wyników.\n",
    "\n",
    "Przydatne materiały:\n",
    "- [Optuna code examples - PyTorch](https://optuna.org/#code_examples)\n",
    "- [Auto-Tuning Hyperparameters with Optuna and PyTorch](https://www.youtube.com/watch?v=P6NwZVl8ttc)\n",
    "- [Hyperparameter Tuning of Neural Networks with Optuna and PyTorch](https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837)\n",
    "- [Using Optuna to Optimize PyTorch Hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "psi",
   "language": "python",
   "name": "psi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
